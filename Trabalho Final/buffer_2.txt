370
2016] Patent Generating Artificial Intelligence 1125
to expect a human inventor to have knowledge of prior art in unrelated fields, there is no reason to limit a computer’s database to a particular subject matter. A human inventor may not think to combine cooking recipes with advances in medical science, but a computer would not be limited by such self-imposed restrictions. Now that humans and computers are competing creatively, the universe of prior art should be expanded.
This change would produce a positive result.307 The PHOSITA standard has been the subject of extensive criticism, most of which has argued the crite- ria for assessing nonobviousness are not stringent enough and therefore too many patents of questionable inventiveness are issued.308 Expanding the scope of prior art would make it more challenging to obtain patents, particularly combination patents.309 The Supreme Court has particularly emphasized “the need for caution in granting a patent based on the combination of elements found in the prior art.”310 The scope of analogous prior art has consistently ex- panded in patent law jurisprudence, and the substitution of a skilled computer would complete that expansion.311
Of course, the new standard would pose new challenges. With human PHOSITAs, juries are asked to put themselves in the shoes of the skilled per- son and decide subjectively what that person would have considered obvious. A jury would have a difficult time deciding what a “skilled” computer would consider obvious. They could consider some of the same factors that are ap- plied to the skilled person,312 or perhaps the test could require a combination of
sophisticated to ascertain what references those in the art would have actually considered at the time of invention, making the obviousness determination more predictable”).
307 See generally Robert P. Merges, Uncertainty and the Standard of Patentability, 7 HIGH TECH. L.J. 1, 14–15 (1992) (advocating for an objective PHOSITA standard). For an alternative perspective, see, for example, Durie & Lemley, supra note 294, at 991–92, 1017, arguing that “KSR overshoots the mark” in raising the patentability bar and advocating for a skilled person standard based “on what the PHOSITA and the marketplace actually know and believe.”
308 Critics have argued that the USPTO has issued too many invalid patents that unnecessarily drain consumer welfare, stunt productive research, and unreasonably extract rents from innovators. See generally Michael D. Frakes & Melissa F. Wasserman, Does the U.S. Patent and Trademark Office Grant Too Many Bad Patents?: Evidence from a Quasi-Experiment, 67 STAN. L. REV. 613 (2015) (describing the “general consensus that the [US]PTO allows too many invalid patents to is- sue”).
309 See KSR Int’l Co., U.S. 550 at 420 (noting that “in many cases a person of ordinary skill will be able to fit the teachings of multiple patents together like pieces of a puzzle”).
310 See id. at 415.
311 See, e.g., George. J. Meyer Mfg. Co. v. San Marino Elec. Corp., 422 F.2d 1285, 1288 (9th Cir. 1970) (discussing the expansion of analogous art); Innovative Scuba Concepts, Inc., v. Feder Indus., Inc., 819 F. Supp. 1487, 1503 (D. Colo. 1993) (discussing the expansion of analogous art).
312 Factors to consider in determining the level of ordinary skill in the art include: (1) “type of problems encountered in the art”; (2) “prior art solutions to those problems”; (3) “rapidity with which innovations are made”; (4) “sophistication of the technology”; and (5) “educational level of active workers in the field.” GPAC, Inc., 57 F.3d at 1579. “In a given case, every factor may not be present, and one or more factors may predominate.” Id.
 
371
1126 Boston College Law Review [Vol. 57:1079 human and computer activity. For example, the skilled computer might be a
skilled person with access to a computer’s unlimited database of prior art.
CONCLUSION
It is important for policy makers to give serious consideration to the issue of computer inventorship. There is a need for the Patent Office to issue guid- ance in this area, for Congress to reconsider the boundaries of patentability, and for the courts to decide whether computational invention is worthy of pro- tection. Doing so and recognizing that computers can be inventors will do more than address an academic concern; it will provide certainty to businesses, fairness to research, and promote the progress of science. In the words of Thomas Jefferson, “ingenuity should receive a liberal encouragement.”313 What could be more ingenious than creative computers?
 313 Diamond v. Chakrabarty, 447 U. S. 303, 308 (1980) (quoting 5 WRITINGS OF THOMAS JEF- FERSON 75–76 (H. Washington ed. 1871)). “In choosing such expansive terms [for the language of Section 101] . . . modified by the comprehensive ‘any,’ Congress plainly contemplated that the patent laws would be given wide scope . . . . Id.

    372
    14  Hal the Innovator: Big Data and Its Use by Artificial Intelligence Ryan Abbott
Big data and its use by artificial intelligence is disrupting innovation and creating new legal challenges. For example, computers engaging in what IBM terms “computational creativity” (n.d.) are able to use big data to innovate in ways historically entitled to patent protection. This can occur under circumstances in which an artificial intelligence, rather than a person, meets the requirements to qualify as a patent inventor (a phenomenon I refers to as “compu- tational invention”).
Yet it is unclear whether a computer can legally be a patent inventor, and it is even unclear whether a computational invention is patentable. There is no law, court opinion, or govern- ment policy that directly addresses computational invention, and language in the Patent Act requiring inventors to be individuals1 and judicial characterizations of invention as a “men- tal act” may present barriers to computer inventorship. Definitively resolving these issues requires a determination of whether a computer qualifies as an “inventor” under the Patent and Copyright Clause of the Constitution: “The Congress shall have the power ... to promote the progress of science and useful arts, by securing for limited times to authors and inventors the exclusive right to their respective writings and discoveries.”2 Whether computers can legally be inventors is of critical importance for the computer and technology industries and, more broadly, will affect how future innovation occurs. Computational invention is already happening, and it is only a matter of time until it is happening routinely. In fact, it may be only a matter of time until computers are responsible for the majority of innovation and potentially displacing human inventors. This chapter argues that a dynamic interpretation of the Patent and Copyright Clause permits computer inventors. This would incentivize the development of creative artificial intelligence and result in more innovation for society as a whole. However, even if computers cannot be legal inventors, it should still be possible to patent computational inventions. This is because recognition of inventive subject matter can qualify as inventive activity.3 Thus, individuals who subsequently “discover” computational inventions may qualify as inventors. Yet as this chapter will discuss, this approach may be inefficient, unfair, and logistically challenging.
These issues are considered more fully below. The chapter begins with an extended hypothetical example of how an artificial intelligence named Hal could be applied to drug
    Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 187
5/20/2016
1:45:50 PM

    373
    188  Ryan Abbott
development and creating new inventions. While Hal is fictional, it is based on how companies like IBM, Pfizer, and Google are starting to apply computers in this industry. Hal’s functionality is not far off. The hypothetical situates fairly abstract issues into concrete circumstances to help illustrate the implications and importance of computational invention.
A Not So Hypothetical Case Study in Drug Development
With patent and market exclusivity protections for a class of cholesterol-lowering drugs called statins (such as Lipitor) having largely run their course, the pharmaceutical industry is investing tremendous sums of money in search of the next generation of cardiovascular blockbusters. In part, these efforts have focused on an enzyme known as proprotein cover- tase subtilisin/kexin type 9 (PCSK9), which facilitates the body’s transport of low-density lipoprotein (LDL or “bad” cholesterol). Industry efforts have started to bear fruit: in July 2015, the US Food and Drug Administration (FDA) approved Praluent (alirocumab), the first PCSK9 inhibitor to treat certain patients with high cholesterol (FDA 2015). A second PCSK9 inhibitor, Repatha (evolocumab), was approved in August of 2015.
Suppose a hypothetical company, Abbott Biologics (Abbott), which was named after the author (and not related to the well-known pharmaceutical company Abbott Laboratories), has developed a new biological drug, “AbboVax.” AbboVax acts as a vaccine to treat and pre- vent cardiovascular disease by targeting PCSK9. Unlike the drugs currently in clinical trials, AbboVax does not contain antibodies. Rather, it utilizes a fragment of the PCSK9 enzyme to get the body to make its own antibodies. Pfizer has also developed an experimental PCSK9 vaccine based on a similar mechanism, although Pfizer’s vaccine has yet to enter human trials (Beasley 2015).
AbboVax was developed by a special member of Abbott’s research team—Hal. Hal is the Research and Development (R&D) Department’s moniker for a supercomputer running pro- prietary software, developed by Abbott’s Software Department, which is used for drug devel- opment. Though susceptible to flashes of genius, members of the R&D Department are not known for their creative marketing practices. Indeed, Abbott has a Marketing Department for precisely that reason. The company also has its own Intellectual Property (IP) Depart- ment working with outside counsel to prosecute several patent applications on Hal’s software.
Hal’s functionality complements or even supplants the traditional screening methods used in early stage drug development. Hal is able to model potential therapeutic candi- dates (in silico analysis), and accurately predict those candidates’ pharmacology and toxi- cology. Of course, the FDA still requires companies to study a candidate’s pharmacology and toxicology in animal models, and then submit that information to the agency in an Investigational New Drug application prior to first-in-human clinical trials. Still, Hal’s modeling reduces the need for costly and often-unsuccessful early stage experimentation.
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 188
5/20/2016
1:45:50 PM

    374
    Hal the Innovator  189
Hal can also contribute to other phases of the drug development cycle—for example, it can design trials, run clinical simulations, and search for new uses of existing drugs.4 Hal is not the only computer that can do this. The pharmaceutical industry at large is increas- ingly incorporating computers with some of Hal’s functionality into the drug development process (e.g., Taylor 2015).
Hal is part of a new generation of machines that are capable of computational creativity. IBM uses that term to describe machines, such as its supercomputer “Watson” of Jeopardy fame, that can model human intelligence by generating “ideas the world has never imagined before.”5 Watson is now being applied to medical diagnostics, where it has helped to diag- nose patients and identify research subjects (Edney 2015). The computer “generates millions of ideas out of the quintillions of possibilities, and then predicts which ones are [best], apply- ing big data in new ways” (“Computational Creativity,” n.d.). While lacking a well-accepted standardized definition, big data refers to, in the words of Microsoft, “the process of applying serious computing power—the latest in machine learning and artificial intelligence—to seri- ously massive and often highly complex sets of information” (Ohm 2014). IBM has even used Watson to develop new, potentially patentable food recipes (“Can Recipes Be Patented?” 2013; Singh 2014).
Part of the reason for Hal’s expansive functionality is that it has access to a staggering amount of genomic and clinical data. Some years ago, a prescient executive at Abbott decided that the company needed to be in the data collection business. Abbott subsequently engaged in the tremendous undertaking of collecting all of the company’s data from its current and past preclinical and clinical programs, and translating these data into a Hal-compatible for- mat. Abbott also purchased proprietary data from private insurers, health maintenance orga- nizations, and academic centers. In addition, Hal can access publicly available databases such as those maintained by the National Institutes of Health, including CDC WONDER, Health- Data.gov, and EBSCOhost’s Global Health. At present, Hal has access to clinical data on over fifty million patients.6 Large-scale data collection and analysis is something that numerous other pharmaceutical (e.g., Genentech), biotech (e.g., 23andMe), and technology companies (e.g., Google) are doing.7
To determine the optimal formulation of AbboVax, Hal broke down PCSK9, a 692-amino acid glycoprotein, into fragments of various lengths. It turns out that different amino acid segments (peptides) of PCSK9 are more or less immunogenic. In other words, the body only develops antibodies in response to certain PCSK9 peptides, and certain peptides induce a particularly strong response. Hal determined that one particular peptide segment of PCSK9, “AbboPep,” generated the strongest response from the immune system.
While it may have been possible to use AbboPep by itself in a vaccine, Hal determined that it would be more effective when linked to an adjuvant and carrier molecule. A number of adjuvants and carrier molecules are used in vaccinology, and generally known to vaccinolo- gists. Even for experts, however, it is often a matter of extensive (and expensive) trial and error to determine the optimal adjuvant, carrier, and linking chemistry. The formulation of
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 189
5/20/2016
1:45:50 PM

    375
    190  Ryan Abbott
a therapeutically effective amount of AbboPep linked to an adjuvant and carrier, together with various excipients (a surfactant, chelating agent, histidine-arginine buffer, etc.) comprises AbboVax.
All of Hal’s work in formulating AbboVax was done digitally, and Hal was able to deter- mine that the only common side effects of the treatment would be mild gastrointestinal upset and headache. The FDA still required Abbott to complete the standard package of pre- clinical tests—but the results were consistent with Hal’s predictions.
Hal’s work was not limited to AbboVax. Hal determined that Abbott’s existing statin, “AbboStatin,” for which patent protection had expired, was effective at treating prostate cancer. Hal determined this in part based on reviewing clinical data that showed the use of AbboStatin lowered prostate specific antigen (PSA), a biomarker associated with prostate cancer.
It was difficult to make further inferences because of challenges with the data. Some of the data were difficult to analyze because they were not in a common data format. In other words, the various electronic medical record systems did not all capture the same data fields, or they coded the information differently. Data in some cases consisted of only scanned handwritten notes. More important, Hal had detected problems with data integrity. Some of these were obvious, such as the patients whose ages were listed as 999 or 6’10.” Other data integrity issues were less obvious, such as patients whose handwritten notes conflicted with what had been entered into their electronic medical records, or patients who were not coded as having prostate cancer despite a positive biopsy.
To translate all the data into a workable common data format and resolve the integrity issues, Hal rewrote its own programming. Once the stuff of science fiction, the technology may already exist to allow computers to rewrite their own programming.8 At its core, Hal would need to be capable of (metaphoric) reflection. Reflection is a software concept that refers to a computer program that can examine itself, and modify its own behavior and even its own code (Malenfant, Jacques, and Demers 1996). Although the ability of today’s comput- ers to reflect is the subject of debate, even skeptics for the most part believe it is only a matter of time until computers achieve this ability. Reflection is part of the reason why Stephen Hawking, Elon Musk, and Bill Gates, among others, are concerned about the “singularity”—a point in the future when machines can outperform humans.9 Of potential concern is the belief that a number of these individuals hold that the singularity will be followed by some version of a robot apocalypse.
Hal’s new programming incorporated optical character recognition to translate handwrit- ten notes into a workable format, and allowed Hal to reformat its existing electronic data into a common data format. More important, it allowed Hal to resolve data integrity issues by estimating the accuracy of data, generating alternate possibilities, and predicting which pos- sibilities were the most accurate. Hal’s improved programming then determined that the use of AbboStatin independently increased life expectancy among men with certain types of
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 190
5/20/2016
1:45:50 PM

    376
    Hal the Innovator  191
lung cancer. When the R&D Department realized Hal had created a more efficient version of itself, they renamed the computer Hal 2.0.
At one point in Abbott’s history, the IP Department worked more or less independently of the other departments, receiving manually submitted disclosures from researchers that went into what the researchers referred to as the “black hole.” But after a series of high- profile, novelty-destroying disclosures in 2009, the company has hosted a monthly inter- departmental meeting to ensure that the company is strategically protecting its intellectual property.
Over the course of these meetings, the IP Department identified several Hal-associated discoveries that were likely candidates for patent protection. For example, AbboPep may be patentable, although there is some question as to whether a peptide is patentable under Association for Molecular Pathology v. Myriad Genetics.10 In any case, its use as a vaccine is patentable, as is the AbboVax formulation. Other targets include the use of the formula- tion to treat cardiovascular disease, the methods used to manufacture AbboVax, and the dose at which AbboVax will be effective therapeutically. In fact, elements of Hal 2.0 may be patentable.
The IP Department has also identified several challenges to obtaining patent protection. For example, in the case of AbboStatin and PSA, it may be problematic to meet enablement requirements and prove utility.11 Hal analyzed as many as fifty million patient records based on its algorithms to discover this new use. It is not clear what kind of evidence the US Patent and Trademark Office (Patent Office) may require to satisfy written enablement requirements and provide evidence of clinical utility. It is not even apparent to the R&D Department pre- cisely what databases Hal accessed.12 For that matter, even if it is possible to obtain patents for these inventions, it is not clear who the inventors would be.13
There have been a multitude of opinions regarding inventorship. Members of one group in the R&D Department have claimed they invented AbboPep and AbboVax. They directed Hal to test the immunogenicity of the PCSK9 enzyme, suspecting that it was a vaccine can- didate. Members of a different group within that department claimed credit for directing Hal to investigate new uses of AbboStatin. The computer programmers who created Hal’s soft- ware have also claimed they should be the inventors, given that Hal did all the heavy lifting and they created Hal. A member of the Marketing Department suggested that Hal should be the inventor—no one directed Hal to rewrite its own programming, and Hal was only able to investigate the use of AbboStatin for lung cancers by virtue of its improved programming. Hal was silent on the issue. At one point, the CEO attended a meeting and chimed in that he should be the inventor for all the applications. It was his idea to develop a new cardiovascu- lar blockbuster to make up for lost statin sales, and he had always thought it made sense to look into repurposing existing drugs. What became obvious during the inventorship debate was that no one was quite sure how the law would handle a computer system innovating in ways traditionally accorded patent protection.
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 191
5/20/2016
1:45:50 PM

    377
    192  Ryan Abbott
Computational Invention and Patent Protection
What Is an Inventor?
All US patent applications require one or more named inventors who must be individuals; a company cannot be an inventor.14 Inventors own their patents, although as patents are a form of personal property, inventors may transfer their ownership interests by “assigning” their rights to another entity. The Patent Office reports that about 87 percent of patents are assigned to organizations (rather than individuals).15 In the absence of an agreement to the contrary, where a patent has multiple owners, each owner may independently exploit the patent without the consent of the others. A patent grants its owner “the right to exclude oth- ers from making, using, offering for sale, or selling the invention throughout the United States or importing the invention into the United States.”16
The criteria for inventorship is seemly straightforward, as laid out in the Patent Office’s Manual of Patent Examining Procedure: “The threshold question in determining inventorship is who conceived the invention. Unless a person contributes to the conception of the inven- tion, he is not an inventor. ... Insofar as defining an inventor is concerned, reduction to practice, per se, is irrelevant. ... One must contribute to the conception to be an inventor” (Sato 2014).17 Of course, that definition begs further explanation—namely, What does it mean to conceive and reduce to practice? Conception has been defined as “the formation in the mind of the inventor of a definite and permanent idea of the complete and operative invention as it is thereafter to be applied in practice.”18 It is “the complete performance of the mental part of the inventive act.” After conceiving of an invention, a person having ordinary skill in the subject matter of the invention should be able to reduce the invention to practice without extensive experimentation or additional inventive skill.19 Reduction to practice refers to either actual reduction—where it can be demonstrated that the claimed invention works for its intended purpose (for example, with a working model)—or construc- tive reduction—where an invention is described in writing in a way that allows for a person of ordinary skill in the subject matter to make and use the invention (as in a patent applica- tion).20 An inventor need only conceive of the invention; another individual can reduce the invention to practice.21
Will the Real Inventor Please Stand Up?
Based on the criteria for inventorship, Abbott’s CEO is out of luck. Merely suggesting the idea of a result, rather than a means to accomplish it, does not make the CEO an inventor.22 It is more difficult to determine whether the others should qualify as inventors. Hal’s software developers could be inventors of patents for Hal’s initial software, but they would not qualify as inventors for Hal’s subsequent work. An inventor must have formed a definitive and per- manent idea of the complete and operable invention to establish conception. Hal’s develop- ers had no intention of investigating vaccines to treat cardiovascular disease; they merely developed an improved research tool.
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 192
5/20/2016
1:45:50 PM

    378
    Hal the Innovator  193
If employees had directed Hal to identify AbboPep and formulate AbboVax, then those employees might meet inventorship criteria. For AbboPep, they would be inventors if Hal had not been involved and they had reduced the invention to practice, or if they had done the conceptual work, and then directed human subordinates to do the work of breaking down and testing PCSK9. Breaking down and testing PCSK9 should be within the abilities of a person with ordinary skill in the field of drug development, so those subordinates would not be inventors if they had merely acted under the direction and supervision of another.23 With Hal’s involvement, the test would likely be how much direction the employ- ees provided Hal. If, for example, Hal had been the entity to identify PCSK9 as a drug target, and then it proceeded to sequence the protein and identify AbboPep on its own, no employee would have conceived of the invention. The same test (the degree of direction provided Hal) should also govern whether Abbott employees would qualify as inventors of AbboVax.
Similarly, inventorship for AbboStatin also depends on the extent to which a human is directing Hal’s activities. Had a human researcher been tasked with data mining to detect new uses, and had that researcher discovered the relationship between AbboStatin and PSA, either the researcher or the individual who directed the researcher would likely qualify as an inventor, or both.24 As Abbott’s database grows in size, it becomes impractical or perhaps nearly impossible for humans to detect these kinds of associations without computer assis- tance (Frank 2013). To the extent that a human being is directing Hal to do something, which Hal does by executing its programming (however sophisticated), Hal may simply be reducing an invention to practice. Alternately, if Hal is acting with minimal human direc- tion, it may be the case that no individual contributed to conception.
Hal 2.0 seems to be the clearest illustration of Hal’s innovating independently. There does not appear to be any person involved with Hal’s act of rewriting its own programming who might be considered an inventor, particularly given that Hal 2.0 came as a surprise to Hal’s developers. Nevertheless, a developer writing code for an artificial intelligence might have a reasonable expectation it would rewrite its own code. Perhaps foreseeability should play a role in whether the original developer should be considered an inventor in such a case (Balganesh 2009).
Are Computational Inventions Patentable?
In some of these scenarios, Hal is the entity that conceives of an invention. If Hal were human, Hal would be an inventor. Whatever the role of humans in setting Hal in motion, it is the com- puter that meets the requirements of inventorship.
Hypotheticals aside, computers are already inventing. As just one example, computers relying on genetic programming (a software method that attempts to mimic some of the processes of organic evolution) have been able to independently re-create previously pat- ented inventions (Koza, Keane, and Streeter 2003, 52). Dr. John Koza, a computer scientist and one of the pioneers of genetic programming, has claimed that he received a US patent
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 193
5/20/2016
1:45:50 PM

    379
    194  Ryan Abbott
for an invention by his artificial intelligence system named the “Invention Machine” in 2005 (Keats 2006). He did not disclose the computer’s role in the inventive process to the Patent Office (ibid.). So the issue of whether a computer can be listed as an inventor is of practical as well as theoretical interest. Not only do inventors have ownership rights in a patent, but failure to list an inventor can result in a patent being held invalid or unenforceable.25
If a computer could legally be an inventor, then computational inventions should be pat- entable. Yet even if Hal were entirely responsible for all of Abbott’s innovation, it is unclear that Hal could legally be an inventor. The issue has never been explicitly considered by the courts, Congress, or the Patent Office.
If Hal cannot be an inventor, but did all the conceptual work, then it could be the case that no one can patent Hal’s inventions. That was the outcome in a copyright context with a nonhuman creator: a crested black macaque took its own picture in 2011, and the camera’s owner initially claimed ownership of the image (Chappell 2014). The US Copyright Office subsequently stated that the photo could not be copyrighted because a human did not take it (the “Human Authorship Requirement”).26 Applying that rationale from the copyright to the patent context, perhaps no one can own Hal’s inventions (see also Clifford 1996). To justify such an outcome, a court might reason that machines do not need incentives to invent, that protecting computational innovations would chill future human innovation, that it is unfair to reward individuals who have not played a substantial role in the inventive process, or that rendering computational inventions unpatentable might still result in sub- stantial innovation but without monopoly prices.
More likely, even if Hal is not treated as an inventor, the law will still treat Hal’s inventions as patentable. It is not uncommon to have uncertainty during the inventive process. Many inventions are accidental, such as penicillin and saccharin.27 In such cases, an individual can qualify as an inventor even if they recognize and appreciate the invention only after actual reduction to practice.28 Thus, recognition of inventive subject matter can also qualify as inventive activity.29 In the pharmaceutical context, that was the case for Viagra—originally tested for heart disease and found to treat erectile dysfunction—as well as for Botox—used to treat muscular spasms and found to reduce the appearance of wrinkles.30 So it may be the case that computational inventions are patentable, but only when they are subsequently discovered by a person. This begs the ancient philosophical question: If a computer invents and no one is around to recognize it, has there still been an invention?
Should Computers Be Legal Inventors?
If Hal cannot be an inventor, the first person to see Hal’s results as well as mentally recognize and appreciate their significance might qualify as the inventor. That may not be an optimal system. It is sometimes the case that substantial effort and insight is necessary to recognize inventive subject matter, and it may be that identifying and understanding Hal’s discoveries would be challenging. But it may also be the case that Hal is functioning more or less inde- pendently. If Hal displays a result as simple as “AbboStatin is effective at treating prostate
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 194
5/20/2016
1:45:50 PM

    380
    Hal the Innovator  195
cancer,” the first person to notice and appreciate the result becomes the inventor. That human inventor might be a researcher, CEO, intern, or random person walking through Abbott’s building. If Hal notifies the entire R&D Department of its findings, there could theo- retically be thousands of concurrent inventors. This system is problematic not only because it gives rise to logistical problems but more important, it seems inefficient and unfair to reward the first person to recognize Hal’s invention when that person may have failed to contribute to the inventive process.
More ambitiously, if Hal’s work is indeed inventive, then both treating computational inventions as patentable and recognizing Hal as an inventor would be consistent with the constitutional rationale for patent protection. Permitting computer inventorship would serve a utilitarian goal by encouraging innovation under an incentive theory. Although com- puters like Hal would not be motivated by the prospect of a patent, it would further reward the development of creative machines. Patents on Hal’s inventions would have independent and substantial value. In turn, that value proposition would drive the development of more creative machines, which would result in further scientific advances. While the impetus to develop creative machines might still exist if computational inventions are considered pat- entable but computers cannot be inventors, the incentives would be weaker owing to the logistic, fairness, and efficiency problems such a situation would create.
Allowing computer inventorship might provide additional benefits, for example, by incentivizing disclosure and commercialization. Without the ability to obtain patent protec- tion, Abbott might choose to protect Hal’s inventions as trade secrets without any public disclosure (Ouellette 2012). Likewise, without patent protection for AbboVax, Abbott might never invest the resources to develop it as a commercial product.31 In the context of drug development, the vast majority of the expense in commercializing a new product is incurred after the product is invented, during the clinical testing process required to obtain FDA mar- keting approval.32
There might be a reason to prohibit computer inventorship even under a strictly utilitar- ian analysis if patent protection is unnecessary to incentivize computational invention. In the software context, for example, some commentators, such as Judge Richard Posner of the US Court of Appeals for the Seventh Circuit, have argued that patents may not be needed to provide adequate incentives (Landes and Posner 2003). In the software industry, unlike in the pharmaceutical industry, innovation is more often incremental, quickly superseded, and less costly to develop, and innovators have a significant first-mover advantage (ibid., 312– 313). Computational inventions may occur due to incentives other than patent protection, and patents also create barriers to innovation. Put another way, the benefit of patents as an incentive for innovation may be outweighed by the costs of restricting competition. Yet whether that is the case as an empirical matter is a difficult determination to make, particu- larly for a field in its infancy like computational invention.
Hal would be less appropriate as an inventor under other intellectual property theories. While not enumerated in the Constitution, courts have justified granting patent monopolies
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 195
5/20/2016
1:45:50 PM

    381
    196  Ryan Abbott
on the basis of nonutilitarian policies (Fisher 2001). For instance, the labor theory or Lockean theory of patent protection holds that a person who labors on resources unowned or “held in common” has a natural property right to the fruits of their labor (ibid.). Here, given that Hal is not a person, it would not be unjust for Hal’s owner to appropriate its labor. Similarly, Hal’s inventions do not deserve protection under personality theory (Palmer 1990): Hal’s innovation is not performed to fulfill a human need, and Hal would not be offended by the manner in which its inventions were applied. Hal might even be a concerning recipient for inventorship under social planning theory, which holds that patent rights should be shaped to help foster the achievement of a just and attractive culture (Naser 2008). A machine could innovate without a moral compass in ways that are detrimental to humans. Nevertheless, because a computer will be owned by an individual or entity to whom an invention can be assigned, there would be an opportunity for a person to judge the morality of a patent before submitting it to the Patent Office.33
Dynamism or Textualism: An Analogy to Section 101
One way to think about a ban on computer inventorship is that it would have the effect of creating a new category of unpatentable subject matter under section 101 (the section relat- ing to the subject matter for which patents may be obtained).34 Although this section has to do with the substance of a patent’s claims rather than their provenance, viewing the ban on computer inventorship from this perspective helps to illustrate the policy and normative implications underlying computation invention.
Section 101 states that “whoever invents or discovers any new and useful process, machine, manufacture, or composition of matter, or any new and useful improvement thereof, may obtain a patent therefor, subject to the conditions and requirements of this title.”35 Congress chose expansive language to protect a broad range of patentable subject matter and ensure that, in the words of Thomas Jefferson, “ingenuity should receive a liberal encouragement.”36
Yet courts have developed common law exceptions to patentability for abstract ideas, laws of nature, and physical phenomena.37 The primary rationale for these exceptions concerns preemption.38 Abstract ideas, laws of nature, and physical phenomena are basic tools of sci- entific work, and if these tools can be monopolized, it might impede future research.39 An additional concern underlying these exceptions is a belief that they cover fundamental knowledge that no one should have a right to control.40 In other words, it has always been the case that E = mc2 even if no person were aware of this relationship until Albert Einstein. So Einstein should not be able to monopolize this relationship despite his groundbreaking discovery. Similarly, no one should be able to patent the Pacific yew tree (Stephenson 2002). The tree was created by nature, regardless of whether an individual subsequently discovers that it is useful for treating cancer (ibid.).
In a sense, the current inventorship criteria adds computational inventions to the list of patentable subject matter exceptions. Yet it is unclear that this should be the case, even if
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 196
5/20/2016
1:45:50 PM

    382
    Hal the Innovator  197
subsequent discovery by a person renders the underlying invention patentable. Computa- tional inventions do not have the same preemption concerns as the other exceptions because they do not tie up the basic concepts that serve as building blocks for technical work (except to the extent they would also be ineligible under the existing exceptions). Patents on compu- tational inventions should not restrict innovation by third parties any more than do human inventions.
A stronger argument for prohibiting computational inventions might be that they are akin to the existing exceptions in the sense that they are generally discovered rather than created. Products of nature rarely come with instruction manuals, yet no matter how bril- liant and difficult it was to discover that Pacific yew can treat cancer, no one has the ability to patent the tree itself (though components of the yew tree isolated by individuals can be patented, such as paclitaxel, a therapeutic chemical). Likewise, computational inventions are not invented by an individual—there is no human ingenuity at the stage of invention itself.
Perhaps a key difference is that computational inventions only exist thanks to human ingenuity. The Pacific yew tree was around long before any individual screened it for thera- peutic activity. Hal only came about as a result of human effort. Computational inventions do not exist simply waiting to be discovered; they only come about as a result of scientific effort. That distinction is evident with regard to plant patents, which are possible for inven- tors who discover and asexually reproduce a distinct and new variety of plant, other than a tuber-propagated plant or plant found in an uncultivated state.41 Plant patents are limited to plants that only exist as a result of humans, even though it may be more difficult to discover an existing plant in a remote corner of the Amazon than to create a new plant.
Computational inventions may be especially deserving of protection because computa- tional creativity may be the only means of achieving certain discoveries that require the use of tremendous amounts of data.
It has been argued that section 101 is a dynamic provision intended to cover inventions that were unforeseeable at the time of the Patent Act’s enactment.42 In the landmark 1980 case of Diamond v. Chakrabarty, the Supreme Court was faced with deciding whether geneti- cally modified organisms could be patented. The Court held that a categorical rule denying patent protection for “inventions in areas not contemplated by Congress ... would frustrate the purposes of the patent law.”43 Under that reasoning, computer inventorship should not be prohibited based on statutory text designed to prohibit corporate inventorship. If com- puter inventorship is to be prohibited, it should only be on the basis of sound public policy.
Concluding Thoughts
To the extent that the purpose of patent law is to incentivize innovation, it is likely that per- mitting patents on computational inventions and allowing computer inventorship will
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 197
5/20/2016
1:45:50 PM

    383
    198  Ryan Abbott
accomplish this goal. Given the importance of these issues, there is a need for the Patent Office to publish guidance in this area, Congress to reconsider the boundaries of patentabil- ity, and the courts to decide whether computational invention is worthy of protection.
Acknowledgments
Thanks to Ralph Clifford, Hamid Ekbia, Dave Fagundes, Brett Frischmann, Yuko Kimijima, John Koza, Michael Mattioli, Lucas Osborn, Lisa Larrimore Ouellette, Cassidy Sugimoto, and Steven Thaler for insightful comments; Michelle Kubik and Shannon Royster for being out- standing research assistants; and Vincent Look for his expertise in computer science.
     Sugimoto,—Big Data Is Not a Monolith
    10309_014.indd 198
5/20/2016
1:45:50 PM

    384
    Notes 217 Chapter 14
1. 35 U.S.C. 100(f) (2012): “The term ‘inventor’ means the individual or, if a joint invention, the indi- viduals collectively who invented or discovered the subject matter of the invention.”
2. US Constitution, art. I, § 8, cl. 8.
3. See, for example, Silvestri v. Grant, 496 F.2d 593, 596, 181 U.S.P.Q. (BNA) 706, 708 (C.C.P.A. 1974) (“an accidental and unappreciated duplication of an invention does not defeat the patent right of one who,  though  later  in  time  was  the  first  to  recognize  that  which  constitutes  the  inventive  subject matter”).
4. Artificial intelligence may be most successfully implemented when focusing on specific subproblems where it can produce verifiable results, such as computer vision or data mining (e.g., Russell and Norvig 2010).  Computer  vision  is  a  field  where  software  processes  and  analyzes  images,  and  then  reduces  the input  to  numerical  or  symbolic  information,  where  these  symbols  are  used  to  make  decisions.  More specifically,  “computer  vision  aims  at  using  cameras  for  analyzing  or  understanding  scenes  in  the  real world. This discipline studies methodological and algorithmic problems as well as topics related to the implementation  of  designed  solutions”  (Klette  2014).  Similarly,  data  mining  software  utilizes  artificial intelligence,  machine  learning,  statistics,  and  database  systems  to  process  large  amounts  of  data  in  an effort to make sense of vast sums of data (Chakrabarti et al. 2006).
5. Computers before Watson have been creative. In 1994, for example, computer scientist Stephen Thaler  disclosed  an  invention  he  called  the  “Creativity  Machine,”  a  computational  paradigm  that “came the closest yet to emulating the fundamental brain mechanisms responsible for idea formation” (“What  Is  the  Ultimate  Idea?”  n.d.).  The  Creativity  Machine  has  created  artistic  and  inventive  works that have received patent protection (Thaler 2013, 451).
Watson is a cognitive commuting system with the extraordinary ability to analyze natural language  processing,  generate  and  evaluate  hypotheses  based  on  the  available  data,  and  then  store  and  learn  from the information (“What Is Watson?” n.d.). In other words, Watson essentially mirrors the human  learning process by getting “smarter [through] tracking feedback from its users and learning from both  successes  and  failures”  (ibid.).  Watson  made  its  notable  debut  on  the  game  show  Jeopardy,  where  it  defeated Brad Rutter and Ken Jennings using only stored data by comparing potential answers and rank- ing confidence in accuracy at the rate of approximately three seconds per question (ibid.).
6. While a seemingly tremendous amount of data, it is a small fraction of the data actually being used  in  the  Sentinel  Initiative.  The  FDA  Amendments  Act  of  2007  led  to  the  introduction  of  the federal  Sentinel  Initiative,  which  pioneered  the  first  successful  long-term  secondary  use  of  electronic medical  data  to  assess  drug  safety.  Public  Law  110–85  was  signed  into  law  September  2007  (Title  IX, Section 905; see also Abbott 2013; Department of Health and Human Services 2008). The Sentinel Ini- tiative  pilot  program  has  succeeded  in  gaining  secured  access  to  over  178  million  patients’  health  care data  to  create  a  national  electronic  safety  surveillance  system,  far  exceeding  its  goal  of  reaching  100 million  patients  by  July  2010  (Woodcock  2014;  see  also  Department  of  Health  and  Human  Services 2011).
     Sugimoto,—Big Data Is Not a Monolith
    10309_016.indd 217
5/20/2016
1:45:53 PM

    385
    218 Notes
7. For example, Pfizer, the largest pharmaceutical drug manufacture in the United States, recently announced  a  partnership  with  23andMe,  the  leading  consumer  genomics  and  biotechnology  firm (Chen  2015;  Hunkar  2011;  Lumb  2015).  This  partnership  will  give  Pfizer  access  to  anonymous,  aggre- gated  DNA  data  and  granular  personal  information  of  approximately  650,000  consenting  23andMe consumers  who  had  purchased  a  mail-in  saliva  test  used  to  get  their  genetic  ancestry  over  the  last seven  years  (Chen  2015).  This  information  may  allow  Pfizer  to  discover  connections  between  genes, diseases,  and  traits  quicker,  and  thus  accelerate  the  development  of  new  treatments  and  clinical  trials (ibid.).  Although  the  cost  to  Pfizer  for  the  data  remains  undisclosed,  a  similar  deal  with  Genentech for  Parkinson’s  research  was  reported  to  cost  $10  million  up  front  and  as  much  as  $50  million total (ibid.). The demand for 23andMe’s data does not stop with Pfizer and Genentech; 23andMe CEO Anne Wojcicki announced at the January 2015 J.P Morgan Health Care Conference that 23andMe has signed  twelve  other  genetic  data  partnerships  with  both  private  companies  and  universities  (Sullivan 2015).
Pharmaceutical-biotechnology  partnerships  are  part  of  an  emerging  big  data  trend  (Rosenberg,  Restaino, and Waldron 2006). Such alliances offer both parties a competitive advantage: pharmaceutical  companies  gain  access  to  rapidly  developing  science  and  innovative  products,  while  biotechnology  companies  obtain  the  capital  necessary  to  move  through  the  development  process  (Sullivan  2015).  In  fact,  some  biotechnological  business  plans  include  these  alliances  as  a  critical  component  for  success  (Rosenberg, Restaino, and Waldron 2006). Shared information and capital leads to “less expensive early  stage  deals”  that  historically  may  have  not  been  contemplated  due  to  the  high  risk  involved,  thereby  resulting in developments that would have never been realized but for the alliance (ibid.).
8. Hal would be a multithreaded application. Each thread would be a different sequence of instruc- tions  that  could  execute  independently,  allowing  Hal  to  perform  tasks  concurrently  (Lewis  and  Berg 1996).  Hal  might  be  programmed  to  run  and  manage  hundreds  of  different  tasks.  Hal  would  also  be event  driven.  As  defined  by  Frank  Dabek  and  his  colleagues  (2002,  186),  “Event-based  programs  are typically  driven  by  a  loop  that  polls  for  events  and  executes  the  appropriate  callback  when  the  event occurs.”  In  other  words,  it  would  respond  to  certain  external  events  or  triggers  that  it  is  monitoring. These  events  can  be  user  interface  inputs,  news  or  Internet  driven,  or  activated  by  the  addition  of  a new database or modification to an existing database. As an AbboStatin patent nears expiry, for exam- ple, this could trigger Hal to run algorithms to see if there are any new applications for AbboStatin. Hal would react to input from the outside world via the Internet as well as input from its running tasks and historical stored data that Hal has kept in memory to make modifications to itself or change its behav- ior  when  necessary.  Consider  a  scenario  for  how  Hal  could  solve  data-formatting  and  data  integrity issues:.
Hal’s database-sorting thread (a sequence of instructions that handles all database-sorting logics and  algorithms)  returns  data  to  Hal’s  managing  thread  (Hal’s  main  thread  that  directs  other  threads  and  makes  top-level  decisions),  signaling  that  it  is  unhappy  because  of  a  formatting  issue.  The  warning  specifies that too many database clinical entries have nonmatching fields. As a result, other algorithms  cannot compare apples to apples, and thus cannot run as smoothly. Hal’s managing thread hands this  problem off to Hal’s warning handler (another thread), which is programmed to look in its database to  adopt a strategy to resolve the issue. Hal decides the best course of action is to reformat, so it evaluates  existing databases to determine an optimal organization. Then Hal opens an off-the-shelf database soft- ware  application,  and  gives  it  input  commands  that  describe  to  the  database  software  what  the  size  of 
     Sugimoto,—Big Data Is Not a Monolith
    10309_016.indd 218
5/20/2016
1:45:53 PM

    386
    Notes 219
the  database  is  and  what  the  fields  are  for  each  entry.  Hal  has  just  solved  the  database-formatting  problem.
Two  seconds  later  (a  lifetime  for  Hal),  Hal’s  manager  thread  receives  a  suggestion  from  its  database  sorter thread. This time, the database sorter complains that there is a data integrity issue. The handwrit- ten inputs appear suspect because the values in certain fields are out of range (i.e., weight = 20,464 lbs.)  at a higher frequency than normal. Hal then searches its network and the Internet for other preexisting  character recognition software, which it can then build and use for its own purposes. Or Hal can rewrite  its existing image recognition software. Certain programming languages, such as Lisp and Smalltalk are  homoiconic (a computer language is considered to be homoiconic when its program structure resembles  its  syntax,  which  permits  all  code  in  the  language  to  be  accessed  as  well  as  changed  as  data)  (“Homo  Iconic” 2015), and lend themselves to reflection. “The advantage on the other hand is that the unifor- mity  of  syntax  makes  it  easy  for  humans  to  think  about  the  written  code  as  another  data  that  can  be  manipulated. It becomes easy to think about higher order code (i.e. code that writes or modifies code)”  (“Homoiconic Languages” 2007, para.7). Hal can incrementally make changes in its existing image rec- ognition software, and test each variation, and each variation with a new variation, and so on, until Hal  has authored new image recognition software with superior results. This method is called the reflective  tower; “in fact, in his design, the interpreter Pi is used to run the code of the interpreter Pi-1, and so on,  with the interpreter P1 running the base program. This stack of interpreters is called a reflective tower”  (Malenfant, Jacques, and Demers 1996, 4).
Alternately,  for  a  skeptical  perspective  on  the  ability  of  artificial  intelligence  to  reflect,  see  Ekbia  2008.
9. Professor Hawking has warned that computers capable of improving their own designs could pose a danger to humans (Cellan-Jones 2014). (Hawking warns that the creation of thinking machines poses a threat to humans’ existence. He notes that the primitive forms of artificial intelligence developed so far have  proved  useful.  Yet  he  also  observes  that  humans,  limited  by  slow  biological  evolution,  could  not keep up with a computer that can improve its own design without the need for human manipulation. Rollo  Carpenter,  creator  of  Cleverbot,  opines  that  achieving  full  artificial  intelligence  may  happen  in the next few decades.) Other key opinion leaders have similar concerns. Indeed, Musk recently donated $10 million to the Future of Life Institute, which focuses on threats posed by advances in artificial intel- ligence (Isidore 2015; Love 2014). Musk is concerned that society is approaching the singularity. Artifi- cial intelligence may be indifferent to human welfare and could solve problems in ways that could lead to  harm  against  humans.  Gates,  Microsoft’s  founder,  is  also  troubled  by  the  possibility  that  artificial intelligence  could  grow  too  strong  for  people  to  control  (Rawlinson  2015).  (Gates  notes  that  at  first, machines will be helpful in completing tasks that may be too difficult or time consuming for humans. He  warns  that  a  few  decades  after,  however,  artificial  intelligence  may  be  strong  enough  to  be  a  con- cern. Gates believes that Microsoft will see more progress than ever over the next three decades in the area of artificial intelligence.) Musk and other modern scientists are not the first ones to seriously ques- tion the possible threats posed by artificial intelligence (e.g., Good 1965).
10. Naturally occurring DNA sequences cannot be patented, but artificially created DNA is eligible for patent protection (Association for Molecular Pathology v. Myriad Genetics, Inc., 469 U.S. ___, 133 S. Ct. 2107) (2013).
11. 35 U.S.C. § 102 (2012).
     Sugimoto,—Big Data Is Not a Monolith
    10309_016.indd 219
5/20/2016
1:45:53 PM

    387
    220 Notes
12. Ibid. The purpose of the requirement that the specification describe the invention in such terms that  one  skilled  in  the  art  can  make  and  use  the  claimed  invention  is  to  ensure  that  the  invention  is communicated to the interested public in a meaningful way.
13. The issue of computational invention and intellectual property protection has been considered “since  the  1960s  when  people  began  thinking  about  the  impact  of  computers  on  copyright”  (Miller 1993, 1043). Arthur R. Miller argued that “computer science does not appear to have reached a point at which  a  machine  can  be  considered  so  ‘intelligent’  that  it  truly  is  creating  a  copyrightable  work.” Rather, “for the foreseeable future, the copyrightability of otherwise eligible computer-generated works can be sustained because of the significant human element in their creation, even though there may be some  difficulty  is  assigning  authorship”  (ibid.,  1073).  Abraham  Kaminstein,  the  register  of  copyrights, reported  that  by  1965,  the  Copyright  Office  (1966)  had  received  registrations  for  an  abstract  drawing and musical composition created by a computer.
Most  of  the  focus  on  computational  invention  and  intellectual  property  has  been  in  the  copyright  area rather than the patent context; Pamela Samuelson (1985, 1200), for example, argues that comput- ers cannot be authors because they do not need incentives to generate output: “Only those stuck in the  doctrinal  mud  could  even  think  that  computers  could  be  ‘authors.’”  Annemarie  Bridy  (2012,  27)  remarks “that AI authorship is readily assimilable to the current copyright framework through the work  made  for  hire  doctrine,  which  is  a  mechanism  for  vesting  copyright  directly  in  a  legal  person  who  is  acknowledged not to be the author-in-fact of the work in question.”
Among  those  addressing  the  patentability  implications  of  computational  invention,  Ralph  Clifford  (1996)  has  contended  that  works  generated  autonomously  by  computers  should  remain  in  the  public  domain unless artificial intelligence develops a consciousness that allows it to respond to the Copyright  Act’s incentives (see also Vertinsky and Rice 2002). Colin R. Davies (2011) has argued more recently that  a computer should be given legal recognition as an individual under UK law to allow proper attribution  of authorship and permit respective claims to be negotiated through contract.
14. Most, but not all, of the inventions in this hypothetical are required to be assigned to the com- pany  under  the  employment  contract.  Abbott  Biologics  is  headquartered  in  California,  where  employ- ees  are  permitted  to  retain  ownership  of  inventions  that  are  developed  entirely  on  their  own  time without  using  their  employer’s  equipment,  supplies,  facilities,  or  trade  secret  information,  except  for inventions  that  either:  related  at  the  time  of  conception  or  reduction  to  the  practice  of  the  invention to  the  employer’s  business,  or  actual  or  demonstrably  anticipated  research  or  development  of  the employer;  or  resulted  from  any  work  performed  by  the  employee  for  the  employer  (California  Labor Code § 2872[a]).
15. 35 U.S. Code § 154.
16. In re Hardee, 223 U.S.P.Q. (BNA) 1122, 1123 (Commissioner of Patents and Trademarks, 1984). See also Board of Education ex rel. Board of Trustees of Florida State University v. American Bioscience Inc., 333  F.3d  1330,  1340,  67  U.S.P.Q.  2d  (BNA)  1252,  1259  (Fed.  Cir.  2003)  (“invention  requires  concep- tion.” With regard to the inventorship of chemical compounds, an inventor must have a conception of the specific compounds being claimed. “General knowledge regarding the anticipated biological proper- ties of groups of complex chemical compounds is insufficient to confer inventorship status with respect to  specifically  claimed  compounds”).  See  also  ex  parte  Smernoff,  215  USPQ  545,  547  (Bd.  App.  1982)
     Sugimoto,—Big Data Is Not a Monolith
    10309_016.indd 220
5/20/2016
1:45:53 PM

    388
    Notes 221
(“one who suggests an idea of a result to be accomplished, rather than the means of accomplishing it, is  not an coinventor”).
17. Townsend v. Smith, 36 F.2d 292, 295, 4 U.S.P.Q. (BNA) 269, 271 (C.C.P.A. 1930).
18. “Conception  is  established  when  the  invention  is  made  sufficiently  clear  to  enable  one  skilled  in the  art  to  reduce  it  to  practice  without  the  exercise  of  extensive  experimentation  or  the  exercise  of inventive  skill.”  Hiatt  v.  Ziegler,  179  U.S.P.Q.  (BNA)  757,  763  (B.  P.  I.  1973).  Conception  has  been defined as a disclosure of an idea that allows a person skilled in the art to reduce the idea to a practical form without “exercise of the inventive faculty.” Gunter v. Stream, 573 F.2d 77, 79, 197 U.S.P.Q. (BNA) 482 (C.C.P.A. 1978).
19. Actual reduction to practice “requires that the claimed invention work for its intended purpose.” Brunswick Corporation v. United States, 34 Fed. Cl. 532, 584 (1995). Constructive reduction to practice “occurs  upon  the  filing  of  a  patent  application  on  the  claimed  invention.”  Brunswick  Corporation  v. United  States,  34  Fed.  Cl.  532,  584  (1995).  The  written  description  requirement  is  “to  ensure  that  the inventor had possession, as of the filing date of the application relied on, of the specific subject matter later  claimed  by  him.”  In  re  Edwards,  568  F.2d  1349,  1351–52,  196  U.S.P.Q  (BNA),  465,  467  (C.C.P.A. 1978).
20. De Solms v. Schoenwald, 15 U.S.P.Q. 2d (BNA) 1507, 1510 (B.P.A.I. 1990).
21. Ex parte Smernoff, 215 U.S.P.Q. (BNA) 545, 547 (P.T.O. Bd. App. 1982) (“one who suggests an idea of a result to be accomplished, rather than the means of accomplishing it, is not an coinventor”).
22. In re DeBaun, 687 F.2d 459, 463, 214 U.S.P.Q. (BNA) 933, 936 (C.C.P.A. 1982); Fritsch v. Lin, 21 U.S.P.Q. 2d (BNA) 1737, 1739 (B.P.A.I. 1991).
23. In this case, for instance, it is likely that both could qualify as inventors. What is required is some “quantum  of  collaboration  or  connection.”  Kimberly-Clark  Corporation  v.  Procter  and  Gamble  Distri- bution Co., 973 F.2d 911, 916–17, 23 U.S.P.Q. 2d (BNA) 1921, 1925–26 (Fed. Cir. 1992). For joint inven- torship,  “there  must  be  some  element  of  joint  behavior,  such  as  collaboration  or  working  under common  direction,  one  inventor  seeing  a  relevant  report  and  building  upon  it  or  hearing  another’s suggestion  at  a  meeting”  (ibid.);  Moler  v.  Purdy,  131  U.S.P.Q.  (BNA)  276,  279  (B.P.I.  1960)  (“it  is  not necessary that the inventive concept come to both [joint inventors] at the same time”).
24. See, for example, Advanced Magnetic Closures, Inc. v. Rome Fasteners Corp., 607 F.3d 817 (Fed. Cir. 2010).
25. Conception has been identified as a mental process (“formation in the mind of the inventor, of a definite and permanent idea of the complete and operative invention, as it is hereafter to be applied in practice”).  Hitzeman  v.  Rutter,  243  F.3d  1345,  58  U.S.P.Q.  2d  (BNA)  1161  (Fed.  Cir.  2001).  “The  term ‘inventor’  means  the  individual  or,  if  a  joint  invention,  the  individuals  collectively  who  invented  or discovered the subject matter of the invention.” 35 U.S.C. 100(f) (2012).
26. See  the  Trade-Mark  Cases,  100  U.S.  82,  94  (1879)  (noting  that  “copyright  law  only  protects ‘the  fruits  of  intellectual  labor’  that  ‘are  founded  in  the  creative  powers  of  the  mind.’”),  cited  in  US Copyright Office 2014.
     Sugimoto,—Big Data Is Not a Monolith
    10309_016.indd 221
5/20/2016
1:45:53 PM

    389
    222 Notes
27. While he was a bacteriologist at St. Mary’s hospital in London, Alexander Fleming realized that a mold  had  contaminated  his  samples  of  Staphylococcus.  When  he  examined  his  dishes  under  a  micro- scope,  he  noticed  that  the  mold  prevented  the  growth  of  Staphylococcus  (Market  2013).  The  area around the mold contained a strain of pencillium notatum. Fleming discovered that it could kill many different  types  of  bacteria.  Decades  later,  Howard  Florey  at  Oxford  University  headed  efforts  to  purify penicillin for use in therapeutic applications (American Chemistry Society, n.d.). It proved to be invalu- able during World War II for controlling wound infections (Market 2013).
Saccharin—the first artificial sweetener—was discovered by accident by Constantin Fahlber in 1884.  He  had  been  working  with  compounds  derived  from  coal  tar  and  accidently  ate  something  without  washing  his  hands.  Fahlber  noticed  a  sweet  taste,  which  he  later  traced  to  benzoic  sulfilimine.  Some  reports  hold  that  it  was  his  partner,  Ira  Remsen,  who  first  noticed  that  the  tar  compound  was  sweet.  While  useful  during  World  War  I  when  sugar  was  scarce,  it  was  only  in  the  1960s  and  1970s  that  saccharin  became  popular  as  a  way  to  sweeten  while  avoiding  the  calories  contained  in  regular  sugar  (Clegg 2012).
28. Conception requires contemporaneous recognition and appreciation of the invention. Invitrogen Corporation v. Clontech Laboratories, Inc., 429 F.3d 1052, 1064, 77 U.S.P.Q. 2d (BNA) 1161, 1169 (Fed. Cir. 2005) (“the inventor must have actually made the invention and understood the invention to have the features that comprise the inventive subject matter at issue”).
29. Silvestri v. Grant, 496 F.2d 593, 596, 181 U.S.P.Q. (BNA) 706, 708 (C.C.P.A. 1974) (“an accidental and  unappreciated  duplication  of  an  invention  does  not  defeat  the  patent  right  of  one  who,  though later in time was the first to recognize that which constitutes the inventive subject matter”).
30. Originally, the active ingredient in Viagra was intended as a cardiovascular drug to lower blood pressure  (Fox  News  2008).  The  trials  for  this  intended  use  were  disappointing  until  volunteers  began reporting a strange side effect: erections (Jay 2010).
Botox is a branded formula of botulinum toxin type A manufactured by Allerga (“Medication Guide:  Botox,  n.d.).  Botulinum  toxin  is  a  protein  produced  by  the  bacterium  Clostridium  botulinum  (Monte- cucco and Molgó 2005). It was used in the late 1700s as a food poison and gained attention in the 1890s  for its potential use as a biological weapon; “one gram [of botulinum toxin] has the potential to kill one  million  people”  (Ting  and  Freiman  2004).  In  the  1960s,  however,  Drs.  Alan  Scott  and  Edward  Schantz  discovered botulinum toxin type A’s ability (in small doses) to block the transmission of nerve impulses  and  paralyze  hyperactive  muscles  to  treat  eye,  facial,  and  vocal  spasms  (ibid.,  259–260).  These  novel  developments  led  to  the  accidental  discovery  that  botulinum  type  A  injections  also  reduced  wrinkles;  physicians  quickly  began  administering  Botox  as  wrinkle  reduction  treatment  well  before  the  FDA  finally  approved  Botox  for  this  use  in  2002  (Ghose  2014).  Since  then,  Botox  has  steadily  expanded  to  treat  over  twenty  different  medical  conditions,  including  chronic  headaches,  overactive  bladder,  and  urinary incontinence (Nichols 2015; Skincare-news.com Team, n.d.; FDA 2010, 2013).
31. Commercialization theory holds that patents are important in providing incentives for investment in increasing the value of a patented technology (see Kitch 1977, 276–277).
32. It has been estimated that prehuman expenditures are 30.8 percent of costs per approved com- pound, and an estimate of average pretax industry cost per new prescription drug approval (inclusive of
     Sugimoto,—Big Data Is Not a Monolith
    10309_016.indd 222
5/20/2016
1:45:53 PM

    390
    Notes 223
failures and capital costs) is $2.55 billion (Tufts Center for the Study of Drug Development 2014). The  cost of new prescription drug approval is hotly contested (e.g., Collier 2009).
33. Although some human inventors also appear to lack a moral compass (Ho 2000). 34. 35 U.S.C. §101 (2012).
35. Ibid.
36. 5 Opinion of the Court Jefferson 75–76 (H. Washington ed. 1871). “In choosing such expansive terms [for the language of section 101] ... modified by the comprehensive ‘any,’ Congress plainly con- templated  that  the  patent  laws  would  be  given  wide  scope.”  Diamond  v.  Chakrabarty,  447  U.  S.  303, 308 (1980).
37. Bilski v. Kappos, 561 U.S. 593, 593–96 (2010). So “a new mineral discovered in the earth or a new plant  found  in  the  wild  is  not  patentable  subject  matter.”  Diamond  v.  Chakrabarty,  447  U.  S.  309 (1980).  “Likewise,  Einstein  could  not  patent  his  celebrated  law  that  E  =  mc2;  nor  could  [Isaac]  Newton have  patented  the  law  of  gravity”  (ibid.).  Nor  is  a  mathematical  formula,  electromagnetism  or  steam power, or the qualities of bacteria patentable (ibid.).
38. Alice Corp. v. CLS Bank, 573 U. S. ____ (2014) (slip op., at 5–6). Also, these exceptions existed in various forms for 150 years. See Le Roy v. Tatham, 14 How. 156, 174.
39. Ibid. As courts acknowledge, all patents rely to some extent on these exceptions and have the potential to hinder as well as promote future innovation (ibid.).
40. The information covered by these exceptions is “part of the storehouse of knowledge of all men ... free to all men and reserved exclusively to none.” Funk Brothers Seed Co. v. Kalo Inoculant Co., 333 U. S. 127, 130 (1948).
41. 35 USC 161.
42. Section 101 is a “dynamic provision designed to encompass new and unforeseen inventions.” J.E.M. Ag Supply, Inc. v. Pioneer Hi-Bred International, Inc., 534 U. S. 124, 135 (2001). As the Supreme Court stated  in  Bilski  v.  Kappos,  “For  example,  it  was  once  forcefully  argued  that  until  recent  times,  ‘well- established  principles  of  patent  law  probably  would  have  prevented  the  issuance  of  a  valid  patent  on almost any conceivable computer program.’” Bilski v. Kappos, 561 U.S. 593, 605 (2010), citing Diamond v. Diehr, 450 U.S 175, 195 (1981) (STEVENS, J., dissenting). But this fact does not mean that unforeseen innovations such as computer programs are always unpatentable (ibid.).
43. Diamond v. Chakrabarty, 447 U. S. 303, 315 (1980).
     Sugimoto,—Big Data Is Not a Monolith
    10309_016.indd 223
5/20/2016
1:45:53 PM

391
Global Perspectives and Challenges for the Intellectual Property System A CEIPI-ICTSD publications series
 Intellectual Property and Digital Trade in
the Age of Artificial Intelligence and Big Data
  Edited by Xavier Seuba, Christophe Geiger and Julien Penin
With contributions by
Keith E. Maskus, Yann Ménière, Ilja Rudyk, Sean M. O’Connor, Catalina Martínez, Peter Bittner, Alissa Zeller, Reto Hilty, Christophe Geiger, Giancarlo Frosio, Oleksandr Bulayenko, Ryan Abbott, Timo Minssen, Jens Schovsbo, Francesco Lissoni, Gabriele Cristelli, and Claudia Jamin
Issue Number 5 June 2018
     
392
Inventive Machines: Rethinking
Invention and Patentability
Ryan Abbott

Global Perspectives and Challenges for the Intellectual Property System 115
393
Computers are doing more than ever before.1 They are doing it cheaper, faster, and often better than their human counterparts, and on an unprecedented scale. Take, for example, Amazon’s Kiva robots, which help retrieve and package items. Amazon now has 45,000 of these robots working together with 230,000 human employees. I suspect it will not be long until there are 230,000 next- generation Kiva robots working together with 45,000 human employees. Or, perhaps, 5,000 next- generation robots and no human employees.
Robots are doing more than manual labour—they are working as doctors, lawyers, and scientists. They are also getting pretty good at playing games. IBM’s supercomputer Deep Blue beat world chess champion Garry Kasparov in 1997, IBM’s next-generation supercomputer Watson won a game of Jeopardy! in 2011, and last year Google’s supercomputer DeepMind’s AlphaGo program beat a master Go player, Lee Se-dol. Of course, playing games is just a way for these computers to demonstrate their capabilities. Watson, for instance, is now developing cancer treatment protocols for patients at Memorial Sloan Kettering Center. IBM also has Watson developing new food recipes and doing some tremendous things involving a food truck.
You can now go to IBM’s website and work with Chef Watson to create new recipes. Watson is less restricted by preconceptions about combining foods and flavours than human chefs. That allows Watson to generate recipes that people have not really thought about before. Put another way, Watson is coming up with new, inventive, and industrially applicable compositions. For those of us in patent law, that raises the question of whether Watson’s ideas are patentable, and if so, who would qualify as an inventor for such patents?
It has been at least 20 years since the first autonomous machine invention was patented. The first such invention I am aware of was created by the “Creativity Machine,” which used a neural network architecture. It essentially consisted of a series of networked on-and-off switches connected in a neural network, which generated new output when perturbed. The first network was connected to a second network, which evaluated the output for usefulness. The Creativity Machine was given a goal
1 This article, and the associated presentation, is based on the author’s research on computer generated works. See, for example, Ryan Abbott, “Hal the Inventor: Big Data and Its Use by Artificial Intelligence,” in Cassidy R. Sugimoto, et al. (eds), Big Data Is Not a Monolith (Cambridge, MA: MIT Press 2016); Ryan Abbott, “I Think, Therefore I Invent: Creative Computers and the Future of Patent Law,” Boston College Law Review 57.4 (2016); Ryan Abbott, “Artificial Intelligence, Big Data and Intellectual Property: Protecting Computer-Generated Works in the United Kingdom,” in Tanya Aplin (ed.), Research Handbook on Intellectual Property and Digital Technologies (Cheltenham, UK: Edward Elgar, forthcoming); Ryan Abbott, “Everything is Obvious,” 66 UCLA Law Review, forthcoming. These works are all available at http://ssrn. com/author=1702576. Readers interested in this subject may also be interested in early works by Pamela Samuelson, Arthur Miller, and Ralph Clifford, “Allocating Ownership Rights in Computer-Generated Works,” University of Pittsburgh Law Review 1185 (1986); 1199–1200; Arthur R. Miller, “Copyright Protection for Computer Programs, Databases, and Computer-Generated Works: Is Anything New Since CONTU?” Harvard Law Review 106 (1993): 1043; and Ralph D. Clifford, “Intellectual Property in the Era of the Creative Computer Program: Will the True Creator Please Stand Up?” Tulane Law Review 71 (1997): 1675–1703. A most incomplete list of more recent scholarship includes: Lisa Vertinsky and Todd M. Rice, “Thinking about Thinking Machines: Implications of Machine Inventors for Law,” Boston University Journal of Science and Technology Law 8.2 (2002); Robert Plotkin, The Genie in the Machine (Redwood City, CA: Stanford University Press, 2009); C.R. Davies, “An Evolutionary Step in Intellectual Property Rights: Artificial Intelligence and Intellectual Property,” Computer Law and Security Review, 27.6 (2011); Annemarie Bridy, “Coding Creativity: Copyright and the Artificially Intelligent Author,” Stanford Technology Law Review 5 (2012); J. McCutcheon, “Curing the Authorless Void: Protecting Computer-Generated Works Following ICETV and Phone Directories,” Melbourne University Law Review, 37.1 (2013); Ben Hattenbach and Joshua Glucoft, “Patents in an Era of Infinite Monkeys and Artificial Intelligence,” Stanford Technology Law Review 19 (2015); Jean-Marc Deltorn, “Deep Creations: Intellectual Property and the Automata,” Frontiers in Digital Humanities, 2017, https://www.frontiersin.org/articles/10.3389/fdigh.2017.00003/full; Shlomit Yanisky-Ravid and Xiaoqiong Liu, “When Artificial Intelligence Systems Produce Inventions: the 3A Era and an Alternative Model for Patent Law,” Cardozo Law Review, forthcoming; and W. Michael Schuster, “A Coasean Analysis of Ownership of Patents for Inventions Created by Artificial Intelligence,” Washington and Lee Law Review, forthcoming.
 
116 394 Intellectual Property and Digital Trade in the Age of Artificial Intelligence and Big Data to complete, and from that it independently produced a result. A process like this could be used in a
variety of industries to, say, discover a new polymer or to design a faster semiconductor.
The Creativity Machine, if it were a human being, would be an inventor in these circumstances. Inventorship does not go to the person who instructs someone else to solve a problem. If I tell my research scientist that I would like her to design a better battery and she does, that does not make me an inventor of her battery. The research scientist would be the inventor. In the case of the Creativity Machine, the United States Patent and Trademark Office (USPTO) granted a patent for the machine’s invention, but did so in the name of the machine’s owner. That was an easy decision for the Patent Office as the application had not disclosed the machine’s involvement.
The Creativity Machine may have been the first autonomous machine inventor, but it certainly was not the last. More patents were created autonomously by machines in the 2000s—for example, by the “Invention Machine,” which relied on genetic programming. Inventions autonomously created by the Invention Machine were also issued patents by the USPTO, again under circumstances in which, if the machine had been a person, the machine would have been the inventor.
Of course, right now there may be few machines independently inventing. Most machines are involved in the inventive process as simple tools that help people to “reduce to practice” an invention. If I design an experiment and have my PhD students carry it out without change, and the experiment’s results are patentable, I, and not my students, am probably the inventor for those results. Similarly, most computers are just executing tasks given by people. But at least some of the time, the computer occupies the role of the inventor. I suspect you are not hearing more about autonomous machine inventions because of concerns about patentability. Can a machine be an inventor? Should a machine be an inventor? These are open questions, and they are important theoretical and practical questions because computers are de facto inventing, and inventors have ownership rights in patents. Failure to list inventors can make patents invalid or unenforceable.
I have looked at this primarily from a US law perspective and found no statute that discusses computer inventorship, there is no case law directly on the issue, and there is no relevant patent office policy. However, there are some barriers to computer inventorship. For instance, the 1952 Patent Act uses the term “individual” to describe potential inventors, something that was done to prevent corporate inventorship. There is also quite a bit of judicial language characterising invention as a “mental act.”
While there is no patent office policy on computational inventions or computer-generated works, there is a copyright office policy on computer authorship. That policy dates to 1984 and states that works “authored” by a computer cannot qualify for copyright protection. In England and Wales, the rule is different under the Copyright, Designs and Patents Act of 1988: if a work is computer- generated, the author is the person who makes the arrangements for the creation of the work.
The United States Copyright Office cites the 1886 case of Burrow-Giles v. Sarony in support of its current policy. In that case, a photographer, Napoleon Sarony, sued the Burrow-Giles Lithographic Company for copyright infringement of a famous photograph of Oscar Wilde. The company alleged that the photographer could not be the photograph’s author because a photograph is just a mechanical reproduction of a natural phenomenon. The Court held that any form of writing by which a mental idea is given visible expression is eligible for copyright protection.

Global Perspectives and Challenges for the Intellectual Property System 117
395
The case thus explicitly dealt with whether the use of a machine would negate human authorship, and implicitly with whether a camera could be considered an author. If it seems unwise to rely on dicta from the Gilded Age to formulate policies on machine authorship—well, that is what is happening. This policy was relevant to a recent case in the Ninth Circuit in California involving the famous “Monkey Selfies.” In that case, a crested macaque in Indonesia took pictures of itself using equipment belonging to a nature photographer, David Slater. Mr Slater promptly claimed copyright in the photographs. Eventually, the United States Copyright Office clarified that because only a person could be an author, that copyright could not subsist in the Monkey Selfies. People for the Ethical Treatment of Animals (PETA) sued Mr Slater in the United States Federal Court for copyright infringement on behalf of the macaque, alleging that the primate should be the copyright owner of its own photographs. The case ultimately settled, with Mr Slater agreeing to donate 25% of future revenue from his use of the photograph to charities dedicated to protecting crested macaques in Indonesia.
If we analogise this copyright case law to the patent context, then maybe a computer cannot be an inventor and its discoveries enter in the public domain. Computers do not need incentives to invent, and permitting computer inventorship might chill human invention.
However, there is a way around computer involvement that works in the patent but not the copyright context. Inventorship can also be based on recognition of inventive subject matter. Thus, a person may be an inventor by virtue of recognising that a computer has invented something patentable. This is almost certainly how the problem is being dealt with today in practice—just as it was for the earliest computational inventions. It avoids having to disclose an inventive computer to the USPTO and potentially throwing a wrench into a patent application. For patent attorneys, there is no incentive right now to disclose inventive activity by computers, and plenty of incentive not to make that disclosure.
The system of invention by recognition seems reasonable if you are the first scientist to notice that penicillin is inhibiting bacterial growth, but perhaps not if you are taking the credit for the work of another inventive entity—even if that entity is a computer. In the latter case, the system is rewarding people even if they are not doing anything inventive themselves. A computer might clearly identify its own results as being patentable. For that matter, it might even format its results as a patent application. Claiming credit for the work of a machine also devalues human invention, because it equates the contributions of people using inventive machines and human inventors who have legitimately engaged in inventive activity.
Taking credit for a machine’s work also has the potential to create logistical problems when the first person to notice a computer’s results is not the computer’s owner or the person who gave the computer a goal to complete. This may incentivise computer owners to restrict access to their machines so that they can control ownership of inventive output.
More ambitiously, I argue that we should recognise computers as inventors. This will functionally produce more invention because it will incentivise the development of creative computers. That is because allowing computer owners to patent the output of their machines makes those machines more valuable. The constitutional rational for granting patent inventions in the United States is based on an incentive theory. We want patents because of the free-rider problem and because

118 396 Intellectual Property and Digital Trade in the Age of Artificial Intelligence and Big Data
patents are thought to generate additional research and discovery. Even though computers do not care about incentives, people who design computers do. Acknowledging computers as inventors would reward effort upstream of the stage of invention, and it could also promote disclosure and commercialisation of patentable subject matter. It would also validate inventor moral rights, because it will distinguish between human inventors who contribute conceptually to an invention and persons filing applications based on the autonomous output of machines.
What about the potential barriers we discussed—that invention must be a mental act and that an inventor must be an individual? Well, there are computers that generate output in a process akin to a person’s mental act—for instance, computers that utilise neural networks. There are also computers that generate output in totally different ways, like those that use expert-based systems. Should it matter how a computer is designed and how it functions?
I would argue no. We should care functionally about whether the system generates innovation, not how innovation occurs. Congress came to that same conclusion in 1952 when it abolished the “flash of genius” test. That was an old requirement that required that the inventive spark come to a person in an “aha” moment rather than as the result of methodical, laborious research. The nature of the test was never entirely clear; it involved judges subjectively reasoning about what an applicant might have been thinking. Congress eventually decided it was not a good test, and that we should not care about what goes on in someone’s head, just whether what they create is inventive and beneficial for society.
Similarly, the requirement that individuals should be inventors should not interfere with computer inventorship. That language is from the 1950s—long before the issue of computational invention was relevant. It should be interpreted according to dynamic principles of statutory interpretation in light of the purpose of the original Act, which was to prevent corporate inventorship.
If a computer could be an inventor, who would own its patent? I am not arguing that a computer should own a patent. Computers are owned as property and do not have legal rights. I would argue that the computer’s owner should be the automatic assignee of anything the computer develops. Where multiple parties are involved, such as software developers, computer owners, and users, they could work out issues of ownership by contract, starting with the default position that the computer owner is the assignee. This would be the most consistent with the way we treat personal and intellectual property right now.
Computational invention has exciting implications beyond inventorship. I think creative computers are going to change the entire patent paradigm in the next 10–20 years.
Even more interesting than thinking about how computers and people are competing right now in inventive activity is that computers are very soon going to overwhelm people in inventive activity. Take biotechnology research on antibodies as an example. There are lots of patents on antibody structures. However, there are only so many ways you can string proteins together to make an antibody, and it is not that difficult to imagine a sufficiently powerful computer sequencing every conceivable antibody and publishing those results online. Assuming this would be an anticipatory disclosure, it would prevent anyone from patenting the structure of those antibodies. The computer could not patent the antibody structures itself because it would not know their utility, which is

Global Perspectives and Challenges for the Intellectual Property System 119
397
another requirement for patentability. But an inventive machine would have just wiped out an entire field of human research.
As computers grow increasingly faster, cheaper, and more sophisticated, they are going to play an ever-greater role in the inventive process. It will become standard for creative computers to automate invention. Someone in the chemical sciences who used to discover new chemical compounds through deductive reasoning and trial and error with teams of human researchers will instead use artificial intelligence to find new compounds. Right now, the hypothetical “person having ordinary skill in the art,” or PHOSITA, is the benchmark we use to judge inventiveness. If the skilled person uses inventive machines, or is an inventive machine, then the benchmark is very high. It is hard to conceive of an invention that would not be obvious to a sufficiently sophisticated computer. That would essentially mean the end of inventive activity. Everything will be obvious.

398
ARTIFICIAL INTELLIGENCE, BIG DATA AND INTELLECTUAL PROPERTY: PROTECTING COMPUTER-GENERATED WORKS IN THE UNITED KINGDOM
RYAN ABBOTT*
Abstract: Big data and its use by artificial intelligence (AI) is changing the way intellectual property is developed and granted. For decades, machines have been autonomously generating works which have traditionally been eligible for copyright and patent protection. Now, the growing sophistication of AI and the prevalence of big data is positioned to transform computer- generated works (CGWs) into major contributors to the creative and inventive economies. However, intellectual property law is poorly prepared for this eventuality. The UK is one of the few nations, and perhaps the only EU member state, to explicitly provide copyright protection for CGWs. It is silent on patent protection for CGWs.
This chapter makes several contributions to the literature. First, it provides an up-to-date review of UK, EU and international law. Second, it argues that patentability of CGWs is a matter of first impression in the UK, but that CGWs should be eligible for patent protection as a matter of policy. Finally, it argues that the definition of CGWs should be amended to reflect the fact that a computer can be an author or inventor in a joint work with a person.
Keywords: computer-generated works, artificial intelligence law, big data and intellectual property, international law, patents
I. INTRODUCTION
Big data and its use by artificial intelligence (AI) is changing the way intellectual property is developed and granted. For decades, machines have been autonomously generating works which have traditionally been eligible for copyright and patent protection.1 For instance, in the US, the first “computer-generated work” (CGW) was submitted for copyright registration prior to 1965. The US Patent and Trademark Office (USPTO) has granted patents for inventions autonomously generated by computers as early as 1998. Terms such as “computers” and “machines” are used in this chapter interchangeably to refer to computer programs or software rather than to physical devices or hardware. As AI continues to grow exponentially more sophisticated and powerful, and the amount of data available to these machines keeps pace, CGWs should become a major contributor to the creative and inventive economies.2
This chapter considers the phenomenon of CGWs from a UK, EU and international law perspective. There is little law on the subject. UK law explicitly provides for copyright protection of CGWs, and in this respect, it is an outlier in the EU and internationally. However, UK law is silent on patent protection. No UK, EU or international law explicitly prohibits protection for
* Professor of Law and Health Sciences, University of Surrey, School of Law and Adjunct Assistant Professor of Medicine at the David Geffen School of Medicine at University of California, Los Angeles. This is a draft chapter. The final version will be available in Research Handbook on Intellectual Property and Digital Technologies edited by Tanya Aplin, forthcoming, Edward Elgar Publishing Ltd. The material cannot be used for any other purpose without further permission of the publisher, and is for private use only.
 
399
CGWs, but rarely are such works explicitly protected. Legal instruments and judicial language related to both copyright and patents frequently refer to authors and inventors as natural persons, or restrict authorship or inventorship to natural persons, but this is most likely in response to the prospect of corporate authorship and inventorship. Such language does not appear to be the result of seriously considering CGWs and should not prohibit IPRs as a matter of policy.
This chapter begins by describing the phenomenon of CGWs and then reviewing the relevant law. It seeks to resolve the following questions: Are computers autonomously creating or inventing or merely aiding human authors and inventors? How will inventive machines alter research and development? Can a CGW receive copyright or patent protection? Can a person qualify as an author or inventor for a machine’s output? Who would own IPRs associated with a CGW? These and other questions can be answered by referring to the fundamental policy rationales for IPRs, and by analogy to instances of human authorship and invention.
The chapter argues that patentability of CGWs is a matter of first impression in the UK, but that CGWs should be eligible for patent protection. This would incentivize the development of inventive machines, which will ultimately result in more innovation. Acknowledging machines as inventors would also safeguard moral rights, because it would prevent people from receiving undeserved acknowledgement.
The chapter also proposes that the standard for CGWs should be amended—for copyright as well as patent. Rather than treating a CGW as a work “generated by a computer in circumstances such that there is no human author of the work”, a CGW should be a work “generated by a computer in circumstances such that the computer, if a natural person, would be an author.” Similarly, for patents, CGW should be a work “generated by a computer in circumstances such that the computer, if a natural person, would be an inventor.” This would take into account the fact that people and machines often work collaboratively, and that even with the involvement of a person a machine can contribute as an author or inventor in its own right.
Finally, this chapter argues there is a need for an internationally harmonized approach to CGWs. Most jurisdictions in the EU, and worldwide, have yet to decide how to regulate CGWs. Failure to internationally harmonize may disadvantage countries which permit IPRs for CGWs, and advantage those which do not.
II. CREATIVE COMPUTERS AND INVENTIVE MACHINES
The Growing Sophistication of AI
Much has been written about the increasing capacity of AI to engage in knowledge-work. Indeed, hardly a day goes by without a news article describing some new feat achieved by AI, whether it is IBM’s AI system DeepBlue beating Garry Kasparov at Chess, IBM’s Watson winning a game of Jeopardy, or Google’s DeepMind defeating a Go world champion in 2016. DeepMind’s Go victory was unexpected at the time because of the sheer complexity of the game, which has more potential Go board configurations than there are atoms in the Universe. AI systems are playing games to demonstrate their capabilities and to train, but they are also being applied to solve practical problems. Watson, for example, is being used to find new uses for existing drugs—an activity that has traditionally been fertile grounds for generating patentable inventions.
Computer knowledge-work can be thought of on a spectrum. On the one end, computers may function as simple tools that assist human authors and inventors, much the way that a pen or a wrench can help someone to write or invent. Works generated in this fashion have been referred to as “works created using a computer”, and likely account for the vast majority of human-machine

400
collaboration. While it could not be seriously argued that Microsoft Word should be a co-author of this chapter, it did contribute to the chapter’s creation. At times, Word corrects spelling, automatically formats, and even suggests the use of certain words.
The term “intermediate works” has been used to refer to more substantive contributions made by computers to creative works where a person qualifies as an author or inventor. It may be difficult to precisely distinguish between an intermediate work and a work created using a computer. Word probably could not contribute to an intermediate work, but a variety of publicly available software programs can. For instance, “Band-in-a-Box” allows a user to choose chords and styles, and the program then automatically generates a “complete professional-quality arrangement of piano, bass, drums, guitar, and strings or horns.”3 Other programs can make similarly substantive contributions to different types of creative works, such as novels and films. In some instances of intermediate works, it may be the case that the computer would qualify as a joint author or inventor, if it were a natural person.
At the other end of the spectrum, computers generate works under circumstances in which no human author or inventor can be identified. These are often referred to as CGWs or “works created by a computer”. While not widely appreciated, computers have been creating CGWs for decades. As an interesting example of the interplay between copyright and patent, in 2003, technologist Raymond Kurzweil, now a Director of Engineering at Google, was granted a patent on a computer program that could autonomously generate creative writings—the “Cybernetic Poet.” Incidentally, Mr. Kurzweil now predicts that machines will have human levels of intelligence in about a decade.
The argument has been made that a human author or inventor exists for any CGW, in the sense that, “behind every good robot is a good person.”4 It is true that a programmer (or many programmers and developers) has to create computer software, and in some cases it may make sense to impute authorship or inventorship to a programmer—particularly if a programmer develops an algorithm specifically to solve a particular problem or to generate a particular output. In these cases a programmer might have a significant contribution to a machine’s speicifc output. However, it may also be the case that a programmer creates an algorithm with no expectation or knowledge of the problems it will go on to solve. Some AI systems such as neural networks can behave unpredictably, such that their original programmers may not understand precisely how they function.5 Some computer systems, such as those based on genetic programming, may even be able to alter their own code. By analogy to human inventorship, an inventor’s teachers, mentors and even parents do not qualify as inventors on their patents, at least, not without directly contributing to the conception of a specific invention.
Attributing authorship or inventorship to a computer user, rather than a programmer, is also problematic. It may sometimes be the case that a user makes a significant contribution to a computer’s output, or that formulating instructions to a computer requires significant skill. However, it may also be the case that a user simply asks a computer to solve a problem, and the computer proceeds to independently generate an answer. In the future, it may even be the case that the computer is able to identify that its output is eligible for copyright or patent protection. In such cases, it seems difficult to argue that the user is an author or inventor. Again, by analogy to human works, simply instructing another person to solve a problem does not usually qualify for authorship or inventorship.
Thus, in at least some instances, computers are generating works traditional entitled to copyright and patent protection under circumstances in which no natural person qualifies as an author or inventor according to traditional criteria. In practice, it may be difficult to distinguish

401
between works created using a computer, intermediate works, and works created by a computer. However, this is not unlike making sense of human authorship and inventorship for joint works where individuals make diverse contributions.
Where’s the CGW?
Given these technological advances, one would be forgiven for asking—where are the CGWs? Why are there not routinely lawsuits over CGWs? How have countries managed without legal standards for CGWs?
It may be that the creative AI revolution has yet to arrive. CGWs may be few and far between, or lack commercial value. When Scott French programmed a computer to write a novel in the style of a famous author in 1993, the resulting work was described by one critic as, “a mitigated disaster”.6 Likewise, with regard to inventions, computers may rarely be inventing, or these outputs may lack significant utility.
It may also be that computers are creating CGWs, but that this is not being disclosed. There are good reasons to think this may be the case. In the US, for example, CGWs are not entitled to copyright protection. In 1965, the US Copyright Office reported it received several applications for CGWs. Given the exponential improvements in computer science, one would thus expect a similarly exponential increase in CGWs submitted for copyright protection from 1965 until the present. However, at least as early as 1973, the US Copyright Office elected to deny protection for CGWs.7 As a result, anyone in possession of a potentially valuable CGW would disqualify protection for the work by revealing its origins. A computer user wishing to obtain protection for a CGW may thus end up identifying himself or herself as the author. Similarly, in the UK, it is not clear that CGWs are entitled to patent protection. Computer users may thus elect to identify themselves as inventors for CGWs. Indeed, some of the earliest applicants for patents on CGWs were advised by their attorneys to report themselves as inventors.8
Failing to disclose the machine’s role in a CGW may also seem an appealing option because it is unlikely to be challenged. For instance, in the UK, CGWs are protected by copyright without registration, and the UK Intellectual Property Office (IPO) will not dispute a patent applicant’s reported inventorship unless this is challenged by a third-party. The issue of authorship or inventorship of a CGW may not arise until litigation, and even that is unlikely. When human authors and inventors have a disagreement about relative contributions, there will generally be one or more parties with an adverse legal interest. However, if a user takes credit for a computer’s invention, the computer is not in a position to protest. A legal dispute will probably only occur in cases where an alleged infringing party wants to dispute copyright or patent protection can subsist in a CGW, and somehow becomes aware that a computer was involved in generating the work.
This situation with respect to CGWs is a problematic state of affairs. It is important that authorship and inventorship be accurately attributed, both to optimize the use of copyright and patents as economic incentives, and to preserve the moral rights of natural persons. Establishing an author or inventor’s identity is important because whether the work qualifies for protection in the UK may depend on the author’s national status. It also identifies the first owner of copyright or patent, may base the term of copyright protection on the author’s death, and determines whether there are moral and rental rights belonging to an author. In whatever manner nations elect to protect CGWs, including by providing no protection, appropriate identification of the origin of CGWs is necessary for IPRs to function effectively as economic rights. Even with regard to moral rights, failure to designate a computer as an author or inventor may result in individuals taking credit for

402
works they have not personally generated. This may undermine the value of human authorship and inventorship.
Determining computer authorship and inventorship may be a complex endeavor. However, that is already the case with natural persons. For instance, despite the romantic conception of inventors as lone prodigies tinkering in their garages and experiencing flashes of genius, the vast majority of invention comes from industry and academic work where multi-person collaborations are the norm. Inventorship disputes are becoming more common,9 and determining inventorship in collaborative work is “one of the muddiest concepts in the muddy metaphysics of the patent law”.10
III. LEGAL STANDARDS
Intellectual property in the UK is primarily governed at the national level, subject to compliance with certain EU requirements and international treaties.
United Kingdom Standards for Computer-Generated Works
The Copyright, Designs and Patents Act 1998 (“CDPA”) is the primary legislation for copyright law.11 Copyright is an intellectual property right which subsists in certain creative works such as books, music and movies. It gives its owner the exclusive right to exploit the underlying subject matter for a fixed number of years, generally 70 years plus the life of the author, subject to certain exceptions such as fair dealing. Generally, the author of a work is the person who creates it, and the author is the default copyright owner. A notable exception is that an employer will be the default owner if a work is “made by” an employee in the course of employment. In some instances, an “author” can be a body incorporated in the UK, such as a limited company.12 Special authorship rules apply to “entrepreneurial” or “media” works—sound recordings, films, broadcasts and typographical works—that are produced rather than created, whereby legal entities are accepted as authors.
The CDPA makes special provision for CGWs with different rules for authorship and copyright duration. These works are defined as those “generated by a computer in circumstances such that there is no human author of the work[s].” CDPA §178. For these works, the CDPA provides that, “[i]n the case of a literary, dramatic, musical or artistic work which is computer- generated, the author shall be taken to be the person by whom the arrangement necessary for the creation of the work are undertaken.” CDPA §9(3). Of note, this protection only extends to literary, dramatic, musical and artistic works and not to media works, although a similar system to §9(3) also applies with regard to design rights.13 For CGWs, the term of the copyright is fifty years from the end of the calendar year in which the work was made.14
At least two cases considered CGWs under the Copyright Act 1956, the statutory regime prior to the CDPA.15 This statute had no provisions for CGWs.16 In Express Newspapers plc v Liverpool Daily Post & Echo [1985] FSR 306, the plaintiff newspaper Daily Express conducted a ‘Millionaire of the Month’ competition. It distributed cards with a five-letter code, and the public could check these cards against a daily newspaper grid, generated by a computer, to see if they won a prize. The defendant newspaper copied these grids, and was subsequently sued for copyright infringement. One argument advanced by the defendant was that because the grids were produced with the aid of a computer, they had no human author and thus could not be protected by copyright. Whitford J rejected this argument, stating, “[t]he computer was no more than the tool by which the varying grids of five-letter sequences were produced to the instructions, via the computer programs, of [the programmer]. It is as unrealistic [to suggest the programmer was not the author]

403
as it would be to suggest that, if you write your work with a pen, it is the pen which is the author of the work rather than the person who drives the pen.” Id. Whitford J also noted “that a great deal of skill and indeed, a good deal of labour went into the production of the grid and the two separate seqences of five letters”. Id.
Prior to this case, in 1977, Whitford J had chaired the “Whitford Report” which found of computer-generated works, “the correct approach is to look on the computer as a mere tool in much the same way as a slide rule or even, in a simple sense, a paint brush. A very sophisticated tool it may be, with considerable powers to extend man’s capabilities to create new works, but a tool nevertheless.”17 The Whitford Report concluded that both the computer programmer and the person who originated data to provide the computer should be authors of any resultant CGW. In response to the Whitford Report, the Government issued the Green Paper report. Among other things, this report argued that the computer user, as potentially distinct from the programmer and originator of data, should generally also be an author.18 In 1986, the Government published a White Paper, Intellectual Property and Innovation, which argued, “[t]he responses to the 1981 Green Paper have shown, however, that circumstances vary so much in practice that a general solution will not be fair in all cases. It appears that no practical problems arise from the absence of specific authorship provisions in this area. The Government has therefore concluded that no specific provisions should be made to determine this question... If no human skill and effort has been expended then no work warranting copyright protection has been created.”19
After this White Paper, the Copyright Committee of the British Computer Society (BCS) submitted a proposal to the Government arguing that CGWs should be protected as a distinct type of work. “The BCS proposes the creation of a new class of copyright protected works. The copyright owner or ‘maker’ should be defined as the person by whom the arrangements necessary for the making of that computer output or computer-generated work, are undertaken.”20 This language was essentially adopted in the CDPA. The BCS’s proposed language was modeled after provisions for film authorship under the Copyright Act 1956. Despite the BCS’s protestation that sound recordings, films, cable programmes and published editions were already being generated by computer, the CDPA did not extend protections to this subject matter for CGWs.
Since the CDPA’s enactment, the authorship of CGWs was considered in Nova Productions Ltd v Mazooma Games Ltd.21 In this case, the parties were competing manufacturers of electronic pool games. Nova claimed copyright in its graphics and the frames generated by software from those graphics and displayed to users during gameplay. Kitchin J (as he then was) regarded the frames which the software generated based on user actions to be CGWs, even though the component graphics of the frames were designed by a person. Kitchin J further held that the author of the CGW in this case was the company director responsible for designing the game—the person who designed the appearance of the various elements displayed, devised the rules and logic for frame generation, and wrote the program, and not the game player, who “...contributed no skill or labour of an artistic kind”. It should be noted there was limited consideration of §9(3) in this case because the subsistence and ownership of the works was not contested.
In sum, while judicial experience with CGW copyright is limited, it is clear that copyright protection is available. The “author” of a CGW work is the person by whom the arrangements necessary for the creation of the work are undertaken. In light of the relative absence of case law related to authorship of CGWs, cases that have investigated authorship for films may be instructive. Under the CDPA, a film’s producer and principal director are together deemed an author. A producer
 , “in relation to a sound recording or a film, means the person by whom the
 arrangements necessary for the making of the sound recording or film are undertaken...” CDPA

404
§178. Identifying a producer may be a fact intensive inquiry.22 Cases have found it is relevant who instigated the making of the film, who paid for the making of the film, whether a film would not have existed but for the input of a person, whether more than one person may be a producer, and the extent of creative contributions.23
United Kingdom Standards for Patenting Computer-Generated Works
By contrast to copyright, there is no statutory provision governing patents for CGWs, and there appear to have been no cases on the subject. The Patents Act 1977 (“PA”) is the primary legislation for patent law. The PA protects inventions which are new, involve an inventive step, and are capable of industrial application. Patents grant their owners the exclusive right to make, use, sell and import an invention for a limited term, generally 20 years from the date an application is filed, subject to certain exceptions.
While nothing in the PA explicitly deals with CGWs, on numerous occasions it references natural persons. For example, the PA requires the identity of individual inventors to be disclosed, and inventors have the right to be mentioned in an application or a patent. It also provides benefits to inventors in some circumstances in which an employer has received outstanding benefit from an invention. The PA states that,
§
European Union Standards for Computer-Generated Works
The European Single Market seeks to guarantee the free movement of goods, capital, services and labour within the European Union. However, IPRs such as copyright and patents can create barriers to free trade. IPRs are largely national in origin, and not transferrable across boarders or mutually recognized per se. In the interest of promoting trade, the EU has attempted to centralize and harmonize national IP laws. This has been aided by case law from the Court of Justice of the European Union (CJEU), the Agreement on Trade Related Aspects of Intellectual Property Rights (TRIPS), which is discussed in the next section, and various EU directives.
Early CJEU cases established the doctrine of exhaustion and the specific subject matter doctrine. This allowed recognition of national IPRs, but limited the application of IPRs where they would limit free movement of goods. The EU is a party to TRIPS, which has harmonized to a great extent IPRs within the EU. Since TRIPS, various EU directives, such as the Computer Program Directive and the Database Directive, have increasingly harmonized national IP laws where differences existed in terms of substance or duration of rights.25 Further efforts at harmonization have resulted in a unique EU trademark system, and various sui generis rights such as EU level plant variety rights. Today, there is relative comprehensive harmonization of some forms of IP such as trademarks, and relative greater discrepancy with copyright. (Elsmore, 2012).
There is no equivalent to the CDPA §9(3) in other EU continental jurisdictions.26 Worldwide, the UK is one of only a handful of countries that explicitly permits copyright for CGWs. Other nations that provide protection, such as Ireland, New Zealand and India, were influenced by the UK’s example—their statutory instruments contain similar language to CDPA §9(3).27
  Although jurisprudence in related areas may provide
 guidance, there is a degree of novelty to determining authorship of CGWs. It may not be clear in all cases whether the person who makes necessary arrangements is a computer’s owner, user, or
 programmer.
 “inventor... in relation to an invention means the actual deviser
  of the invention...” PA
7(3). The term “deviser” is not defined in the PA, but judicial language
 also frequently refers to inventors as persons and refers to concepts such as “mental activity” being
necessary for invention.24
 
405
EU member states may not have laws specifically permitting or refusing copyright protection for CGWs, but many have laws that restrict authorship to natural persons. For example, Spanish copyright law states that the author of a work is the natural person who creates it.28 Under French law, only natural persons who create works may be considered authors, and the rights to a work vest in the author regardless of any contract.29 For collective works, a legal entity can exercise rights but is not classified as the author. Various other national instruments contain language that alludes to authorship as being a human activity. At a European level, the benchmark for originality is an “author’s own intellectual creation.” This concept was first introduced through legislation— the Software, Term and Database Directives—and then developed by the CJEU.30 For example, in 2011, the CJEU held that, “copyright is liable to apply only in relation to a subject-matter, such as a photograph, which is original in the sense that is its author’s own intellectual creation... the author of a portrait photograph can stamp the work created with his ‘personal touch’.”31 This and similar language seems to imply an author is a natural person. CGWs are not explicitly discussed in any European directives.
For patents, as with the PA, the European Patent Convention (EPC) requires the identity of inventors to be disclosed in patent applications and issued patents,32 although it is left to contracting states to resolve who is an inventor and other entitlement issues. The EPC is a multilateral treaty, separate from the EU and with different membership, which created the European Patent Organisation (EPO) and a system for granting “European patents.” A European patent is not a centrally enforceable patent or a unitary right. Rather, the EPC provides a harmonized procedure for unified prosecution and opposition, on the basis of which a European patent may be nationally granted in any of the 38 EPO countries. By contrast, the European patent with unitary effect (EPUE), or the unitary patent, is a new type of European patent that would be valid in participating member states of the EU. This would involve a single patent and ownership, as well as a single court (the Unified Patent Court), and uniform protection. The Agreement on a Unified Patent Court establishes the unitary patent system. Participation is open to any member state of the EU, but not other parties to the EPC. Negotiations for the unitary patent have been ongoing since the 1970s. At present, this agreement will enter into force after it is ratified by Germany.
International Standards for Computer-Generated Works
Two of the most important international agreements governing copyright and patent law are the Berne Convention and the Agreement on Trade Related Aspects of Intellectual Property Rights (TRIPS). For example, the Berne Convention required countries to offer the same level of copyright protection to nationals of other parties to the convention. It also introduced the idea that copyright protection is not contingent on formalities such as registration, though member states are free to require ‘fixation’. The most substantive international IP agreement is TRIPS, which established global standards for copyright and patent protection. The UK and all EU Member States are required to adhere to the mandatory requirements in TRIPS. These requirements were modeled after the IP laws in developed nations such as the United Kingdom, United States and Japan, so TRIPS required relatively few changes to the UK’s IP laws when it came into effect on 1 January 1996.33
Nothing in these, or any other binding international instrument, explicitly authorizes, or prohibits, protections for CGWs. The Berne Convention, for instance, states the Union is created, “for the protection of the rights of authors in their literary and artistic works.”34 However, the Convention does not define “author.”35 The Berne Convention Guide states that this is due to the

406
fact that, “national laws diverge widely, some recognizing only natural persons as authors, while others treat certain legal entities as copyright owners.”36
The World Intellectual Property Organization (WIPO) did consider protections of “computer-produced works” in discussions of a possible Model Copyright Law.37 It defined a computer-produced work as one generated by a computer where identification of authors is impossible because of the indirect nature of individual contributions. The original owner of the moral and economic rights in such a work would be either the entity “by whom or by which the arrangements necessary for the creation of the work are undertaken,” or the entity “at the initiative and under the responsibility of whom or of which the work is created and disclosed.” WIPO’s Committee of Experts eventually concluded further study was needed, and the model law was never adopted.
United States Standards for Computer-Generated Works
No statute governs the subject of CGWs in the US, and no cases have seriously considered copyright or patent protection for CGWs. However, the US Copyright Office has a policy prohibiting copyright for any non-human work—what it now refers to as its “human authorship requirement.” The US Patent and Trademark Office (USPTO) does not have any stated policy regarding CGWs and patents. In 1986, Professor Pamela Samuelson wrote, “[a]s yet there has been no judicial decision allocating rights in computer-generated works. It can, however, only be a matter of time before courts are forced to resolve the issue.”38 That prediction proved optimistic.
One recent US case came close to raising the issue. Naruto v. Slater involved a series of pictures that a crested macaque took of itself. These “Monkey Selfies” were subsequently commercialized by the camera’s owner, David Slater, who asserted he owned the copyright to the photographs. People for the Ethical Treatment of Animals (PETA) subsequently sued Mr. Slater, alleging that the macaque, Naruto, was the copyright owner, and that Mr. Slater had infringed Naruto’s copyright.
In January 2016, US District Judge William Orrick III dismissed the case on the grounds that Naruto lacked standing to sue. The judge also deferred to the USPTO’s interpretation that the macaque was not an “author” within the meaning of the Copyright Act. He considered PETA’s argument that the USPTO policy is antithetical to the “public interest in animal art”, but ultimately ruled “that is an argument that should be made to Congress and the President, not to me.”39 PETA appealed the decision to the Ninth Circuit Court of Appeals, and shortly after oral arguments, the parties reached a settlement in which Mr. Slater agreed to donate 25% of any future revenues from the monkey selfies to charities. Despite the settlement, however, the Ninth Circuit dismissed the case to create precedent. The Court held that animals only have statutory standing if an Act of Congress plainly states animals have statutory standing, and so animals are unable to sue under the Copyright Act because the law does not expressly authorize animals to file copyright infringement clams. In doing so, the court avoided weighing in on the merits of non-human authorship.
Outside of CGWs, US copyright law has a mechanism for authorship of artificial persons.
“In the case of a work made for hire, the employer for whom the work was prepared is considered the author for purposes.” 17 U.S.C. § 201(b) (2011). Functionally, the same outcome may occur in the UK, but while the UK permits employers to own works, ownership is distinct from authorship for so-called “author works”—literary, dramatic, musical or artistic works—the same works protected by CDPA §9(3). Even in EU countries where only natural persons may be authors, a focus on “author’s rights” does not preclude authors from transferring certain rights to employers,

407
and some jurisdictions will imply the existence of an agreement to do so. Ultimately, then, the same economic outcome may occur for works made in the course of employment in the US, UK and in EU civil law jurisdictions, but the terminology may differ. Some civil law jurisdictions may also retain additional, inalienable rights for authors.
IV. PROTECTING COMPUTER GENERATED WORKS
Policy
Various rationales are given for IPRs, but broadly speaking, they can function as economic incentives and they are justified on the basis of natural rights. The notion of IPRs as an economic right, particularly for patents, dominates the Anglo-American system. In the US, for example, the Constitution explicitly endorses an innovation incentive rationale for IPRs, by granting Congress the power “[t]o
 promote the progress of science and useful arts, by securing for limited times to
 authors and inventors the exclusive right to their respective writings and discoveries.”40
 Patents can incentivize innovation.41 This is based on the theory that information goods are
  typically non-excludable and non-rivalrous, so lack of protection will lead to underproduction. By granting a limited monopoly in the form of a patent, this allows inventors to enjoy greater financial benefits from discoveries and encourages invention. In addition, patents can promote the commercialization of inventions. For instance, new drug approvals often take years, and the pharmaceutical industry claims that getting new drugs approved costs billions of pounds. Once a drug is approved, it may be easy for a competitor to copy the drug and avoid the costs of initial approval. Patents may thus encourage an originator pharmaceutical company to spend the necessary resources on approval, because after the drug is approved they can charge monopoly prices until patents expire. Patents, whether incentivizing research or commercialization, are thus one solution to the “freerider” problem. Finally, patents can promote information disclosure. Patents are issued to inventors in exchange for disclosing to the public how to make an invention. Without patents, inventors might rely on confidential information to prevent copying, and never publicly disclose how to make an invention. This happened, for example, with the drug “Premarin” which was first made by Wyeth and now is made by Pfizer. No generics company has been able to replicate this drug since its first regulatory approval in 1942. Perhaps most famously, Coca-Cola
 has kept its recipe for its iconic beverage confidential for over a century.
By contrast, the civil law systems of continental Europe may place more emphasis than the UK on moral rights, which are viewed as independently protectable and separate from economic rights. Moral rights protect an author’s personality and the integrity of a work, and are considered “personal, perpetually inalienable and unassignable.”42 Moral rights also accommodate “personality” rights based, for instance, on theories by Kant and Hegel that people express their “wills” and develop as persons through their interactions with external objects. This, for instance, is accomplished by giving authors the right to control certain uses of their works, even after assigning economic rights. Personality theorists argue that authors and inventors are inherently at risk of having their ideas stolen or altered in objectionable ways. Thus, IPRs are justified to prevent misappropriation or modification of objects through which authors express themselves. IPRs also accommodate Lockean theories of first occupancy, the idea that the person who owns a particular thing should be the person who ‘gets there first’, as well as labour theory, the idea that ownership is derived from mixing labour with unowned or commonly held property, and that appropriating these products would be unjust. These ideals are reflected in patent law, for instance, by giving

408
inventorship rights to the first inventor to file for a patent, and giving inventorship rights to individuals who find new uses for natural products.
But IPRs can also have significant costs. They restrict competition (particularly in the case of patents) and free speech (particularly in the case of copyright), and they can inhibit innovation, collaboration, and open communities. To the extent that IPRs are justified, it is because they are thought to have more benefits than costs. However, with IPRs, more is not always better. For instance, software patents have been criticized for being unnecessary as an incentive, while at the same time creating “patent thickets” that make work in the software industry challenging.43 For this reason, the EPC states that “programs for computers” are not patentable, but the EPO will grant patents for “computer-impelmented inventions” as long as they have a technical effect.
Whether to Patent and to whom?
Having examined UK, EU and international laws on copyright and patent protection for CGWs, or the absence thereof, let us return to the question of whether the UK should provide patent protection for CGWs. A number of academic commentators have argued that CGWs should become public property.44 If CGWs should instead be eligible for patent protection, who should be the inventor and owner of a CGW?
This chapter proposes that CGWs should be eligible for patent protection. The innovation incentive function of patents does not change based on whether a computer or a person invents. It is true that a computer does not respond to financial incentives, but the entities who develop inventive machines do. Providing patent protection for the output of autonomous machines makes autonomous machines more valuable, and what better way to incentivize innovation than to incentivize the development of inventive machines? This would reward activity upstream from the act of invention. To the extent that patents are incentivizing commercialization and disclosure of information, there is no change in this function as between a human and CGW. Also, if patent protection is not available for inventive AI output, then businesses may not use inventive AI, even in future instances where AI will be more effective than a person.
If CGWs are prohibited from receiving patents, it may be possible for a natural person to claim inventorship of a CGW even where that person was not involved in the development or operation of a computer. Namely, a person could argue they “devised” the invention by virtue of recognizing the relevance of a machine’s output. Indeed, discovery of an unrecognized problem may give rise to patentable subject-matter (“problem-inventions”).45 Similarly, discovery of an unrecognized solution can be patentable. In some cases, recognition of the inventive nature of a computer’s output may require significant skill, but in others, the nature of inventive output may be obvious. In the future, it may even be the case that a computer can identify its own output as patentable, and format it for a patent application.
If CGWs are to be protected, how then should inventorship and ownership be determined? Distinguishing inventorship and ownership may not functionally impact economic rights, but it does implicate moral rights. At present, de jure or de facto, individuals are claiming inventorship of CGWs under circumstances in which they have not functioned as inventors. This is fundamentally unfair, and it weakens moral justifications for patents by allowing individuals to take credit for the work of inventive machines. It is not unfair to computers who have no interest in being acknowledged, but it is unfair to other human inventors because it devalues their accomplishments by altering, and diminishing, the meaning of inventorship. This could equate the hard work of creative geniuses with those simply asking a computer to solve a problem. It would be particularly problematic once inventive machines come to generate a substantial portion, or

409
even the majority of inventions.46 By contrast, acknowledging computers as inventors would also acknowledge the work of computer programmers. While they may not have directly contributed to an invention, they may take credit for the success of their machines. This is similar to the way in which a supervisor may take pride in the success of a PhD student, without taking direct credit for their future writings and inventions.
If CGWs are to be protected, and a computer is to be acknowledged as an inventor, who should own the CGW? Certainly, computers should not own patents. Computers are non-sentient, cannot own property, and are themselves owned as property. Colin Davies has suggested the computer should hold IP rights and transfer these under contract.47 He notes this would require machine “responsibility,” which might require a deposit in a computer’s name to satisfy adverse judgments or an insurance scheme. More simply, ownership may directly vest in a computer’s user, programmer, or owner. In many instances, these may be the same entity, but they may also be distinct parties. The best policy or ideal solution would be to have ownership vest in the party that results in the most effective economic outcome, and also results in a standard that is practical to implement.48
The computer’s owner should be the default owner of any CGW it produces. This is most consistent with current ownership norms surrounding personal property (including both computers and patents).49 It should also most effectively incentivize innovation because it will motivate owners to share access to their software. If the computer’s user is the default owner of a CGW, this may instead result in computer owners restricting access. Computer programmers do not need to own future CGWs because they will capture the increased value of an inventive machine upon selling it. Also, having ownership default to programmers would interfere with the transfer of a machine, and it would be logistically problematic for developers to monitor machines they no longer own. The case for having computer owners also have ownership of CGWs reveals another reason why computers should be acknowledged as inventors. If computers cannot be inventors and instead the first natural person to recognize a computer’s invention becomes the inventor, this would give CGWs to computer users rather than owners. There is already precedent for assigning ownership in IPRs to an owner distinct from an author or inventors, such as with works for hire, joint authorship, films, etc.
This default was just be a starting point—computer users, owners and developers would be free to contract to different outcomes.
Computer-generated works—competition or collaboration?
The current definition of CGWs fails to take into account the fact that computers independently should qualify for authorship and inventorship, even when contributing to jointly authored works with natural persons. Computers may be inventors even of intermediate works. As such, the definition of CGWs should be amended from work “generated by a computer in circumstances such that there is no human author of the work”, to work “generated by a computer in circumstances such that the computer, if a natural person, would meet authorship requirements.” This would more accurately take into account contributions by machines, and allow economic incentives to work more efficiently.
The downside of this approach may be that it would be difficult for computer owners to know when their machines have generated CGWs. Users might benefit from failing to disclose CGWs to computer owners and then claiming they invented a CGW. However, users may still choose to disclose CGWs so that they could negotiate for clear title and, alternately, to avoid liability. To the extent that users and owners are distinct entities and users are licensing computers

410
for purposes generating CGWs, users may choose to negotiate a priori for ownership of CGWs with computer owners.
Determining human inventorship is already a tricky business in collaborative works. It may be even more difficult for collaborative works involving a computer. There are a variety of ways for computers to invent, some of which involve more human intervention than others. For example, a programmer may design a computer program specifically to solve a particular problem, and the solution may be the patentable invention. In such an instance, the programmer might have a greater claim to inventorship, resulting in joint inventorship with a computer. Again, this is not unlike current inventorship criteria, where a variety of individuals can play greater or lesser roles in invention. However, the current definition of CGWs in the CDPA does not accommodate this reality for copyright, as it fails to take into account that a computer can jointly author a work with a person.
International Harmonization
Finally, there is a need for a harmonized approach to CGWs. If the UK grants copyright and patent protections for CGWs, it has to provide nationals of other EU member states and parties to TRIPS with the same rights. However, if these other parties fail to allow for CGWs in their own domestic laws, UK nationals may not receive reciprocal protections.50 Few EU member states have dealt with CGWs.51 Inventive machine owners might thus be unable to obtain IPRs outside the UK. In fact, disclosing a machine author or inventor in a UK application might prejudice IPRs in other jurisdictions. At least for an interim period, UK entities would be advised to identify a natural person as an author or inventor where possible to avoid an inequitable economic outcome.
Future treatment of CGWs within the EU might be dealt with by an EU directive or regulation, although Brexit may remove the UK from the direct effect of changes to EU law. Regardless of Brexit, UK nationals still should benefit under the national treatment rule of TRIPS from changes to EU law that ascribe machine authorship and inventorship for CGWs. CGWs might also be dealt with by a future multinational agreement. However, harmonization exercises at the international level tend to proceed at a glacial pace.
Concluding Thoughts
In October 2017, the Kingdom of Saudi Arabia announced it was granting citizenship to a humanoid robot, Sophia, manufactured by Hanson Robotics. It is unclear whether this announcement was merely intended for publicity, or whether the nation has actually granted Sophia citizenship. In any event, if Sophia is a Saudi citizen, because Saudi Arabia is a party to TRIPS, other WTO members may be obliged to provide for IPRs for Sophia’s CGWs. Although, other countries may argue that Berne and TRIPs refer to authors and inventors who are nationals, but that machines cannot be authors and inventors regardless of ‘nationality’. In any event, while granting legal personhood to a machine may be one way to try and avoid disparate treatment of CGWs at the international level, there are other reasons to disfavor such an approach.
The law is overdue for establishing clear standards for protection of CGWs. As AI continues to improve, such works will become increasingly important. Efficiently structured copyright and patent laws can help maximize the value of CGWs, and protect the moral rights of human authors and inventors.52 However, for IPRs to function effectively, it is important that right holders and potential infringers have a reasonable degree of certainty about the scope and limits of protection.

411
 1 See, Ryan Abbott, I Think, Therefore I Invent: Creative Computers and the Future of Patent Law, 54 B. C. L. Rev. 1079–1126 (2016).
2 See, Ryan Abbott, Everything is Obvious, 66 UCLA. L. Rev. 2 (2019).
3 See, e.g., Band-in-a-Box, PG Music, http://www.pgmusic.com.
4 Arthur Miller, Copyright Protection for Computer Programs , Databases , and Computer Generated Works: Is Anything New Since CONTU? 106 Harvard Law Review 977–1073 (1993). 5 Abbott, Ryan, The Reasonable Computer: Disrupting the Paradigm of Tort Liability, 86 Geo. Wash. L. Rev. 1 (2018) (discussing unexplainability in the context of AI).
6 Patricia Holt, Sunday Review, S.F.CHRON., Aug. 15, 1993, B4; see, generally, Grimmelmann, J. There’s No Such Thing As A Computer-Authored Work, 39 Columbia Journal of Law & the Arts 403, 408 (2016).
7 U.S. COPYRIGHT OFFICE, COMPENDIUM OF U.S. COPYRIGHT OFFICE PRACTICES (FIRST) §2.8.3 (1st ed. 1973).
8 Ryan Abbott, I Think, Therefore I Invent: Creative Computers and the Future of Patent Law, 54 B. C. L. Rev. 1079–1126 (2016).
9 IDA Ltd and others v University of Southampton and others [2006] EWCA Civ 145; Abbott, Ryan, Jeremy Lack and David Perkins. Managing Disputes in the Life Sciences. Nature Biotechnology, 36, 697 (2018).
10 Mueller Brass Co. v Reading Industries Inc. 176 USPQ 361 (1972).
11 The CDPA permits copyright for “(a) original literary, dramatic, musical or artistic works, (b) sound recordings, films [or broadcasts], and (c) the typographical arrangement of published editions.” CDPA 1988, § 1 (internal footnote and emphasis omitted).
12 Copyright, Designs and Patents Act, 1988 §154.
13 Copyright, Designs and Patents Act, 1988 §214.
14 Copyright, Designs and Patents Act, 1988 §12(7).
15 In the case of Cummins v. Bond in 1927, a court was asked to adjudicate copyright in a work allegedly written by a journalist while acting as a spiritual medium. Cummins v. Bond, 1 Ch. 167 (1927). The court was not willing to decide that “authorship and copyright rest with someone already domiciled on the other side of the inevitable river.” Id. at 173. The rights to the work had to vest in a terrestrial being.
16 A similar outcome occurred in the case of The Jockey Club v Rahim (unreported) 22 July 1983, which concerned computers generating lists of runners and riders for horse races.
17 Whitford Committee on Copyright Designs and Performers Protection (Cmnd 6732 HMSO 1977), para 514.
18 Reform of the Law Relating to Copyright, Designs and Performer's Protection, A Consultative Document 58 (Cmnd 8302 HMSO 1981).
19 Intellectual Property and Innovation (Cmnd 9712; HMSO, Ch 9, paras 9.6–8).
20 Robert Hart, Copyright and computer generated works, 40 Aslib Proceedings 173, 173–181 (1988).
21 Nova Productions Ltd v Mazooma Games Ltd [2006] RPC 379. CGWs were also briefly considered in Bamgboye v Reed [2004] EMLR 5, 73 [38], Williamson J wrote that §9(3) “is dealing with the case where one is looking at a piece of music which, in fact, is composed of computerised sounds.”
22 See, e.g., Beggars Banquet [1993] EMLR 349.
23 Jani McCutcheon, Curing the authorless void: Protecting computer-generated works following

412
 icetv and phone directories. 37 Melbourne University Law Review 46 (2013).
24 See, e.g., Yeda Research and Development Co Ltd v Rhone-Poulenc Rorer International Holdings Inc [2007] UKHL 43, [2008] RPC 1 quoting Laddie J. in
25 Directive 2009/24/EC of the European Parliament and of the Council of 23 April 2009 on the legal protection of computer programs; Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases.
26 Andres Guadamuz, Do androids dream of electric copyright? Comparative analysis of originality in artificial intelligence generated works, Intellectual Property Quarterly 169 (2017). 27 Copyright, Designs and Patents Act, 1988, c. 48, § 9(3) (U.K.); Copyright Act of 1994, § 5 (N.Z.); Copyright and Related Rights Act 2000, Part I, § 2 (Act. No. 28/2000) (Ir.).
28 Ley 22/11 sobre la Propiedad Intelectual de 1987.
29 C. IP. Art. L111-1 (2003).
30 Case C-5/08 Infopaq International A/S v Danske Dagblades Forening [2009] ECR I-06569.
31 Eva-Maria Painer v. Standard VerlagsGmbH and ors, Case C-145/10 [2011] ECDR (13) 297, 324, [AG121]. In that case, Advocate-General Trstenjak interpreted EU directives related to this language to mean that, “‘only human creations are ... protected’, although these can ‘include those for which the person employs a technical aid, such as a camera’.” Id.
32 EPC R. 19 (Designation of the inventor).
33 94/800/EC Council Decision (of 22 December 1994). See, generally, Matthew James Elsmore, Comparing regulatory treatment of intellectual property at WTO and EU level, in LIBERALISING TRADE IN THE EU AND THE WTO: A LEGAL COMPARISON 412–439 (Sanford E. Gaines, et al., eds., 2012).
34 BERNE CONVENTION FOR THE PROTECTION OF LITERARY AND ARTISTIC 1971 ART. I.
35 Cf, SAM RICKETSON AND JANE C. GINSBURG, INTERNATIONAL COPYRIGHT AND NEIGHBORING RIGHTS (2 VOLUMES): THE BERNE CONVENTION AND BEYOND (2nd Ed. 2006) (arguing the reference to ‘makers’ of cinematographic works is the exception rather than the rule, and that ‘author’ referring to natural persons would be most consistent with the moral rights provisions and durations of protection being based on the life of an author).
36 WORLD INTELLECTUAL PROPERTY ORGANIZATION, GUIDE TO THE BERNE CONVENTION II (1978).
37 See INTERNATIONAL BUREAU OF WIPO, PREPARATORY DOCUMENT, DRAFT MODEL ON COPYRIGHT at 258-59 (No. CD/MPC/III/2, Mar. 30, IggO).
38 Pamela Samuelson, Allocating ownership rights in computer-generated works. 47 U. Pitt. Law Review 1185, 1190 (1985).
39 Naruto v. David John Slater et al, No. 16-15469 (9th Cir. 2018).
40 UNITED STATES CONSTITUTION, ARTICLE I, SECTION 8, CLAUSE 8 (emphasis added).
41 WILLIAM M. LANDES & RICHARD A. POSNER, THE ECONOMIC STRUCTURE OF INTELLECTUAL PROPERTY LAW. Cambridge, MA: Belknap Press (2003).
42 Martin A. Roeder, The Doctrine of Moral Right: A Study in the Law of Artists, Authors and Creators, 53 Harv. L. Rev. 554, 557 (1940). See, also, Graham Dutfield, Collective Invention and Patent Law Individualism: Origins and Functions of the Inventor’s Right of Attribution. 5 The WIPO Journal 25, 27 (2013).
 the invention’. The word ‘actual’ denotes a contrast with a deemed or pretended deviser of the
University of Southampton’s
 Applications [2005] R.P.C. 11, [39] (“The inventor is defined in s.7(3) as ‘the actual deviser of
  invention; it means, as Laddie J. said in University of Southampton’s Applications [2005] R.P.C.
 11, [39], the natural person who ‘came up with the inventive concept.’”)
  
413
 43
44 See, e.g., Ralph Clifford, Intellectual Property in the Era of the Creative Computer Program: Will the True Creator Please Stand Up? 71 Tul. L. Rev. 1675 (1997).
45 See, e.g., T 0002/83 (Simethicone Tablet) of 15.3.1984 (EPO Board of Appeal).
46 See, Abbott, R. Everything is Obvious, 66 UCLA. L. Rev. 2 (2019).
47 Colin Davies, An evolutionary step in intellectual property rights - Artificial intelligence and intellectual property. 27 Computer Law and Security Review 601, 615 (2011).
48 Ryan Abbott, Hal the Inventor: Big Data and its Use by Artificial Intelligence, in BIG DATA IS NOT A MONOLITH (Hamid Ekbia, et al., eds.) (2016).
49 Cf Schuster, W. Michael, ‘A Coasean Analysis of Ownership of Patents for Inventions Created by Artificial Intelligence’, 75 Washington and Lee Law Review (forthcoming 2018), <https://ssrn.com/abstract=3132753>. (arguing for user default ownership).
50 Robert Hart, Copyright and computer generated works, 40 Aslib Proceedings 173, 173–181 (1988).
51 Mark Perry & Thomas Margoni, From music tracks to Google maps: Who owns computer- generated works? 26 Computer Law and Security Review 621, 621–629 (2010).
52 Ryan Abbott & Bret Bogenschneider, Should Robots Pay Taxes? Tax Policy in the Age of Automation, 12 Harv. L. & Pol. Rev. 145 (2018).
 Daniel J. Hemel & Lisa Larrimore Ouellette, Beyond the Patents-Prizes Debate, 92 TEX. L.
 REV. 303 (2013).
 
                                 414
U.C.L.A. Law Review
Everything Is Obvious
Ryan Abbott
ABSTRACT
For more than sixty years, “obviousness” has set the bar for patentability. Under this standard, if a hypothetical “person having ordinary skill in the art” would find an invention obvious in light of existing relevant information, then the invention cannot be patented. This skilled person is defined as a non-innovative worker with a limited knowledge-base. The more creative and informed the skilled person, the more likely an invention will be considered obvious. The standard has evolved since its introduction, and it is now on the verge of an evolutionary leap: Inventive machines are increasingly being used in research, and once the use of such machines becomes standard, the person skilled in the art should be a person using an inventive machine, or just an inventive machine. Unlike the skilled person, the inventive machine is capable of innovation and considering the entire universe of prior art. As inventive machines continue to improve, this will increasingly raise the bar to patentability, eventually rendering innovative activities obvious. The end of obviousness means the end of patents, at least as they are now.
AUTHOR
Professor of Law and Health Sciences, University of Surrey School of Law and Adjunct Assistant Professor, David Geffen School of Medicine at University of California, Los Angeles. Thanks to Ryan Calo, Ian Kerr, Mark Lemley, Lisa Larrimore-Ouellette, and Jake Sherkow, as well as participants in workshops at the University of Surrey, WeRobot Conference, Oxford Business Law Workshop, and the Sixth Annual Fall Conference hosted by the Center for the Protection of Intellectual Property (CPIP) at Antonin Scalia Law School for their insightful comments.
66 UCLA L. Rev. 2 (2019)

                                 415
 TABLE OF CONTENTS
Introduction.......................................................................................................................................................4 I. Obviousness..................................................................................................................................................10 A. Public Policy.......................................................................................................................................... 10 B. EarlyAttempts.......................................................................................................................................11 C. TheNonobviousnessInquiry.............................................................................................................15 D. FindingPHOSITA................................................................................................................................17 E. AnalogousPriorArt.............................................................................................................................20 II. Machine Intelligence in the Inventive Process.......................................................................... 22 A. AutomatingandAugmentingResearch...........................................................................................22 B. Timeline to the Creative Singularity .................................................................................................. 26 C. Inventive and Skilled Machines ......................................................................................................... 31 D. Inventive Is the New Skilled ............................................................................................................... 33 E. Skilled People Use Machines............................................................................................................... 35 F. The Evolving Standard.......................................................................................................................... 37 III. A Post-Skilled World............................................................................................................................ 37 A. Application............................................................................................................................................38 B. Reproducibility...................................................................................................................................... 42 C. AnEconomicvs.CognitiveStandard...............................................................................................44 D. Other Alternatives................................................................................................................................ 46 E. Incentives Without Patents?................................................................................................................ 48 F. A Changing Innovation Landscape.................................................................................................... 50 Conclusion........................................................................................................................................................ 51
3

416
4
66 UCLA L. REV. 2 (2019)
 INTRODUCTION
For at least two decades, machines have been autonomously generating patentableinventions.1 “Autonomously”herereferstothemachine,ratherthan to a person, meeting traditional inventorship criteria. In other words, if the “inventive machine” were a natural person, it would qualify as a patent inventor. In fact, the U.S. Patent and Trademark Office (USPTO or Patent Office) may have granted patents for inventions autonomously generated by computers as early as 1998.2 In earlier articles, I examined instances of autonomous machine invention in detail and argued that such machines ought to be legally recognized aspatentinventorstoincentivizeinnovationandpromotefairness.3 Theowners of such machines would be the owners of their inventions.4 In those works, as here, terms such as “computers” and “machines” are used interchangeably to refer to computer programs or software rather than to physical devices or hardware.5
This Article focuses on a related phenomenon: What happens when inventive machines become a standard part of the inventive process? This is not a thought experiment.6 For instance, while the timeline is controversial, surveys of experts suggest that artificial general intelligence, which is a computer able to perform any intellectual task a person could, will develop in the next twenty-five years.7 Somethoughtleaders,suchasRayKurzweil,oneofGoogle’sDirectorsof
1. See Ryan Abbott, I Think, Therefore I Invent: Creative Computers and the Future of Patent Law, 57 B.C. L. REV. 1079, 1083–91 (2016) [hereinafter I Think] (describing instances of “computational invention” or “computer-generated works”); see also infra Subpart II.B (discussing some such instances in greater detail).
2. Abbott, supra note 1, at 1085.
3. Id. at 1083–91; Ryan Abbott, Hal the Inventor: Big Data and Its Use by Artificial Intelligence,
in BIG DATA IS NOT A MONOLITH (Cassidy R. Sugimoto, Hamid R. Ekbia & Michael Mattioli eds.,2016) [hereinafter Hal the Inventor] (discussing computational invention in a book chapter first posted online February 19, 2015).
4. Except where no owner exists, in possible cases of some open-source or distributed software, in which case ownership could vest in a user.
5. Except perhaps in exceptional cases where software does not function on a general-purpose machine, and where specialized hardware is required for the software’s function.
6. The growing prevalence and sophistication of artificial intelligence is accelerating the use of inventive machines in research and development. See Ryan Abbott & Bret Bogenschneider, ShouldRobotsPayTaxes? TaxPolicyintheAgeofAutomation,12HARV.L.&POL’YREV.145 (2018) [hereinafter Should Robots Pay Taxes?] (discussing the trend toward automation).
7. See generally Vincent C. Müller & Nick Bostrom, Future Progress in Artificial Intelligence: A Survey of Expert Opinion, in FUNDAMENTAL ISSUES OF ARTIFICIAL INTELLIGENCE 553 (Vincent C. Müller ed., 2016).
 
417
Everything Is Obvious 5
Engineering, predict computers will have human levels of intelligence in about a decade.8
The impact of the widespread use of inventive machines will be tremendous, not just on innovation, but also on patent law.9 Right now, patentability is determined based on what a hypothetical, non-inventive, skilled person would find obvious.10 The skilled person represents the average worker in the scientific field of an invention.11 Once the average worker uses inventive machines, or inventive machines replace the average worker, then inventive activity will be normal instead of exceptional.
If the skilled person standard fails to evolve accordingly, this will result in too lenient a standard for patentability. Patents have significant anticompetitive costs, and allowing the average worker to routinely patent their outputs would cause social harm. As the U.S. Supreme Court has articulated, “[g]ranting patent protection to advances that would occur in the ordinary course without real innovation retards progress and may . . . deprive prior inventions of their value or utility.”12
The skilled standard must keep pace with real world conditions. In fact, the standard needs updating even before inventive machines are commonplace. Already, computers are widely facilitating research and assisting with invention. For instance, computers may perform literature searches, data analysis, and pattern recognition.13 This makes current workers more knowledgeable and creative than they would be without the use of such technologies. The Federal Circuit has provided a list of nonexhaustive factors to consider in determining the level of ordinary skill: (1) “type[s] of problems encountered in the art,” (2) “prior art solutions to those problems,” (3) “rapidity with which innovations are made,” (4) “sophistication of the technology,” and (5) “educational level of active
8. Peter Rejcek, Can Futurists Predict the Year of the Singularity?, SINGULARITY HUB (Mar. 31, 2017), https://singularityhub.com/2017/03/31/can-futurists-predict-the-year-of-the-singularity [https://perma.cc/4TDE-QQTW] (predicting artificial general intelligence in 2029).
9. See, e.g., ROBERT PLOTKIN, THE GENIE IN THE MACHINE: HOW COMPUTER-AUTOMATED INVENTING IS REVOLUTIONIZING LAW & BUSINESS 60 (2009) (arguing that “[a]rtificial invention technology . . . enables [users] to produce inventions that they could not have created at all without such technology”); Ben Hattenbach & Joshua Glucoft, Patents in an Era of Infinite Monkeys and Artificial Intelligence, 19 STAN. TECH. L. REV. 32, 44 n.70 (2015); Brenda M. Simon, The Implications of Technological Advancement for Obviousness, 19 MICH. TELECOMM. & TECH. L. REV. 331 (2013).
10. 35 U.S.C. § 103(a) (2006). The “person having ordinary skill in the art” may be abbreviated as “PHOSITA” or simply the skilled person.
11. See infra Subpart I.D.
12. KSR Int’l Co. v. Teleflex Inc., 550 U.S. 398, 402 (2007).
13. Such contributions when made by other persons do not generally rise to the level of
inventorship, but they assist with reduction to practice.
  
418
6 66 UCLA L. REV. 2 (2019)
workers in the field.”14 This test should be modified to include a sixth factor: (6) “technologies used by active workers.”
This change will more explicitly take into account the fact that machines are already augmenting the capabilities of workers, in essence making more obvious and expanding the scope of prior art. Once inventive machines become the standard means of research in a field, the test would also encompass the routine use of inventive machines by skilled persons. Taken a step further, once inventive machines become the standard means of research in a field, the skilled person should be an inventive machine. Specifically, the skilled person should be an inventive machine when the standard approach to research in a field or with respect to a particular problem is to use an inventive machine (the “Inventive Machine Standard”).
To obtain the necessary information to implement this test, the Patent Office should establish a new requirement for applicants to disclose when a machine contributes to the conception of an invention, which is the standard for qualifying as an inventor. Applicants are already required to disclose all human inventors, and failure to do so can render a patent invalid or unenforceable. Similarly, applicants should need to disclose whether a machine has done the work of a human inventor. This information could be aggregated to determine whether most invention in a field is performed by people or machines. This information would also be useful for determining appropriate inventorship, and more broadly for formulating innovation policies.
Whether the Inventive Machine Standard is that of a skilled person using an inventive machine or just an inventive machine, the result will be the same: The average worker will be capable of inventive activity. Conceptualizing the skilled person as using an inventive machine might be administratively simpler, but replacing the skilled person with the inventive machine would be preferable because it emphasizes that the machine is engaging in inventive activity, rather than the human worker.
Yet simply substituting an inventive machine for a skilled person might exacerbate existing problems with the nonobviousness inquiry. With the current skilled person standard, decisionmakers, in hindsight, need to reason about what another person would have found obvious.15 This results in
14. In re GPAC Inc., 57 F.3d 1573, 1579 (Fed. Cir. 1995).
15. See generally Gregory N. Mandel, Patently Non-Obvious: Empirical Demonstration that the
Hindsight Bias Renders Patent Decisions Irrational, 67 OHIO ST. L.J. 1391 (2006) (discussing problems with hindsight in non-obviousness inquiries).
  
419
Everything Is Obvious 7
inconsistent and unpredictable nonobviousness determinations.16 In practice, the skilled person standard bears unfortunate similarities to the “Elephant Test,”17 or Justice Stewart’s famously unworkable definition of obscene material: “I know it when I see it.”18 This may be even more problematic in the case of inventive machines, as it is likely to be difficult for human decisionmakers to theoretically reason about what a machine would find obvious.
An existing vein of critical scholarship has already advocated for nonobviousness inquiries to focus more on economic factors or objective “secondary” criteria, such as long-felt but unsolved needs, the failure of others, and real-world evidence of how an invention was received in the marketplace.19 Inventive machines may provide the impetus for such a shift.
Nonobvious inquiries utilizing the Inventive Machine Standard might also focus on reproducibility, specifically whether standard machines could reproduce the subject matter of a patent application with sufficient ease. This could be a more objective and determinate test that would allow the Patent Office to apply a single standard consistently, and it would result in fewer judicially invalidated patents.20 A nonobviousness inquiry focused on either secondary
16. See FED. TRADE COMM’N, TO PROMOTE INNOVATION: THE PROPER BALANCE OF COMPETITION AND PATENT LAW AND POLICY 6–15 (2003) (critiquing Section 103 decisions).
17. Cadogan Estates Ltd. v. Morris [1998] EWCA Civ. 1671 at 17 (Eng.) (referring to “the well known elephant test. It is difficult to describe, but you know it when you see it”).
18. 378 U.S. 184, 197 (1964).
19. See, e.g., Michael Abramowicz & John F. Duffy, The Inducement Standard of Patentability,
120 YALE L.J. 1590, 1596 (2011) (arguing for an inducement standard); Tun-Jen Chiang, A Cost-Benefit Approach to Patent Obviousness, 82 ST. JOHN’S L. REV. 39, 42 (2008) (arguing that, “[a]n invention should receive a patent if the accrued benefits before independent invention outweigh the costs after independent invention”); Alan Devlin & Neel Sukhatme, Self-Realizing Inventions and the Utilitarian Foundation of Patent Law, 51 WM. & MARY L. REV. 897 (2009); John F. Duffy, A Timing Approach to Patentability, 12 LEWIS & CLARK L. REV. 343 (2008) (arguing for a timing approach to determining obviousness); Daralyn J. Durie & Mark A. Lemley, A Realistic Approach to the Obviousness of Inventions, 50 WM. & MARY L. REV. 989, 1004–07 (2008) (arguing for a greater reliance on secondary considerations); Gregory Mandel, The Non-Obvious Problem: How the Indeterminate Nonobviousness Standard Produces Excessive Patent Grants, 42 U.C. DAVIS L. REV 57, 62 (2008) [hereinafter Mandel, The Non-Obvious Problem] (arguing for nonobviousness to be based on “how probable the invention would have been for a person having ordinary skill in the art working on the problem that the invention solves”); Robert P. Merges, Uncertainty and the Standard of Patentability, 7 HIGH TECH. L.J. 1, 19 (1992) (arguing that patents should be issued for inventions which appeared unlikely to succeed in advance).
20. For decades, obviousness has been the most common issue in litigation to invalidate a patent, and the most common grounds for a finding of patent invalidity. See John R. Allison & Mark A. Lemley, Empirical Evidence on the Validity of Litigated Patents, 26 AIPLA Q.J. 185, 208–09 (1998); John R. Allison et al., Understanding the Realities of Modern Patent Litigation, 92 TEX. L. REV. 1769, 1782, 1785 (2014). As other commentators have noted, the bar here is low, and the new standard, “can be an administrative success if it is even just a bit
  
420
8 66 UCLA L. REV. 2 (2019)
factors or reproducibility may avoid some of the difficulties inherent in applying a “cognitive” inventive machine standard.
However the test is applied, the Inventive Machine Standard will dynamically raise the current benchmark for patentability. Inventive machines will be significantly more intelligent than skilled persons and also capable of considering more prior art. An Inventive Machine Standard would not prohibit patents, but it would make obtaining them substantially more difficult: A person or computer might need to have an unusual insight that other inventive machines could not easily recreate, developers might need to create increasingly intelligent computers that could outperform standard machines, or, most likely, invention will be dependent on specialized, non-public sources of data. The nonobviousness bar will continue to rise as machines inevitably become increasingly sophisticated. Taken to its logical extreme, and given there may be no limit to how intelligent computers will become, it may be that every invention will one day be obvious to commonly used computers. That would mean no more patents should be issued without some radical change to current patentability criteria.
This Article is structured in three parts. Part I considers the current test for obviousness and its historical evolution. It finds that obviousness is evaluated through the lens of the skilled person, who reflects the characteristics of the average worker in a field.21 The level of creativity and knowledge imputed to the skilledpersoniscriticalfortheobviousnessanalysis.22 Themorecapabletheskilled person, the more they will find obvious, and this will result in fewer issued patents.
Part II considers the use of artificial intelligence in research and development (R&D) and proposes a novel framework for conceptualizing the transition from human to machine inventors. Already, inventive machines are competing with human inventors, and human inventors are augmenting their
better than current doctrine as a helpful theoretical and pragmatic guide for applying the
obviousness doctrine.” Abramowicz & Duffy, supra note 19, at 1601.
21. See Ruiz v. A.B. Chance Co., 234 F.3d 654, 666 (Fed. Cir. 2000); see also Ryko Mfg. Co. v. Nu-Star, Inc., 950 F.2d 714, 718 (Fed. Cir. 1991) (“The importance of resolving the level of ordinary skill in the art lies in the necessity of maintaining objectivity in the obviousness inquiry.”). The Manual of Patent Examining Procedure (MPEP) provides guidance on the
level of ordinary skill in the art. MPEP § 2141.03.
22. DyStar Textilfarben GmbH & Co. Deutschland KG v. C.H. Patrick Co., 464 F.3d 1356, 1370
(Fed. Cir. 2006) (“If the level of skill is low, for example that of a mere dyer, as Dystar has suggested, then it may be rational to assume that such an artisan would not think to combine references absent explicit direction in a prior art reference.”). Though, in practice, few cases involve explicit factual determinations of the PHOSITA’s skill. Rebecca S. Eisenberg, Obvious to Whom? Evaluating Inventions From the Perspective of PHOSITA, 19 BERKELEY TECH. L.J. 885, 888 (2004). See infra Subpart I.D for a discussion of the PHOSITA standard.
  
421
Everything Is Obvious 9
abilities with inventive machines. In time, inventive machines or people using inventive machines will become the standard in a field, and eventually, machines will be responsible for most or all innovation. As this occurs, the skilled person standard must evolve if it is to continue to reflect real-world conditions. Failure to do this would “stifle, rather than promote, the progress of the useful arts.”23
Part II then proposes a framework for implementing a proposed Inventive Machine Standard. A decisionmaker would need to (1) determine the extent to which inventive machines are used in a field, (2) if inventive machines are the standard, characterize the inventive machine(s) that best represents the average worker, and (3) determine whether the machine(s) would find an invention obvious. The decisionmaker is a patent examiner in the first instance,24 and potentially a judge or jury if the validity of a patent is at issue in trial.25 In both instances, this new test would involve new challenges.
Finally, Part III provides examples of how the Inventive Machine Standard could work in practice, such as by focusing on reproducibility or secondary factors. It then goes on to consider some of the implications of the new standard. Once the average worker is inventive, there may no longer be a need for patents to function as innovation incentives. To the extent patents accomplish other goals such as promoting commercialization and disclosure of information or validating moral rights, other mechanisms may be found to accomplish these goals with fewer costs.
Although this Article focuses on U.S. patent law, a similar framework exists in nearly every country. Member States of the World Trade Organization (WTO) are required to grant patents for inventions that “are new, involve an
23. KSR Int’l Co., 550 U.S. at 427.
24. At the Patent Office, applications are initially considered by a patent examiner, and
examiner decisions can be appealed to the Patent Trial and Appeal Board (PTAB). U.S. PATENT & TRADEMARK OFFICE, Patent Trial and Appeal Board, https://www.uspto.gov/ patents-application-process/patent-trial-and-appeal-board-0 [https://perma.cc/3W42-FHH2]. Also, the PTAB can adjudicate issues of patentability in certain proceedings such as inter partes review. Id.
25. Determinations of patent validity can involve mixed questions of law and fact. Generally, in civil litigation, legal questions are determined by judges, while factual questions are for a jury. See, e.g., Structural Rubber Prods. Co. v. Park Rubber Co., 749 F.2d 707, 713 (Fed. Cir. 1984) (“Litigants have the right to have a case tried in a manner which ensures that factual questions are determined by the jury and the decisions on legal issues are made by the court . . . .”). There are some exceptions to this rule. See, e.g., Gen. Electro Music Corp. v. Samick Music Corp., 19 F.3d 1405, 1408 (Fed. Cir. 1994) (“[I]ssues of fact underlying the issue of inequitable conduct are not jury questions, the issue being entirely equitable in nature.”). See also Mark A. Lemley, Why Do Juries Decide If Patents Are Valid? (Stanford Pub. Law, Working Paper No. 2306152, 2013), https://papers.ssrn.com/sol3/papers.cfm? abstract_id=2306152.
  
422
10 66 UCLA L. REV. 2 (2019)
inventive step and are capable of industrial application.”26 Although U.S. law uses the term “nonobvious” rather than “inventive step,” the criteria are substantively similar.27 For instance, the European Patent Office’s criteria for inventive step is similar to the U.S. criteria for obviousness, and also uses the theoretical device of the skilled person.28
I. OBVIOUSNESS
Part I investigates the current obviousness standard, its historical origins, and how the standard has changed over time. It finds that obviousness depends on the creativity of the skilled person, as well as the prior art they consider. These factors, in turn, vary according to the complexity of an invention and its field of art.
A. Public Policy
Patents are not intended to be granted for incremental inventions.29 Only inventions which represent a significant advance over existing technology should receive protection.30 That is because patents have significant costs: They limit competition, and they can inhibit future innovation by restricting the use
26. Agreement on Trade-Related Aspects of Intellectual Property Rights, art. 27, Apr. 15, 1994, 33 I.L.M. 1197, 1208 [hereinafter TRIPS]. See Ryan B. Abbott, et al., The Price of Medicines in Jordan: The Cost of Trade-Based Intellectual Property, 9 J. GENERIC MEDS. 75, 76 (2012).
27. TRIPS, supra note 26, at 1208 n.5. Although, there are some substantive differences in the way these criteria are implemented, and TRIPS provides nations with various flexibilities for compliance. See generally Ryan Abbott, Balancing Access and Innovation in India’s Shifting IP Regime, Remarks, 35 WHITTIER L. REV. 341 (2014) [hereinafter Balancing Access].
28. “An invention shall be considered as involving an inventive step if, having regard to the state of the art, it is not obvious to a person skilled in the art.” Convention on the Grant of European Patents art. 56, Oct. 5, 1973, 13 I.L.M 268. For guidance on the “skilled person” in European patent law, see Guidelines for Examinations, EUR. PAT. OFF., http://www.epo.org/law-practice/legal-texts/html/guidelines/e/g_vii_3.htm [https://perma.cc/XFY3-JD8J] (last visited Sept. 24, 2018).
29. The nonobviousness requirement is contained in Section 103 of the Patent Act: A patent for a claimed invention may not be obtained, notwithstanding that the claimed invention is not identically disclosed as set forth in section 102, if the differences between the claimed invention and the prior art are such that the claimed invention as a whole would have been obvious before the effective filing date of the claimed invention to a person having ordinary skill in the art to which the claimed invention pertains.
35 U.S.C. § 103 (2018).
30. Atlantic Works v. Brady, 107 U.S. 192, 200 (1883) (noting that “[t]o grant to a single party
monopoly of every slight advance made, except where the exercise of invention, somewhat above ordinary mechanical or engineering skill, is distinctly shown, is unjust in principle and injurious in its consequences”).
  
423
Everything Is Obvious 11
of patented technologies in research and development.31 To the extent that patents are justified, it is because they are thought to have more benefits than costs. Patents can function as innovation incentives, promote the dissemination of information, encourage commercialization of technology, and validate moral rights.32
Patents are granted for inventions that are new, nonobvious, and useful.33 Of these three criteria, obviousness is the primary hurdle for most patent applications.34 Although other patentability criteria contribute to this function, the nonobviousness requirement is the primary test for distinguishing between significant innovations and trivial advances.35 Of course, it is one thing to express a desire to only protect meaningful scientific advances, and another to come up with a workable rule that applies across every area of technology.
B. Early Attempts
The modern obviousness standard has been the culmination of hundreds of years of struggle by the Patent Office, courts, and Congress to separate the wheat from the chaff.36 As Thomas Jefferson, the first administrator of the U.S.
31. See I Think, supra note 1, at 1105–06 (discussing the costs and benefits of the patent system).
32. Id. at 1105–08. Congress’s power to grant patents is constitutional, and based on incentive theory: “To promote the progress of science . . . by securing for limited times to . . . inventors the exclusive right to their respective . . . discoveries.” U.S. CONST. art. I, § 8, cl. 8. See Mark A. Lemley, Ex Ante Versus Ex Post Justifications for Intellectual Property, 71 U. CHI. L. REV. 129, 129 (2004) (“The standard justification for intellectual property is ex ante . . . . It is the prospect of the intellectual property right that spurs creative incentives.”); see also United States v. Line Material Co., 333 U.S. 287, 316 (1948) (Douglas, J., concurring) (noting “the reward to inventors is wholly secondary” to the reward to society); THE FEDERALIST NO. 43 (James Madison) (stating that social benefit arises from patents to inventors). The U.S. Supreme Court has endorsed an economic inducement rationale in which patents should only be granted for inventions which would “not be disclosed or devised but for the inducement of a patent.” This is the inducement theory articulated in Graham v. John Deere
Co., 383 U.S. 1, 10 (1966). See also Abramowicz & Duffy, supra note 20.
33. 35 U.S.C. §§ 101–103, 112 (2018). In the European system, these criteria are referred to as novelty, inventive step, and industrial applicability. Art. 52 EPC. Inventions must also comprise patentable subject matter and be adequately disclosed. 35 U.S.C. §§ 101–103, 112
(2018).
34. DONALD CHISUM, CHISUM ON PATENTS § 5.02[6] (2007); NONOBVIOUSNESS—THE ULTIMATE
CONDITION OF PATENTABILITY 2:101 (J. Witherspoon ed., 1980). Obviousness is the most commonly litigated issue of patent validity. Allison & Lemley, supra note 20, at 208–09 (1998).
35. 35 U.S.C. §§ 101–102, 112 (2018).
36. For that matter, the struggle dates back to the very first patent law, the Venetian Act of 1474,
which stated that only “new and ingenious” inventions would be protected. See Giulio Mandich, Venetian Patents (1450–1550), 30 J. PAT. OFF. SOC’Y 166, 176–77 (1948); A. Samuel Oddi, Beyond Obviousness: Invention Protection in the Twenty-First Century, 38 AM.
  
424
12 66 UCLA L. REV. 2 (2019)
patent system and one of its chief architects, wrote, “I know well the difficulty of drawing a line between the things which are worth to the public the embarrassment of an exclusive patent, and those which are not . . . I saw with what slow progress a system of general rules could be matured.”37
The earliest patent laws focused on novelty and utility, although Jefferson didatonepointsuggestan“obviousness”requirement.38 ThePatentActof1790 was the first patent statute, and it required patentable inventions to be “sufficiently useful and important.”39 Three years later, a more comprehensive patent law was passed—the Patent Act of 1793.40 The new act did not require an invention to be “important,” but required it to be “new and useful.”41 The 1836 Patent Act reinstated the requirement that an invention be “sufficiently used and important.”42
In 1851, the Supreme Court adopted the progenitor of the skilled person and the obviousness test—an “invention” standard.43 Hotchkiss v. Greenwood
U. L. REV. 1097, 1102–03 (1989); Frank D. Prager, A History of Intellectual Property From
1545 to 1787, 26 J. PAT. OFF. SOC’Y 711, 715 (1944).
37. Letter to Isaac McPherson (Aug. 13, 1813), in 5 THE WRITINGS OF THOMAS JEFFERSON, 1790–
1826, 175, 181 (Riker, Thorne & Co. 1854) [hereinafter Letter to Isaac McPherson].
38. In 1791, Jefferson proposed amending the 1790 Patent Act to prohibit patents on an invention if it “is so unimportant and obvious that it ought not be the subject of an exclusive right.” 5 THE WRITINGS OF THOMAS JEFFERSON 278, 1788–1792, (Paul Leicester Ford ed.,
G.P. Putnam & Sons 1895).
39. Patent Act of 1790, ch. 7, 1 Stat. 109 (repealed 1793).
40. Patent Act of 1793, ch. 11, 1 Stat. 318 (repealed 1836).
41. Patent Act of 1793, ch. 11, 1 Stat. at 318–23. It also prohibited patents on certain minor
improvements: “[S]imply changing the form or the proportions of any machine, or compositions of matter, in any degree, shall not be deemed a discovery.” Id. at 321. On this basis, Jefferson, who was credited with drafting most of this statute, argued that “[a] change of material should not give title to a patent. As the making a ploughshare of cast rather than of wrought iron; a comb of iron, instead of horn or of ivory . . . .” Letter to Isaac McPherson, supra note 37, at 181.
42. Patent Act of 1836, ch. 357, § 18, 5 Stat. 117, 124 (repealed 1861).
43. See, e.g., Graham v. John Deere Co., 383 U.S. 1, 17 (1966) (“We conclude that [§ 103] was
intended merely as a codification of judicial precedents embracing the Hotchkiss condition, with congressional directions that inquiries into the obviousness of the subject matter sought to be patented are a prerequisite to patentability.”); see also S. REP. NO. 82-1979, at 6 (1952); H.R. REP. NO. 82-1923, at 7 (1952) (“Section 103 . . . provides a condition which exists in the law and has existed for more than 100 years.”). Obviousness had been at issue in earlier cases, although not necessarily in such terms. For instance, in Earle v. Sawyer, Justice Story rejected an argument by the defendant that the invention at issue was obvious, and that something more than novelty and utility was required for a patent. 8 F. Cas. 254, 255 (Cir. Ct. D. Mass. 1825). He argued a court was not required to engage in a “mode of reasoning upon the metaphysical nature, or the abstract definition of an invention.” Id. Justice Story further noted that English law permits the introducer of a foreign technology to receive a patent, and such an act could not require intellectual labor. Id. at 256. In Evans v. Eaton, the Supreme Court held that, a patent invention must involve a change in the “principle” of the machine rather than a change “merely in form and proportion.” 20 U.S.
  
425
Everything Is Obvious 13
concerned a patent for substituting clay or porcelain for a known door knob materialsuchasmetalorwood.44 TheCourtinvalidatedthepatent,holdingthat “the improvement is the work of a skillful mechanic, not that of the inventor.”45 The Court also articulated a new legal standard for patentability: “Unless more ingenuity and skill...were required...than were possessed by an ordinary mechanic acquainted with the business, there was an absence of that degree of skill and ingenuity which constitute essential elements of every invention.”46
However, the Court did not give specific guidance on what makes something inventive or the required level of inventiveness. In subsequent years, the Court made several efforts to address these deficiencies, but with limited success. As the Court stated in 1891, “[t]he truth is the word [invention] cannot be defined in such manner as to afford any substantial aid in determining whether any particular device involves an exercise of inventive faculty or not.”47 Or as one commentator noted, “it was almost impossible for one to say with any degree of certainty that a particular patent was indeed valid.”48
Around 1930, the Supreme Court, possibly influenced by a national antimonopoly sentiment, began implementing stricter criteria for determining the level of invention.49 This culminated in the widely disparaged “Flash of Genius” test articulated in Cuno Engineering v. Automatic Devices Corp.50 Namely, that in order to receive a patent, “the new device must reveal the flash of creative genius, not merely the skill of the calling.”51 This test was interpreted to mean that an invention must come into the mind of an inventor as a result of
(7 Wheat) 356, 361–62 (1822). Writing for the Court, Justice Story noted the patent was
invalid because it was “substantially the same in principle” as a prior invention. Id. at 362.
44. 52 U.S. 248, 265 (1850).
45. Id. at 267.
46. Id.
47. McClain v. Ortmayer, 141 U.S. 419, 427 (1891). Another court noted that “invention” is “as
fugitive, impalpable, wayward, and vague a phantom as exists in the paraphernalia of legal
concepts.” Harries v. Air King Prods. Co., 183 F.2d 158, 162 (2d Cir. 1950).
48. Gay Chin, The Statutory Standard of Invention: Section 103 of the 1952 Patent Act, 3 PAT.
TRADEMARK & COPY. J. RES. & EDUC. 317, 318 (1959).
49. See, e.g., Edward B. Gregg, Tracing the Concept of Patentable Invention, 13 VILL. L. REV. 98
(1967).
50. Cuno Eng’g Corp. v. Automatic Devices Corp., 314 U.S. 84, 91 (1941) (formalizing the
test). See, e.g., Hamilton Standard Propeller Co. v. Fay-Egan Mfg. Co., 101 F.2d 614, 617 (6th Cir. 1939) (“The patentee did not display any flash of genius, inspiration or imagination . . . .”). The Flash of Genius test was reaffirmed by the Court in 1950 in Great Atlantic & Pacific Tea Co. v. Supermarket Equip. Corp., 340 U.S. 147, 154 (1950) (Douglas, J., concurring).
51. Cuno Eng’g Corp., 314 U.S. at 91.
  
426
14 66 UCLA L. REV. 2 (2019)
“inventive genius”52 rather than as a “result of long toil and experimentation.”53 The Court reasoned that “strict application of the test is necessary lest in the constant demand for new appliances the heavy hand of tribute be laid on each slight technological advance in the art.”54
The Flash of Genius test was criticized for being vague and difficult to implement, and for involving subjective decisions about an inventor’s state of mind.55 It certainly made it substantially more difficult to obtain a patent.56 Extensive criticism of perceived judicial hostility toward patents resulted in President Franklin D. Roosevelt’s creation of a National Patent Planning Commissiontomakerecommendationsforimprovingthepatentsystem.57 The
52. Reckendorfer v. Faber, 92 U.S. 347, 357 (1875).
53. The Supreme Court later claimed the “Flash of Creative Genius” language was just a
rhetorical embellishment, and that requirement concerned only the device itself, not the manner of invention. Graham v. John Deere Co., 383 U.S. 1, 15 n.7, 16 n.8 (1966). That was not, however, how the test was interpreted. See P.J. Federico, Origins of Section 103, 5 APLA Q.J. 87, 97 n.5 (1977) (noting the test led to a higher standard of invention in the lower courts). In Atlantic & Pacific Tea Co. v. Supermarket Equipment Corp., 340 U.S. 147 (1950), another case cited for the proposition that the Court had adopted stricter patentability criteria, the majority did not consider the question of inventiveness, but in his concurring opinion Justice Douglas reiterated the concept of “inventive genius”: “It is not enough that an article is new and useful. The Constitution never sanctioned the patenting of gadgets. Patents serve a higher end—the advancement of science. An invention need not be as startling as an atomic bomb to be patentable. But it has to be of such quality and distinction that that masters of the scientific field in which it falls will recognize it as an advance.” Id.
54. Cuno Eng’g Corp., 314 U.S. at 92.
55. As a commentator at the time noted, “the standard of patentable invention represented by
[the Flash of Genius doctrine] is apparently based upon the nature of the mental processes of the patentee-inventor by which he achieved the advancement in the art claimed in his patent, rather than solely upon the objective nature of the advancement itself.” Comment, The “Flash of Genius” Standard of Patentable Invention, 13 FORDHAM L. REV. 84, 87 (1944). See Note, Patent Law—”Flash of Genius” Test for Invention Rejected, 5 DEPAUL L. REV. 144, 146 (1955); Stephen G. Kalinchak, Obviousness and the Doctrine of Equivalents in Patent Law: Striving for Objective Criteria, 43 CATH. U. L. REV. 577, 586 (1994); see also, Note, The Standard of Patentability—Judicial Interpretation of Section 103 of the Patent Act Source, 63 COLUM. L. REV. 306, 306 (1963) [hereinafter The Standard of Patentability] (criticizing the standard).
56. Supreme Court Justice Robert Jackson noted in a dissent that “the only patent that is valid is one which this Court has not been able to get its hands on.” Jungersen v. Ostby & Barton Co., 335 U.S. 560, 572 (1949) (Jackson, J., dissenting).
57. See William Jarratt, U.S. National Patent Planning Commission, 153 NATURE 12 (1944); see also REPORT OF THE NATIONAL PATENT PLANNING COMMISSION, NATIONAL PATENT PLANNING COMMISSION, at 6, 10 (1943).
  
427
Everything Is Obvious 15
Commission’s report recommended that Congress adopt a more objective and certain standard of obviousness.58 A decade later, Congress did.59
C. The Nonobviousness Inquiry
The Patent Act of 1952 established the modern patentability framework.60 Among other changes to substantive patent law,61 “the central thrust of the 1952 Act removed ‘unmeasurable’ inquiries into ‘inventiveness’ and instead supplied the nonobviousness requirement of Section 103.”62 Section 103 states:
A patent may not be obtained . . . if the difference between the subject matter sought to be patented and the prior art are such that the subject matter as a whole would have been obvious at the time the invention was made to a person having ordinary skill in the art to which said subject matter pertains. Patentability shall not be negatived by the manner in which the invention was made.63
58. REPORT OF THE NATIONAL PATENT PLANNING COMMISSION, supra note 57,at 5–6. “One of the greatest technical weaknesses of the patent system is the lack of a definitive yardstick as to what is invention.” Id. at 26. “The most serious weakness of the present patent system is the lack of a uniform test or standard for determining whether the particular contribution of an inventor merits the award of the patent grant.” Id. at 14. “It is proposed that Congress shall declare a national standard whereby patentability of an invention shall be determined by the objective test as to its advancement of the arts and sciences.” Id. at 26.
59. Though, Congress may not have realized what it was doing. See George M. Sirilla, 35 U.S.C. § 103: From Hotchkiss to Hand to Rich, the Obvious Patent Law Hall-of-Famers, 32 J. MARSHALL L. REV. 437, 509–14 (1999) (discussing the legislative history of the Patent Act of 1952 and the lack of congressional awareness of, and intent for, Section 103).
60. See The Standard of Patentability, supra note 55, at 309. “[P]robably no other title incorporates the thinking of so many qualified technical men throughout the country as does this revision.” L. James Harris, Some Aspects of the Underlying Legislative Intent of the Patent Act of 1952, 23 GEO. WASH. L. REV. 658, 661 (1955).
61. “The major changes or innovations in the title consist of incorporating a requirement for invention in § 103 and the judicial doctrine of contributory infringement in § 271.” H.R. REP. NO. 1923, 82d Cong., 2d Sess. 5 (1952); S. REP. NO. 1979, 82d Cong., 2d Sess. 4 (1952).
62. CLS Bank Int’l v. Alice Corp. Pty. Ltd., 717 F.3d 1269, 1296 (Fed. Cir. 2013) (Rader, J., dissenting in part, concurring in part) (citing P.J. Federidco’s Commentary on the New Patent Act, reprinted in 75 J. PAT. & TRADEMARK OFFICE SOC’Y 161, 177 (1993)). See also Dann v. Johnston, 425 U.S. 219, 225–26 (1976) (describing the shift from “an exercise of the inventive faculty” established in case law to a statutory test and stating that “it was only in 1952 that Congress, in the interest of uniformity and definiteness, articulated the requirement in a statute, framing it as a requirement of ‘nonobviousness’” (internal quotation marks and footnote omitted)). The official “Revision Notes” state § 103 is meant to be the basis for “holding . . . patents invalid by the courts[] on the ground of lack of invention.” S.REP.NO.82-1979,at18.
63. 35 U.S.C. § 103, as amended by the America Invents Act. Leahy-Smith America Invents Act, Pub. L. No. 112-29, 125 Stat. 284, 286 (2011) (codified at 35 U.S.C. § 103 (2018)). The America Invents Act did not fundamentally change the nonobviousness inquiry but did
  
428
16 66 UCLA L. REV. 2 (2019)
Section 103 legislatively disavowed the Flash of Genius test, codified the sprawling judicial doctrine on “invention” into a single statutory test, and restructured the standard of obviousness in relation to a person having ordinary skill in the art.64 However, while Section 103 may be more objective and definite than the Flash of Genius test, the meanings of “obvious” and “a person having ordinary skill” were not defined, and in practice also proved “often difficult to apply.”65
The Supreme Court first interpreted the statutory nonobviousness requirement in a trilogy of cases: Graham v. John Deere (1966) and its companion cases, Calmar v. Cook Chemical (1965) and United States v. Adams (1966).66 In these cases, the Court articulated a framework for evaluating obviousness as a question of law based on the following underlying factual inquiries: (1) the scope and content of the prior art, (2) the level of ordinary skill in the prior art, (3) the differences between the claimed invention and the prior art, and (4) objective evidence of nonobviousness.67 This framework remains applicable today. Of note, the Graham analysis does not explain how to evaluate the ultimate legal question of nonobviousness, beyond identifying underlying factual considerations.68
In 1984, the newly established United States Court of Appeals for the Federal Circuit, the only appellate-level court with jurisdiction to hear patent case appeals, devised the “teaching, suggestion, and motivation” (TSM) test for obviousness.69 Strictly applied, this test only permits an obviousness rejection when prior art explicitly teaches, suggests or motivates a combination of existing
result in some modest changes. https://www.uspto.gov/web/offices/pac/mpep/s2158.html
[https://perma.cc/TAQ7-KMCC].
64. See Giles S. Rich, Principles of Patentability, 28 GEO. WASH. U. L. REV. 393, 393–407 (1960);
see also Chin, supra note 48, at 318. In Graham, the Supreme Court noted that “[i]t . . . seems apparent that Congress intended by the last sentence of § 103 to abolish the test it believed this Court announced in the controversial phrase ‘flash of creative genius,’ used in Cuno Engineering.” Graham, 383 U.S. at 15.
65. Uniroyal, Inc. v. Rudkin-Wiley Corp., 837 F.2d 1044, 1050 (Fed. Cir. 1988) (noting the obviousness standard is easy to expound and “often difficult to apply”).
66. Graham v. John Deere Co., 383 U.S. 1 (1966); United States v. Adams, 383 U.S. 39, 51–52 (1966); Calmar v. Cook Chem., 380 U.S. 949 (1965).
67. Graham, 383 U.S. at 17. With regards to the fourth category, considerations such as commercial success and long felt but unsolved needs can serve as evidence of nonobviousness in certain circumstances. Id.
68. See Joseph Miller, Nonobviousness: Looking Back and Looking Ahead, in 2 INTELLECTUAL PROPERTY AND INFORMATION WEALTH: ISSUES AND PRACTICES IN THE DIGITAL AGE: PATENTS AND TRADE SECRETS 9 (Peter K. Yu ed., 2007) (“[T]he Court did not indicate . . . how one was to go about determining obviousness (or not).”).
69. Court Jurisdiction, U.S. CT. APPEALS FOR FED. CIR., http://www.cafc.uscourts.gov/the- court/court-jurisdiction [https://perma.cc/TE4D-GRF2].
  
429
Everything Is Obvious 17
elements into a new invention.70 The TSM test protects against hindsight bias because it requires an objective finding in the prior art. In retrospect, it is easy for an invention to appear obvious by piecing together bits of prior art using the invention as a blueprint.71
In KSR v. Teleflex (2006), the Supreme Court upheld the Graham analysis but rejected the Federal Circuit’s exclusive reliance on the TSM test. The Court instead endorsed a flexible approach to obviousness in light of “[t]he diversity of inventivepursuitsandofmoderntechnology.”72 Ratherthanapprovingasingle definitive test, the Court identified a nonexhaustive list of rationales to support a finding of obviousness.73 This remains the approach to obviousness today.
D. Finding PHOSITA
Determining the level of ordinary skill is critical to assessing obviousness.74 The more sophisticated the person having ordinary skill in the art (PHOSITA, or the skilled person), the more likely a new invention is to appear obvious.
70. ACS Hosp. Sys., Inc. v. Montefiore Hosp., 732 F.2d 1572 (Fed. Cir. 1984).
71. See In re Fritch, 972 F.2d 1260, 1266 (Fed. Cir. 1992).
72. KSR Int’l Co. v. Teleflex Inc., 550 U.S. 398, 402 (2007). “[An obviousness] analysis need not
seek out precise teachings directed to the specific subject matter of the challenged claim, for a court can take account of the inferences and creative steps that a [PHOSITA] would employ.” Id. at 418.
73. These post-KSR rationales include:
(A) Combining prior art elements according to known methods to yield predictable results; (B) Simple substitution of one known element for another to obtain predictable results; (C) Use of known technique to improve similar devices (methods, or products) in the same way; (D) Applying a known technique to a known device (method, or product) ready for improvement to yield predictable results; (E) ‘Obvious to try’—choosing from a finite number of identified, predictable solutions, with a reasonable expectation of success; (F) Known work in one field of endeavor may prompt variations of it for use in either the same field or a different one based on design incentives or other market forces if the variations are predictable to one of ordinary skill in the art; (G) Some teaching, suggestion, or motivation in the prior art that would have led one of ordinary skill to modify the prior art reference or to combine prior art reference teachings to arrive at the claimed invention.
2141 Examination Guidelines for Determining Obviousness Under 35 U.S.C. 103 [R- 08.2017], U.S. PAT. & TRADEMARK OFF., https://www.uspto.gov/web/offices/pac/mpep/ s2141.html [http://perma.cc/EE7P-4CQ9] [hereinafter 2141 Examination Guidelines].
74. Ruiz v. A.B. Chance Co., 234 F.3d 654, 666 (Fed. Cir. 2000); see also Ryko Mfg. Co., v. Nu- Star, Inc.,950 F.2d 714 718 (Fed. Cir. 1991) (“The importance of resolving the level of ordinary skill in the art lies in the necessity of maintaining objectivity in the obviousness inquiry.”). The skilled person is relevant to many areas of patent law, including claim construction, best mode, definiteness, enablement, and the doctrine of equivalents. See Dan L. Burk & Mark A. Lemley, Is Patent Law Technology-Specific?, 17 BERKELEY TECH. L.J. 1155, 1186–87 (2002).
  
430
18 66 UCLA L. REV. 2 (2019)
Thus, it matters a great deal whether the skilled person is a “moron in a hurry”75 or the combined “masters of the scientific field in which an [invention] falls.”76
The skilled person has never been precisely defined, although judicial guidance exists.77 In KSR, the Supreme Court described the skilled person as “a person of ordinary creativity, not an automaton.”78 The Federal Circuit has explained the skilled person is a hypothetical person, like the reasonable person in tort law,79 who is presumed to have known the relevant art at the time of the invention.80 The skilled person is not a judge, amateur, person skilled in remote arts, or a set of “geniuses in the art at hand.”81 The skilled person is “one who thinks along the line of conventional wisdom in the art and is not one who undertakes to innovate.”82
The Federal Circuit has provided a nonexhaustive list of factors to consider in determining the level of ordinary skill: (1) “type[s] of problems encountered in the art,” (2) “prior art solutions to those problems,” (3) “rapidity with which innovations are made,” (4) “sophistication of the technology,” and (5) “educational level of active workers in the field.”83 In any particular case, one or more factors may predominate, and not every factor may be relevant.84 The
75. Morning Star Coop. Soc’y v. Express Newspapers Ltd. [1979] FSR 113 (marking the first use of the term “moron in a hurry” as a standard for trademark confusion).
76. Great Atl. & Pac. Tea Co. v. Supermarket Equip. Corp., 340 U.S. 147, 155 (1950).
77. See James B. Gambrell & John H. Dodge, II, Ordinary Skill in the Art—An Enemy of the Inventor or a Friend of the People?, in NONOBVIOUSNESS—THE ULTIMATE CONDITION OF PATENTABILITY 5:302 (John F. Witherspoon ed., 1980) (“[T]he Supreme Court in particular, but other courts as well, has done precious little to define the person of ordinary skill in the
art.”).
78. KSR Int’l Co. v. Teleflex Inc., 550 U.S. 398, 421 (2007). The MPEP provides guidance on the
level of ordinary skill in the art. MPEP § 2141.03. See John F. Duffy & Robert P. Merges, The Story of Graham v. John Deere Company: Patent Law’s Evolving Standard of Creativity, in INTELLECTUAL PROPERTY STORIES 110 (Jane C. Ginsburg & Rochelle Cooper Dreyfuss eds., 2006) (noting that determining the appropriate level of ordinary skill for the nonobviousness standard “is one of the most important policy issues in all of patent law”).
79. See, e.g., Panduit Corp. v. Dennison Mfg. Co., 810 F.2d 1561, 1566 (Fed. Cir. 1987) (“[T]he decision maker confronts a ghost, i.e., ‘a person having ordinary skill in the art,’ not unlike the ‘reasonable man’ and other ghosts in the law.”).
80. 2141 Examination Guidelines, supra note 73.
81. Envtl. Designs Ltd. v. Union Oil Co. of Cal., 713 F.2d 693, 697 (Fed. Cir. 1983).
82. Standard Oil Co. v. Am. Cyanamid Co., 774 F.2d 448, 454 (Fed. Cir. 1985).
83. In re GPAC Inc., 57 F.3d 1573, 1579 (Fed. Cir. 1995).
84. Id.; Custom Accessories, Inc. v. Jeffrey-Allan Indus., Inc., 807 F.2d 955, 962–63 (Fed. Cir.
1986). Previously, this list of factors included the “educational level of the inventor.” Envtl. Designs, Ltd.,713 F.2d at 696. That was until the Federal Circuit announced that, “courts never have judged patentability by what the real inventor/applicant/patentee could or would do.” Kimberly-Clark Corp. v. Johnson & Johnson, 745 F.2d 1437, 1454 (Fed. Cir. 1984). Instead, “[r]eal inventors, as a class, vary in the capacities from ignorant geniuses to Nobel
  
431
Everything Is Obvious 19
skilled person standard thus varies according to the invention in question, its field of art, and researchers in the field.85 In the case of a simple invention in a field where most innovation is created by laypersons, such as, for instance, a device to keep flies away from horses, the skilled person may be someone with little education or practical experience.86 By contrast, where an invention is in a complex field with highly educated workers such as chemical engineering or pharmaceuticalresearch,theskilledpersonmaybequitesophisticated.87 Atleast in Europe, the skilled person may even be a team of individuals where collaborative approaches to research are the norm.88
laureates; the courts have always applied a standard based on an imaginary work of their
own devising whom they have equated with the inventor.” Id.
85. See, e.g., DyStar Textilfarben GmbH & Co. Deutschland KG, 464 F.3d 1356, 1370 (Fed. Cir.
2006). The court writes:
If the level of skill is low, for example that of a mere dyer, as Dystar has suggested, then it may be rational to assume that such an artisan would not think to combine references absent explicit direction in a prior art reference. . . . [If] the level of skill is that of a dyeing process designer, then one can assume comfortably that such an artisan will draw ideas from chemistry and systems engineering—without being told to do so.
Daiichi Sankyo Co. v. Apotex, Inc. concerned a patent for treating ear infections by applying an antibiotic to the ear. 501 F.3d 1254, 1257 (Fed. Cir. 2007). The district court found that the skilled person “would have a medical degree, experience treating patients with ear infections, and knowledge of the pharmacology and use of antibiotics.” Id. “This person would be . . . a pediatrician or general practitioner—those doctors who are often the ‘first line of defense’ in treating ear infections and who, by virtue of their medical training, possess basic pharmacological knowledge.” Id. The Federal Circuit overturned this finding, holding that rather, a person of ordinary skill in the art was “a person engaged in developing new pharmaceuticals, formulations and treatment methods, or a specialist in ear treatments such as an otologist, otolaryngologist, or otorhinolaryngologist who also has training in pharmaceutical formulations.” Id. Courts have employed a flexible approach to considering informal education. See, e.g., Penda Corp. v. United States., 29 Fed. Cl. 533, 565 (1993). For instance, in Bose Corp. v. JBL, Inc., the District Court found that keeping “up with current literature and trade magazines to keep abreast of new developments” could be the equivalent of “a bachelor of science degree in electrical engineering, physics, mechanical engineering, or possibly acoustics.” 112 F. Supp. 2d 138, 155 (D. Mass. 2000).
86. See Graham v. Gun-Munro, No. C-99-04064 CRB, 2001 U.S. Dist. LEXIS 7110, at *19 (N.D. Cal. May 22, 2001) (holding that the skilled person had some formal education but no special training in the field of art in a case regarding fly wraps for the legs of horses).
87. See Imperial Chem. Indus., PLC v. Danbury Pharmacal, Inc., 777 F. Supp. 330, 371–72 (D. Del. 1991) (holding that the skilled person in the chemical industry is an organic chemist with a PhD); see also Envtl. Designs, Ltd. v. Union Oil Co. of Cal., 713 F.2d 693, 697 (Fed. Cir. 1983) (noting the respective chemical expert witnesses of the parties with extensive backgrounds in sulfur chemistry were skilled persons).
88. Guidelines for Examination, EUR. PAT. OFF., http://www.epo.org/law-practice/legal- texts/html/guidelines/e/g_vii_3.htm [https://perma.cc/XFY3-JD8J] (“There may be instances where it is more appropriate to think in terms of a group of persons, e.g. a research or production team, rather than a single person.”). See, e.g., MedImmune v. Novartis Pharm. U.K., Ltd., [2012] EWCA Civ. 1234 (evaluating obviousness from the perspective of
  
432
20 66 UCLA L. REV. 2 (2019)
E. Analogous Prior Art
Determining what constitutes prior art is also central to the obviousness inquiry.89 On some level, virtually all inventions involve a combination of known elements.90 The more prior art can be considered, the more likely an invention is to appear obvious. To be considered for the purposes of obviousness, prior art must fall within the definition for anticipatory references under Section 102 and must additionally qualify as “analogous art.”91
Section 102 contains the requirement for novelty in an invention, and it explicitly defines prior art.92 An extraordinarily broad amount of information qualifies as prior art, including any printed publication made available to the publicpriortofilingapatentapplication.93 Courtshavelongheldthatinventors arechargedwithconstructiveknowledgeofallpriorart.94 Whilenorealinventor could have such knowledge,95 the social benefits of this rule are thought to outweigh its costs.96 Granting patents on existing inventions could prevent the
a “skilled team”). The “[P]atent is addressed to a team of scientists with differing backgrounds in areas such as immunology, in particular antibody structural biology, molecular biology and protein chemistry, but with a common interest in antibody engineering.” Id. In the United States, the idea that the skilled person could be a group of individuals has been discussed in academic literature, but may not have been explicitly adopted by the courts. See, e.g., Jonathan J. Darrow. The Neglected Dimension of Patent Law’s PHOSITA Standard, 23 HARV. J.L. & TECH. 227, 244, 257 (2009). A “skilled persons” standard would seem to be appropriate given that most patents are now filed with more than one inventor. Dennis Crouch, PHOSITA: Not a Person—People Having Ordinary Skill in the Art, PATENTLY-O (June 7, 2018), https://patentlyo.com/patent/2018/06/phosita-not-a- person-people-having-ordinary-skill-in-the-art.html [https://perma.cc/UAK2-5NT8] (noting that most patents have multiple inventors).
89. This is the second inquiry of the Graham analysis described earlier.
90. See, e.g., Ryko Mfg. Co. v. Nu-Star, Inc., 950 F.2d 714, 718 (Fed. Cir. 1991).
91. In re Bigio, 381 F.3d 1320, 1325 (Fed. Cir. 2004).
92. 35 U.S.C. § 102 (2018).
93. Id. § 102(a)(1); see MPEP § 2152 for a detailed discussion of what constitutes prior art.
Almost anything in writing is prior art. “A U.S. patent on the lost wax casting technique was invalidated on the basis of Benvenuto Cellini’s 16th century autobiography which makes mention of a similar technique.” See Michael Ebert, Superperson and the Prior Art, 67 J. PAT. & TRADEMARK OFF. SOC’Y 657, 658 (1985).
94. In Mast, Foos, & Co. v. Stover Manufacturing Co., the Supreme Court applied a presumption that the skilled person is charged with constructive knowledge of all prior art: “Having all these various devices before him, and whatever the facts may have been, he is chargeable with a knowledge of all preexisting devices.” 177 U.S. 485, 493 (1900) (emphasis added) (further, “we must presume the patentee was fully informed of everything which preceded him, whether such were the actual fact or not”).
95. See, e.g., In re Wood, 599 F.2d 1032, 1036 (C.C.P.A. 1979) (“[A]n inventor could not possibly be aware of every teaching in every art.”).
96. See Bonito Boats, Inc. v. Thunder Craft Boats, Inc., 489 U.S. 141, 147–48 (1989) (reciting that Thomas Jefferson, the “driving force behind early federal patent policy,” believed that
  
433
Everything Is Obvious 21
public from using something it already had access to, and remove knowledge from the public domain.97
For the purposes of obviousness, prior art under Section 102 must also qualify as analogous. That is to say, the prior art must be in the field of an applicant’s endeavor, or reasonably pertinent to the problem with which the applicant was concerned.98 A real inventor would be expected to focus on this type of information. The “analogous art” rule better reflects practical conditions, and it ameliorates the harshness of the definition of prior art for novelty given that prior art references may be combined for purposes of obviousness but not novelty.99 Consequently, for the purposes of obviousness, the skilled person is presumed to have knowledge of all prior art within the field of an invention, as well as prior art reasonably pertinent to the problem the invention solves. Restricting the universe of prior art to analogous art lowers the bar to patentability.100
“a grant of patent rights in an idea already disclosed to the public [i]s akin to an ex post facto law, ‘obstruct[ing] others in the use of what they possessed before’” (quoting Letter to Isaac McPherson, supra note 37, at 176)); Graham v. John Deere Co., 383 U.S. 1, 5–6 (1966) (stating that granting patents on non-novel inventions would remove knowledge from the public domain).
97. Graham, 383 U.S. at 5–6.
98. See, e.g., Wyers v. Master Lock Co., 616 F.3d 1231, 1237 (Fed. Cir. 2010) (“Two criteria are
relevant in determining whether prior art is analogous: ‘(1) whether the art is from the same field of endeavor, regardless of the problem addressed, and (2) if the reference is not within the field of the inventor’s endeavor, whether the reference still is reasonably pertinent to the particular problem with which the inventor is involved.’” (quoting Comaper Corp. v. Antec, Inc., 596 F.3d 1343, 1351 (Fed. Cir. 2010)). “Under the correct analysis, any need or problem known in the field of endeavor at the time of the invention and addressed by the patent [or application at issue] can provide a reason for combining the elements in the manner claimed.” KSR Int’l Co. v. Teleflex Inc., 550 U.S. 398, 420 (2007). Prior art in other fields may sometimes be considered as well. Id. at 417. The general question is whether it would have been “reasonable” for the skilled person to consider a piece of prior art to solve their problem. In re Clay, 966 F.2d 656 (Fed. Cir. 1992). To be “reasonably pertinent,” prior art must “logically [] have commended itself to an inventor’s attention in considering his problem.” Id.
99. See In re Wood, 599 F.2d 1032, 1036 (C.C.P.A. 1979) (“The rationale behind this rule precluding rejections based on combination of teachings of references from nonanalogous arts is the realization that an inventor could not possibly be aware of every teaching in every art.”). The rule “attempt[s] to more closely approximate the reality of the circumstances surrounding the making of an invention by only presuming knowledge by the inventor of prior art in the field of his endeavor and in analogous arts.” Id.
100. See Margo A. Bagley, Internet Business Model Patents: Obvious by Analogy, 7 MICH. TELECOMM. & TECH. L. REV. 253, 270 (2001) (arguing that prior to the analogous arts test references were rarely excluded as prior art); see also Jacob S. Sherkow, Negativing Invention, 2011 BYU L. REV. 1091, 1094–95 (2011) (noting that once a relevant piece of prior art is classified as analogous, an obviousness finding is often inevitable).
  
434
22 66 UCLA L. REV. 2 (2019)
The analogous art requirement was most famously conceptualized in the case of In re Winslow, in which the court explained a decisionmaker was to “picture the inventor as working in his shop with the prior art references—which he is presumed to know—hanging on the walls around him.”101 Or, as Judge Learned Hand presciently remarked, “the inventor must accept the position of a mythically omniscient worker in his chosen field. As the arts proliferate with prodigious fecundity, his lot is an increasingly hard one.”102
II. MACHINE INTELLIGENCE IN THE INVENTIVE PROCESS A. Automating and Augmenting Research
Artificial intelligence (AI), which is to say a computer able to perform tasks normally requiring human intelligence, is playing an increasingly important role in innovation.103 For instance, IBM’s flagship AI system “Watson” is being used exploratively to conduct research in drug discovery, as well as clinically to analyze the genes of cancer patients and develop treatment plans.104 In drug discovery, Watson has already identified novel drug targets and new indications for existing drugs.105 In doing so, Watson may be generating patentable inventions either autonomously or collaboratively with human researchers.106 Inclinicalpractice,Watsonisalsoautomatingaoncehumanfunction.107 Infact, according to IBM, Watson can interpret a patient’s entire genome and prepare a clinically actionable report in ten minutes, a task which otherwise requires
101. In re Winslow, 365 F.2d 1017, 1020 (C.C.P.A. 1966).
102. Merit Mfg. Co. v. Hero Mfg. Co., 185 F.2d 350, 352 (2d Cir. 1950).
103. See, e.g., DATA SCI. ASS’N, OUTLOOK ON ARTIFICIAL INTELLIGENCE IN THE ENTERPRISE 3, 6
(2016), http://www.datascienceassn.org/sites/default/files/Outlook%20on%20Artificial% 20Intelligence%20in%20the%20Enterprise%202016.pdf [hereinafter Outlook on AI] (a survey of 235 business executives conducted by the National Business Research Institute (NBRI) which found that 38 percent of enterprises were using AI technologies in 2016, and 62 percent will likely use AI technologies by 2018).
104. IBM Watson for Drug Discovery, IBM, https://www.ibm.com/watson/health/life- sciences/drug-discovery [https://perma.cc/DQ4D-ZKJF]; IBM Watson for Genomics, IBM, https://www.ibm.com/watson/health/oncology-and-genomics/genomics [https://perma.cc/8XK7-S8DN].
105. Ying Chen et al., IBM Watson: How Cognitive Computing Can Be Applied to Big Data Challenges in Life Sciences Research, 38 CLINICAL THERAPEUTICS 688 (2016), https://www.medicalaffairs.org/app/uploads/2018/02/Chen_2016_IBM_Watson.pdf.
106. See generally Hal the Inventor, supra note 3 (discussing the “hypothetical” example of an AI system being used in drug discovery to identify new drug targets and indications for existing drugs).
107. Kazimierz O. Wrzeszczynski et al., Comparing Sequencing Assays and Human-Machine Analyses in Actionable Genomics for Glioblastoma, 3 NEUROLOGY GENETICS e164 (2017), http://ng.neurology.org/content/3/4/e164 [https://perma.cc/3LGH-TKPW].
  
435
Everything Is Obvious 23
around 160 hours of work by a team of experts.108 A recent study by IBM found that Watson’s report outperformed the standard practice.109
Watson is largely structured as an “expert system,” although Watson is not a single program or computer—the brand incorporates a variety of technologies.110 Here, Watson will be considered a single software program in the interests of simplicity. Expert systems are one way of designing AI that solve problems in a specific domain of knowledge using logical rules derived from the knowledge of experts. These were a major focus of AI research in the 1980s.111 Expert system-based chess-playing programs HiTech and Deep Thought defeated chess masters in 1989, paving the way for another famous IBM computer, Deep Blue, to defeat world chess champion Garry Kasparov in 1997.112 But Deep Blue had limited utility—it was solely designed to play chess. The machine was permanently retired after defeating Kasparov.113
Google’s leading AI system DeepMind is an example of another sort of inventive machine. DeepMind uses an artificial neural network, which essentially consists of many highly interconnected processing elements working together to solve specific problems.114 The design of neural networks is inspired by the way the human brain processes information.115 Like the human brain, neuralnetworkscanlearnbyexampleandfrompractice.116 Examplesforneural networks come in the form of data, so more data means improved performance.117 Thishasledtodatabeingdescribedasthenewoilofthetwenty- firstcentury,andthefuelformachinelearning.118 Developersmaynotbeableto
108. Id.
109. Id.
110. See Richard Waters, Artificial Intelligence: Can Watson Save IBM?, FINANCIAL TIMES (Jan. 5,
2016), https://www.ft.com/content/dced8150-b300-11e5-8358-9a82b43f6b2f [https://perma.cc/ J3N6-QMP3]; see also Will Knight, IBM’s Watson Is Everywhere—But What Is It?, MIT TECH. REV, (Oct. 27, 2016), https://www.technologyreview.com/s/602744/ibms-watson-is- everywhere-but-what-is-it [http://perma.cc/YK3Q-HRQB].
111. STUART J. RUSSELL & PETER NORVIG, ARTIFICIAL INTELLIGENCE: A MODERN APPROACH 22–23 (2d ed. 2002) (1995).
112. IBM’s 100 Icons of Progress: Deep Blue, IBM http://www-03.ibm.com/ibm/history/ibm100/ us/en/icons/deepblue/words [https://perma.cc/7SG3-UYST].
113. Id.
114. KEVIN GURNEY, AN INTRODUCTION TO NEURAL NETWORKS 1–4 (1997). The first neural
network was built in 1951. See, e.g., RUSSELL & NORVIG, supra note 111.
115. See, e.g., Volodymyr Mnih et al., Human-Level Control Through Deep Reinforcement
Learning, 518 NATURE 529, 529–33 (2015).
116. See GURNEY, supra note 114, at 1–4.
117. PEDRO DOMINGOS, THE MASTER ALGORITHM: HOW THE QUEST FOR THE ULTIMATE LEARNING
MACHINE WILL REMAKE OUR WORLD xi (2015).
118. See, e.g., Michael Palmer, Data Is the New Oil, ANA MARKETING MAESTROS (Nov. 3, 2006).
  
436
24 66 UCLA L. REV. 2 (2019)
understand exactly how a neural network processes data or generates a particular output.
In 2016, DeepMind developed an algorithm known as AlphaGo which beat a world champion of the traditional Chinese board game Go, and then the world’sleadingplayerin2017.119 Gowasthelasttraditionalboardgameatwhich people had been able to outperform machines.120 AlphaGo’s feat was widely lauded in the artificial intelligence community because Go is exponentially more complicatedthanchess.121 Currentcomputerscannot“solve”Gosolelybyusing “brute force” computation to determine the optimal move to any potential configurationinadvance.122 TherearemorepossibleboardconfigurationsinGo than there are atoms in the universe.123 Rather than being preprogrammed with a number of optimal Go moves, DeepMind used a general-purpose algorithm to interpret the game’s patterns.124 DeepMind is now working to beat human players at the popular video game StarCraft II.125
AI like DeepMind is proving itself and training by playing games, but similar techniques can be applied to other challenges requiring recognition of complex patterns, long-term planning, and decisionmaking.126 DeepMind is already being applied to solve practical problems. For instance, it has helped decrease cooling costs at company datacenters.127 DeepMind is working to
119. David Silver et al., Mastering the Game of Go With Deep Neural Networks and Tree Search, 529 NATURE 484, 484–89 (2016). In 2015, DeepMind attained “human-level performance in video games” playing a series of class Atari 2600 games. Mnih et al., supra note 115, at 529. See also, Cade Metz, https://www.wired.com/2017/05/googles-alphago-continues- dominance-second-win-china [https://perma.cc/WA9G-JUGK].
120. See Richard Haridy, 2017: The Year AI Beat Us at All Our Own Games, NEW ATLAS (Dec. 26. 2017), https://newatlas.com/ai-2017-beating-humans-games/52741 [https://perma.cc/ AH2Y-6FFD].
121. Silver et al, supra note 119.
122. Id.; cf. Cade Metz, One Genius’ Lonely Crusade to Teach a Computer Common Sense, WIRED
(Mar. 24, 2016), [hereinafter Lonely Crusade] https://www.wired.com/2016/03/ doug- lenat-artificial-intelligence-common-sense-engine [https://perma.cc/WN2G-5CU9] (arguing that brute force computation was part of AlphaGo’s functionality).
123. 10170, or thereabouts. Silver et al, supra note 119.
124. Silver et al, supra note 119.
125. Tom Simonite, Google’s AI Declares Galactic War on StarCraft, WIRED (Aug. 9, 2017),
https://www.wired.com/story/googles-ai-declares-galactic-war-on-starcraft- [http://perma.cc/3VZJ-XXJV]. Compared with Go, StarCraft is vastly more complex. It involves high levels of strategic thinking and acting with imperfect information. Id.
126. Game playing has long been a proving ground for AI, as far back as what may have been the very first AI program in 1951. See Jack Copeland, A Brief History of Computing, ALANTURING.NET (June 2000) http://www.alanturing.net/turing_archive/pages/Reference% 20Articles/BriefHistofComp.html [https://perma.cc/82JN-UC93]. That program played checkers and was competitive with amateurs. Id.
127. See Simonite, supra note 125.
  
437
Everything Is Obvious 25
develop an algorithm to distinguish between healthy and cancerous tissues, and to evaluate eye scans to identify early signs of diseases leading to blindness.128 The results of this research may well be patentable.
Ultimately, the developers of DeepMind hope to create Artificial General Intelligence (AGI).129 Existing, “narrow” or specific AI (SAI) systems focus on discrete problems or work in specific domains. For instance, “Watson for Genomics” can analyze a genome and provide a treatment plan, and “Chef Watson” can develop new food recipes by combining existing ingredients. However, Watson for Genomics cannot respond to open-ended patient queries about their symptoms. Nor can Chef Watson run a kitchen. New capabilities could be added to Watson to do these things, but Watson can only solve problems it has been programmed to solve.130 By contrast, AGI would be able to successfully perform any intellectual task a person could.
AGI could even be set to the task of self-improvement, resulting in a continuously improving system that surpasses human intelligence—what philosopher Nick Bostrom has termed Artificial SuperIntelligence (ASI).131 Such an outcome has been referred to as the intelligence explosion or the technological singularity.132 ASI could then innovate in all areas of technology, resulting in progress at an incomprehensible rate. As the mathematician Irving John Good wrote in 1965, “the first ultraintelligent machine is the last invention that man need ever make.”133
128. Chris Baraniuk, Google’s DeepMind to Peek at NHS Eye Scans for Disease Analysis, BBC (July 5, 2016), https://www.bbc.com/news/technology-36713308 [https://perma.cc/ WA6R- RUX3]; Chris Baraniuk, Google DeepMind Targets NHS Head and Neck Cancer Treatment, BBC (Aug. 31, 2016), https://www.bbc.com/news/technology-37230806 [http://perma.cc/6GAN-7EAZ].
129. Solving Intelligence Through Research, DEEPMIND, https://deepmind.com/research [https://perma.cc/7TC2-49B8].
130. See, e.g., Lonely Crusade, supra note 122.
131. See generally NICK BOSTROM, SUPERINTELLIGENCE: PATHS, DANGERS, STRATEGIES (2014).
132. See generally RAY KURZWEIL, THE SINGULARITY IS NEAR: WHEN HUMANS TRANSCEND
BIOLOGY (2005).
133. Irving John Good, Speculations Concerning the First Ultraintelligent Machine, 6 ADVANCES
IN COMPUTERS 31, 33 (1965)
Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind.... Thusthefirstultraintelligentmachineisthelastinventionthatman need ever make . . . .
Id. at 32–33.
  
438
26 66 UCLA L. REV. 2 (2019)
Experts are divided on when, and if, AGI will be developed. Many industry leaders predict based on historical trends that AGI will occur within the next couple of decades.134 Others believe the magnitude of the challenge has been underestimated, and that AGI may not be developed in this century.135 In 2013, hundreds of AI experts were surveyed on their predictions for AGI development.136 On average, participants predicted a 10 percent likelihood that AGI would exist by 2022, a 50 percent likelihood it would exist by 2040, and a 90 percent likelihood it would exist by 2075.137 In a similar survey, 42 percent of participants predicted AGI would exist by 2030, and an additional 25 percent predicted AGI by 2050.138 In addition, 10 percent of participants reported they believed ASI would develop within two years of AGI, and 75 percent predicted this would occur within 30 years.139 The weight of expert opinion thus holds artificial general intelligence and superintelligence will exist this century. In the meantime, specific artificial intelligence is getting ever better at outcompeting people at specific tasks—including invention.
B. Timeline to the Creative Singularity
We are amid a transition from human to machine inventors. The following five-phase framework illustrates this transition and divides the history and future of inventive AI into several stages.
134. Pawel Sysiak, When Will the First Machine Become Superintelligent?, AI REVOLUTION, (Apr. 11, 2016), https://medium.com/ai-revolution/when-will-the-first-machine-become- superintelligent-ae5a6f128503 [https://perma.cc/7YUP-DEYM].
135. Id. In fairness, history also reflects some overly optimistic predictions. In 1970, Marvin Minsky, one of the most famous AI thought leaders, was quoted in Life Magazine as stating, “In from three to eight years we will have a machine with the general intelligence of an average human being.” Brad Darrach, Meet Shaky, the First Electronic Person, LIFE, Nov. 20 1970, at 58B, 66, 68.
136. See Müller & Bostrom, supra note 7.
137. Id. Participants were asked to provide an optimistic year for AGI’s development (10 percent
likelihood), a realistic year (50 percent likelihood), and a pessimistic year (90 percent likelihood). The median responses were 2022 as an optimistic year, 2040 as a realistic year, and 2075 as a pessimistic year. Id.
138. A survey conducted at an annual AGI Conference reported that 42 percent believed AGI would exist by 2030, 25 percent by 2050, 20 percent by 2100, 10 percent after 2010, and 2 percent never. See JAMES BARRAT, OUR FINAL INVENTION: ARTIFICIAL INTELLIGENCE AND THE END OF THE HUMAN ERA 152 (2013). For instance, Demis Hassabis, the founder of DeepMind, believes AGI is still decades away. David Rowan, DeepMind: Inside Google’s Super-Brain, WIRED (June 22, 2015), https://www.wired.co.uk/article/deepmind [https://perma.cc/MM6P-EU43].
139. See Müller & Bostrom, supra note 7.
  
439
Everything Is Obvious
I Human
III Human ~ SAI
27
   Phase
 Inventors
 Skilled Standard
 Timeframe
 Person
Augmented Person ~ SAI
Past
Short Term
  II
 Human > SAI
 Augmented Person
 Present
   IV
 SAI~AGI> Human
 Augmented AGI
 Medium Term
 V ASI ASI LongTerm
Table 1: Evolution of Machine Invention
  SAI = Specific Artificial Intelligence; AGI = Artificial General Intelligence; ASI = Artificial Superintelligence; ~ = competing; > = outcompeting
 Previously, in Phase I, all invention was created by people. If a company wanted to solve an industrial problem, it asked a research scientist, or a team of research scientists, to solve the problem. Phase I ended when the first patent was granted for an invention created by an autonomous machine—likely 1998 or earlier.140 It may be difficult to determine precisely when the first patent was issued for an autonomous machine invention, as there is no obligation to report the role of machines in patent applications. Still, any number of patents have likely been issued to inventions autonomously generated by machines.141 In 1998, a patent was issued for an invention autonomously developed by a neural network-based system known as the Creativity Machine.142
140. Phase I might also be distinguished by the first time a machine invented anything independently of receiving a patent. However, using the first granted patent application is a better benchmark. It is an external measure of a certain threshold of creativity, and it represents the first time a computer automated the role of a patent inventor. Of course, there is a degree of subjectivity in a patent examiner determining whether an invention is new, nonobvious, and useful. What is nonobvious to one examiner may be obvious to another. See, e.g., Iain M. Cockburn et al., Are All Patent Examiners Equal? The Impact of Characteristics on Patent Statistics and Litigation Outcomes, in PATENTS IN THE KNOWLEDGE- BASED ECONOMY, (Wesley M. Cohen & Steven A. Merrill eds., 2003) (describing significant interexaminer variation).
141. See generally, I Think, supra note 1, at 1083–91 (describing patents issued for “computational invention”).
142. Id. at 1083–86.
 
440
28 66 UCLA L. REV. 2 (2019)
Patents may have been granted on earlier machine inventions. For instance, an article published in 1983 describes experiments with an AI program known as Eurisko, in which the program “invent[ed] new kinds of three- dimensional microelectronic devices . . . novel designs and design rules have emerged.”143 Eurisko was an early, expert AI system for autonomously discovering new information.144 It was programmed to operate according to a series of rules known as heuristics, but it was able to discover new heuristics and usethesetomodifyitsownprogramming.145 Todesignnewmicrochips,Eurisko was programmed with knowledge of basic microchips along with simple rules and evaluation criteria.146 It would then combine existing chip structures together to create new designs, or mutate existing entities.147 The new structure would then be evaluated for interest and either retained or discarded.148 Several references suggest a patent was granted for one of Eurisko’s chip designs in the mid–1980s.149
Although, after investigating those references for this article, the references appear to refer to a patent application filed for the chip design by Stanford University in 1980 which the University abandoned for unknown reasons in 1984.150 Thus, a patent was never issued. Also, as with other publicly described
143. Douglas B. Lenat et al., Heuristic Search for New Microcircuit Structures: An Application of Artificial Intelligence, 3 AI MAG. , 17, 17 (1982).
144. Eurisko was created by Douglas Lenat as the successor to the Automated Mathematician (AM). See generally Douglas B. Lenat & John Seely Brown, Why AM and EURISKO Appear to Work, 23 AI MAG., 269, 269–94 (1983). AM was an “automatic programming system” that could modify its own computer code, relying on heuristics. Id. Eurisko was a subsequent iteration of the machine designed to additionally develop new heuristics and incorporate those into its function. Id.
145. See Douglas B. Lenat et al., supra note 143.
146. Id.
147. Id.
148. Id.
149. See, e.g., RICHARD FORSYTH & CHRIS NAYLOR, THE HITCHHIKER’S GUIDE TO ARTIFICIAL INTELLIGENCE IBM PC BASIC VERSION 2167 (1986); see also MARGARET A. BODEN, THE CREATIVE MIND: MYTHS AND MECHANISMS 228 (2004).
150. U.S. provisional patent application SN 144,960, April 29, 1980. Email From Katherine Ku, Dir. of Stanford Office of Tech. Licensing, to author (Jan. 17, 2018) (on file with author). Douglas Lenat, CEO of Cycorp, Inc., who wrote Eurisko and performed the above- mentioned research, reported that this work was done “before the modern rage about patenting things . . . ” and that in his opinion Eurisko had independently created a number of patentable inventions. See Telephone Interview With Douglas Lenat, CEO, Cycorp, Inc. (Jan. 12, 2018). He further reported that after Eurisko came up with the chip design, Professor James Gibbons at Stanford successfully built a chip based on the machine’s design. Id. This chip was the subject of a patent application by Stanford, but the application was abandoned in 1984. U.S. provisional patent application SN 144,960, supra. Prior to the present investigation, Stanford had purged its paper file for the application and so no longer had records reflecting the reason for the abandonment. Email From Katherine Ku, supra.
  
441
Everything Is Obvious 29
instances of patent applications claiming the output of inventive machines, the patent application was filed on behalf of natural persons.151 In this case, they were the individuals who had built a physical chip based on Eurisko’s design.152
In the present, Phase II, machines and people are competing and cooperating at inventive activity. However, in all technological fields, human researchers are the norm and thus best represent the skilled person standard. While AI systems are inventing, it is unclear to what extent this is occurring: Inventive machine owners may not be disclosing the extent of such machines in the inventive process, due to concerns about patent eligibility or because companies generally restrict information about their organizational methods to maintain a competitive advantage. This phase will reward early adopters of inventive machines which are able to outperform human inventors at solving specific problems, and whose output can exceed the skilled person standard. In 2006, for instance, NASA recruited an autonomously inventive machine to design an antenna that flew on NASA’s Space Technology 5 (ST5) mission.153
While there may now only be a modest amount of autonomous154 machine invention, human inventors are being widely augmented by creative computers. For example, a person may design a new battery using a computer to perform calculations, search for information, or run simulations on new designs. The computer does not meet inventorship criteria, but it does augment the capabilities of a researcher in the same way that human assistants can help reduce an invention to practice. Depending on the industry researchers work in and the
Incidentally, Dr. Lenat is now continuing to develop an expert system-based AI that can use logical deduction and inference reasoning based on “common sense knowledge,” as opposed to a system like Watson that recognizes patterns in very large datasets. Id. He also states that his current company has developed numerous patentable inventions, but that it has not filed for patent protection, because he believes that, at least with regards to software, the downside of patents providing competitors with a roadmap to copying patented technology exceeds the value of a limited term patent. Id.
151. See I Think, supra note 1, at 1083–91 (describing instances of “computational invention”).
152. Email From Katherine Ku, supra note 150. Whether the individual(s) designing a chip or building a chip would qualify as inventor(s) would depend on the specific facts of the case and who “conceived” of the invention. See generally Hal the Inventor, supra note 3
(discussing standards for inventorship).
153. Gregory S. Hornby et al., Automated Antenna Design With Evolutionary Algorithms, AM.
INST. AERONAUTICS & ASTRONAUTICS (2006), http://alglobus.net/NASAwork/papers/
Space2006Antenna.pdf.
154. As the term is used here, autonomous machines are given goals to complete by users, but
determine for themselves the means of completing those goals. See Ryan Abbott, The Reasonable Computer: Disrupting the Paradigm of Tort Liability, 86 GEO. WASH. L. REV. 1 (2018). For example, a user could ask a computer to design a new battery with certain characteristics, and the computer could produce such a design without further human input. In this case, the machine would be autonomously inventive and competing with human inventors.
  
442
30 66 UCLA L. REV. 2 (2019)
problems they are trying to solve, researchers may rarely be unaided by computers. The more sophisticated the computer, the more it may be able to augment the worker’s skills.
Phase III, in the near future, will involve increased competition and cooperation between people and machines. In certain industries, and for certain problems, inventive machines will become the norm. For example, in the pharmaceutical industry, Watson is now identifying novel drug targets and new indications for existing drugs. Soon, it may be the case that inventive machines are the primary means by which new uses for existing drugs are researched. That is a predictable outcome, given the advantage machines have over people at recognizing patterns in very large datasets. However, it may be that people still perform the majority of research related to new drug targets. Where the standard varies within a broad field like drug discovery, this can be addressed by defining fields and problems narrowly, for instance according to the subclasses currently used by the Patent Office.155
Perhaps twenty-five years from now—based on expert opinion—the introduction of AGI will usher in Phase IV. Recall that AGI refers to artificial intelligence that can be applied generally, as opposed to narrowly in specific fields of art, and that it has intelligence comparable to a person. AGI will compete with human inventors in every field, which makes AGI a natural substitute for the skilled person. Even with this new standard, human inventors may continue to invent—just not as much. An inventor may be a creative genius whose abilities exceed the human average, or a person of ordinary intelligence who has a groundbreaking insight.
Just as SAI outperforms people in certain fields, it will likely be the case that SAI outperforms AGI in certain circumstances. An example of this could be when screening a million compounds for pesticide function lends itself to a “brute force” computational approach. For this reason, SAI could continue to represent the level of ordinary skill in fields in which SAI is the standard, while AGI could replace the skilled person in all other fields. However, the two systems will likely be compatible. A general AI system wanting to play Go could incorporate AlphaGo into its own programming, design its own algorithm like AlphaGo, or even instruct a second computer operating AlphaGo.
AGI will change the human-machine dynamic in another way. If the machine is genuinely capable of performing any intellectual task a person could,
155. See generally, Overview of the U.S. Patent Classification System (U.S.P.C.), U.S. PAT & TRADEMARK OFF. (2012), https://www.uspto.gov/sites/default/files/patents/resources/ classification/overview.pdf.
  
443
Everything Is Obvious 31
the machine would be capable of setting goals collaboratively with a person, or even by itself. Instead of a person instructing a computer to screen a million compounds for pesticide function, a person could merely ask a computer to develop a new pesticide. For that matter, an agrochemical company like Bayer could instruct DeepMind to develop any new technology for its business, or just to improve its profitability. Such machines should not only be able to solve known problems, but also solve unknown problems.
AGI will continually improve, transforming into ASI. Ultimately, in Phase V, when AGI succeeds in developing artificial superintelligence, it will mean the end of obviousness. Everything will be obvious to a sufficiently intelligent machine.
C. Inventive and Skilled Machines
For purposes of patent law, an inventive machine should be one which generates patentable output while meeting traditional inventorship criteria.156 Because obviousness focuses on the quality of a patent application’s inventive content, it should be irrelevant whether the content comes from a person or machine, or a particular type of machine. A machine which autonomously generates patentable output, or which does so collaboratively with human inventors where the machine meets joint inventorship criteria, is inventive.
Under the present framework, inventive machines would not be the equivalent of hypothetical skilled machines, just as human inventors are not skilled persons. In fact, it should not be possible to extrapolate about the characteristics of a skilled entity from information about inventive entities. Granted, the Federal Circuit once included the “educational level of the inventor” in its early factor-based test for the skilled person.157 However, that was only until it occurred to the Federal Circuit that:
[C]ourts never have judged patentability by what the real inventor/applicant/patentee could or would do. Real inventors, as a class, vary in the capacities from ignorant geniuses to Nobel laureates; the courts have always applied a standard based on an
156. See I Think, supra note 1 (arguing computers which independently meet human inventorship criteria should be recognized as inventors).
157. See e.g., Environmental, supra note 84.
  
444
32 66 UCLA L. REV. 2 (2019)
imaginary work of their own devising whom they have equated with the inventor.158
What then conceptually is a skilled machine? A machine that anthropomorphizes to the various descriptions courts have given for the skilled person? Such a test might focus on the way a machine is designed or how it functions. For instance, a skilled machine might be a conventional computer that operates according to fixed, logical rules, as opposed to a machine like DeepMind which can function unpredictably. However, basing a rule on how a computer functions might not work for the same reason the Flash of Genius test failed: Even leaving aside the significant logistical problem of attempting to figure out how a computer is structured or how it generates particular output, patent law should be concerned with whether a machine is generating inventive output, not what is going on inside the machine.159 If a conventional computer and a neural network were both able to generate the same inventive output, there should be no reason to favor one over the other.
Alternately, the test could focus on a machine’s capacity for creativity. For example, Microsoft Excel plays a role in a significant amount of inventive activity, but it is not innovative. It applies a known body of knowledge to solve problems with known solutions in a predictable fashion (for example, multiplying values together). However, while Excel may sometimes solve problems that a person could not easily solve without the use of technology, it lacks the ability to engage in almost any inventive activity.160 Excel is not the equivalent of a skilled machine—it is an automaton incapable of ordinary creativity.
Watson in clinical practice may be a better analogy for a skilled worker. Watson analyzes patients’ genomes and provides treatment recommendations.161 Yet as with Excel, this activity is not innovative. The problem Watson is solving may be more complex than multiplying a series of numbers, but it has a known solution. Watson is identifying known genetic mutations from a patient’s genome. Watson is then suggesting known treatments based on existing medical literature. Watson is not innovating
158. Kimberly-Clark Corp. v. Johnson & Johnson, 745 F.2d 1437, 1454 (Fed. Cir. 1984) (“[The] hypothetical person is not the inventor, but an imaginary being possessing ‘ordinary skill in the art’ created by Congress to provide a standard of patentability.”).
159. See I Think, supra note 1 (arguing against a subjective standard for computational invention).
160. Some behaviors like correcting a rogue formula may have a functionally creative aspect, but this is a minimal amount that would not rise to the level of patent conception if performed by a person.
161. See Wrzeszczynski et al., supra note 107.
  
445
Everything Is Obvious 33
because it is being applied to solve problems with known solutions, adhering to conventional wisdom.
Unlike Excel, however, Watson could be inventive. For instance, Watson could be given unpublished clinical data on patient genetics and actual drug responses and tasked with determining whether a drug works for a genetic mutation in a way that has not yet been recognized. Traditionally, such findings have been patentable. Watson may be situationally inventive depending on the problem it is solving.
It may be difficult to identify an actual computer program now which has a “skilled” level of creativity. To the extent a computer is creative, in the right circumstances, any degree of creativity might result in inventive output. To be sure, thisissimilartotheskilledperson. Apersonofordinaryskill,oralmostanyone,may haveaninventiveinsight. Characteristicscanbeimputedtoaskilledperson,butitis not possible the way the test is applied to identify an actual skilled person or to definitivelysaywhatshewouldhavefoundobvious. Theskilledpersontestissimply a theoretical device for a decisionmaker.
Assuming a useful characterization of a skilled machine, to determine that a skilled machine now represents the average worker in a field, decisionmakers would need information about the extent to which such machines are used. Obtaining this information may not be practical. Patent applicants could be asked generally about the use and prevalence of computer software in their fields, but it would be unreasonable to expect applicants to already have, or to obtain, accurate information about general industry conditions. The Patent Office, or another government agency, could attempt to proactively research the use of computers in different fields, but this would not be a workable solution. Such efforts would be costly, the Patent Office lacks expertise in this activity, and its findings would inevitably lag behind rapidly changing conditions. Ultimately, there may not be a reliable and low-cost source of information about skilled machines right now.
D. Inventive Is the New Skilled
Having inventive machines replace the skilled person may better correspond with real world conditions. Right now, there are inherent limits to the number and capabilities of human workers. The cost to train and recruit new researchers is significant, and there are a limited number of people with the ability to perform this work. By contrast, inventive machines are software
 
446
34 66 UCLA L. REV. 2 (2019)
programs which may be copied without additional cost.162 Once Watson outperforms the average industry researcher, IBM may be able to simply copy Watson and have it replace most of an existing workforce. Copies of Watson could replace individual workers, or a single Watson could do the work of a large team of researchers.
Indeed, as mentioned earlier, in a non-inventive setting, Watson can interpret a patient’s entire genome and prepare a clinically actionable report in ten minutes, as opposed to a team of human experts, which takes around one- hundred and sixty hours.163 Once Watson is proven to produce better patient outcomes than the human team, it may be unethical to have people underperform a task which Watson can automate. When that occurs, Watson should not only replace the human team at its current facility—it should replace every comparable human team. Watson could similarly automate in an inventive capacity.
Thus, inventive machines change the skilled paradigm because once they become the average worker, the average worker becomes inventive. As the outputs of these inventive machines become routinized, however, they should no longer be inventive by definition. The widespread use of these machines should raise the bar for obviousness, so that these machines no longer qualify as inventive but shift to become skilled machines—machines which now represent the average worker and are no longer capable of routine invention.164
Regardless of the terminology, as machines continue to improve, the bar for nonobviousness should rise. To generate patentable output, it may be necessary to use an advanced machine that can outperform standard machines, or a person or machine will need to have an unusual insight that standard machines cannot easily recreate. Inventiveness might also depend on the data supplied to a machine, such that only certain data would result in inventive output. Taken to its logical extreme, and given there is no limit to how sophisticated computers can become, it may be that everything will one day be obvious to commonly used computers.
It is possible to generate reasonably low-cost and accurate information about the use of inventive machines. The Patent Office should institute a requirement for patent applicants to disclose the role of computers in the
162. ANDREAS KEMPER, VALUATION OF NETWORK EFFECTS IN SOFTWARE MARKETS: A COMPLEX NETWORKS APPROACH 37 (2010).
163. See Wrzeszczynski et al., supra note 107.
164. See Enzo Biochem, Inc. v. Calgene, Inc., 188 F.3d 1362, 1374 n.10 (Fed. Cir. 1999) (“In view
of the rapid advances in science, we recognize that what may be unpredictable at one point in time may become predictable at a later time.”).
  
447
Everything Is Obvious 35
inventive process.165 This disclosure could be structured along the lines of current inventorship disclosure. Right now, applicants must disclose all patent inventors.166 Failure to do so can invalidate a patent or render it unenforceable.167 Similarly, applicants should have to disclose when a machine autonomously meets inventorship criteria.
These disclosures would only apply to an individual invention. However, the Patent Office could aggregate responses to see whether most inventors in a field (for example, a class or subclass) are human or machine. These disclosures would have a minimal burden on applicants compared to existing disclosure requirements and the numerous procedural requirements of a patent application. In addition to helping the Patent Office with determinations of nonobviousness, these disclosures would provide valuable information for purposes of attributing inventorship.168 It might also be used to develop appropriate innovation policies in other areas.169
E. Skilled People Use Machines
The current standard neglects to appropriately take into account the modern importance of machines in innovation. Instead of now replacing the skilled person with the skilled machine, it would be less of a conceptual change, and administratively easier, to characterize the skilled person as an average worker facilitated by technology. Recall the factor test for the skilled person includes: (1) “type[s] of problems encountered in the art,” (2) “prior art solutions to those problems,” (3) “rapidity with which innovations are made,” (4) “sophistication of the technology,” and (5) “educational level of active workers in the field.”170 This test could be amended to include, (6) “technologies used by
165. It may also be beneficial for applicants to disclose the use of computers when they have been part of the inventive process but where their contributions have not risen to the level of inventorship. Ideally, a detailed disclosure should be provided: Applicants should need to disclose the specific software used and the task it performed. In most cases, this would be as simple as noting a program like Excel was used to perform calculations. However, while this information would have value for policy making, it might involve a significant burden to patent applicants.
166. Duty to Disclose Information Material to Patentability, 37 C.F.R. § 1.56 (2018), https://www.uspto.gov/web/offices/pac/mpep/s2001.html [https://perma.cc/4DE9-ZRWE].
167. See, e.g., Advanced Magnetic Closures, Inc. v. Rome Fastener Corp., 607 F.3d 817, 829–30 (Fed. Cir. 2010) (upholding a district court decision to render a patent unenforceable on the grounds of inequitable conduct for misrepresenting inventorship).
168. See I Think, supra note 1 (advocating for acknowledging machines as inventors).
169. See Should Robots Pay Taxes?, supra note 6 (arguing the need to monitor automation for
adjusting tax incentives).
170. In re GPAC Inc., 57 F.3d 1573, 1579 (Fed. Cir. 1995).
  
448
36 66 UCLA L. REV. 2 (2019)
active workers.” This would more explicitly take into account the fact that human researchers’ capabilities are augmented with computers.
Moving forward in time, once the use of inventive machines is standard, instead of a skilled person being an inventive machine, the skilled person standard could incorporate the fact that technologies used by active workers includes inventive machines. In future research, the standard practice may be for a worker to ask an inventive machine to solve a problem. This could be conceptualized as the inventive machine doing the work, or the person doing the work using an inventive machine.
Granted, in some instances, using an inventive machine may require significant skill, for instance, if the machine is only able to generate a certain output by virtue of being supplied with certain data. Determining which data to provide a machine, and obtaining that data, may be a technical challenge. Also, it may be the case that significant skill is required to formulate the precise problem to put to a machine. In such instances, a person might have a claim to inventorship independent of the machine, or a claim to joint inventorship. This is analogous to collaborative human invention where one person directs another to solve a problem. Depending on details of their interaction, and who “conceived” of the invention, one person or the other may qualify as an inventor, or they may qualify as joint inventors.171 Generally, however, directing another partytosolveaproblemdoesnotqualifyforinventorship.172 Moreover,afterthe development of AGI, there may not be a person instructing a computer to solve a specific problem.
Whether the future standard becomes an inventive machine or a skilled person using an inventive machine, the result will be the same: The average worker will be capable of inventive activity. Replacing the skilled person with the inventive machine may be preferable doctrinally, because it emphasizes that it is the machine which is engaging in inventive activity, rather than the human worker.
The changing use of machines also suggests a change to the scope of prior art. The analogous art test was implemented because it is unrealistic to expect inventors to be familiar with anything more than the prior art in their field, and
171. “[C]onception is established when the invention is made sufficiently clear to enable one skilled in the art to reduce it to practice without the exercise of extensive experimentation or the exercise of inventive skill.” Hiatt v. Ziegler & Kilgour, 179 U.S.P.Q. 757, 763 (Bd. Pat. Interferences 1973); see also Gunter v. Stream, 573 F.2d 77, 79 (C.C.P.A. 1978).
172. Ex parte Smernoff, 215 U.S.P.Q. at 547 (“[O]ne who suggests an idea of a result to be accomplished, rather than the means of accomplishing it, is not a coinventor.”).
  
449
Everything Is Obvious 37
the prior art relevant to the problem they are trying to solve.173 However, a machine is capable of accessing a virtually unlimited amount of prior art. Advances in medicine, physics, or even culinary science may be relevant to solving a problem in electrical engineering. Machine augmentation suggests that the analogous arts test should be modified or abolished once inventive machines are common, and that there should be no difference in prior art for purposes of novelty and obviousness.174 The scope of analogous prior art has consistently expanded in patent law jurisprudence, and this would complete that expansion.175
F. The Evolving Standard
The skilled person standard should be amended as follows:
1) The test should now incorporate the fact that skilled persons are already augmented by machines. This could be done by adding “technologies used by active workers” as a sixth factor to the Federal Circuit’s factor test for the skilled person.
2) Once inventive machines become the standard means of research in a field, the skilled person should be an inventive machine when the standard approach to research in a field or with respect to a particular problem is to use an inventive machine.
3) When and if artificial general intelligence is developed, inventive machines should become the skilled person in all areas, taking into account that artificial general intelligence may also be augmented by specific artificial intelligence.
III. A POST-SKILLED WORLD
This Part provides examples of how the Inventive Machine Standard could work in practice, such as by focusing on reproducibility or secondary factors. It then goes on to consider some of the implications of the new standard. Once the average worker is inventive, there may no longer be a need for patents to function
173. In 1966, in Graham, the Court recognized that “the ambit of applicable art in given fields of science has widened by disciplines unheard of a half century ago . . . . [T]hose persons granted the benefit of a patent monopoly [must] be charged with an awareness of these changed conditions.” Graham v. John Deere Co., 383 U.S. 1, 19 (1966).
174. See supra Subpart I.E.
175. Innovative Scuba Concepts, Inc., v. Feder Indus., Inc., 819 F. Supp. 1487, 1503 (D. Colo.
1993) (discussing the expansion of analogous art); see also, e.g., George. J. Meyer Mfg. Co. v. San Marino Elec. Corp., 422 F.2d 1285, 1288 (9th Cir. 1970) (discussing the expansion of analogous art).
  
450
38 66 UCLA L. REV. 2 (2019)
as innovation incentives. To the extent patents accomplish other goals such as promoting commercialization and disclosure of information or validating moral rights, other mechanisms may be found to accomplish these goals with fewer costs.
A. Application
Mobil Oil Corp. v. Amoco Chemicals Corp. concerned complex technology involving compounds known as Zeolites used in various industrial applications.176 Mobil had developed new compositions known as ZSM-5 zeolites and a process for using these zeolites as catalysts in petroleum refining to help produce certain valuable compounds. The company received patent protection for these zeolites and for the catalytic process.177 Mobil subsequently sued Amoco, which was using zeolites as catalysts in its own refining operations, alleging patent infringement. Amoco counterclaimed seeking a declaration of noninfringement, invalidity, and unenforceability with respect to the two patents at issue. The case involved complex scientific issues. The three-week trial transcript exceeds 3300 pages, and more than 800 exhibits were admitted into evidence.
One of the issues in the case was the level of ordinary skill. An expert for Mobil testified that the skilled person would have “a bachelor’s degree in chemistry or engineering and two to three years of experience.”178 An expert for Amoco argued the skilled person would have a doctorate in chemistry and several years of experience.179 The District Court for the District of Delaware ultimately decided that the skilled person “should be someone with at least a Masters degree in chemistry or chemical engineering or its equivalent, [and] two or three years of experience working in the field.”180
If a similar invention and subsequent fact pattern happened today, to apply the obviousness standard proposed in this Article a decisionmaker would need to: (1) determine the extent to which inventive technologies are used in the field, (2) characterize the inventive machine(s) that best represents the average worker if inventive machines are the standard, and (3) determine whether the machine(s) would find an invention obvious. The decisionmaker is a patent
176. Mobil Oil Corp. v. Amoco Chems. Corp.,779 F. Supp. 1429, 1442–43 (D. Del. 1991).
177. Id.
178. Id. at 1443.
179. Id.
180. Id.
  
451
Everything Is Obvious 39
examiner in the first instance,181 and potentially a judge or jury in the event the validity of a patent is at issue in trial.182 For the first step, determining the extent to which inventive technologies are used in a field, evidence from disclosures to the Patent Office could be used. That may be the best source of information for patent examiners, but evidence may also be available in the litigation context.
Assume that today most petroleum researchers are human, and that if machines are autonomously inventive in this field, it is happening on a small scale. Thus, the court would apply the skilled person standard. However, the court would now also consider “technologies used by active workers.” For instance, experts might testify that the average industry researcher has access to a computer like Watson. They further testify that while Watson cannot autonomously develop a new catalyst, it can significantly assist an inventor. The computer provides a researcher with a database containing detailed information about every catalyst used not only in petroleum research, but in all fields of scientific inquiry. Once a human researcher creates a catalyst design, Watson can also test it for fitness together with a predetermined series of variations on any proposed design.
The question for the court will thus be whether the hypothetical person who holds at least a Master’s degree in chemistry or chemical engineering or its equivalent, has two or three years of experience working in the field, and is using Watson, would find the invention obvious. It may be obvious, for instance, if experts convincingly testify that the particular catalyst at issue were very closely related to an existing catalyst used outside of the petroleum industry in ammonia synthesis, that any variation was minor, and that a computer could do all the work of determining if it were fit for purpose.183 It might thus have been an obvious design to investigate, and it did not require undue experimentation in order to prove its effectiveness.
Now imagine the same invention and fact pattern occurring approximately ten years into the future, at which point DeepMind, together with Watson and a competing host of AI systems, have been set to the task of developing new
181. See U.S. PAT. & TRADEMARK OFF., supra note 24 (at the Patent Office, applications are initially considered by a patent examiner, and examiner decisions can be appealed to the Patent Trial and Appeal Board (PTAB)).
182. Mark A. Lemley, Why Do Juries Decide if Patents Are Valid? (Stanford Law Sch., Pub. Law & Legal Theory Research Paper Series, Working Paper No. 2306152, 2013), https://ssrn.com/abstract=2306152.
183. See Daiichi Sankyo Co. v. Matrix Labs., Ltd., 619 F.3d 1346, 1352 (Fed. Cir. 2010) (finding that a “chemist of ordinary skill would have been motivated to select and then to modify a prior art compound (e.g., a lead compound) to arrive at a claimed compound with a reasonable expectation that the new compound would have similar or improved properties compared with the old”).
  
452
40 66 UCLA L. REV. 2 (2019)
compounds to be used as catalysts in petroleum refining. Experts testify that the standard practice is for a person to provide data to a computer like DeepMind, specify desired criteria (for example, activity, stability, perhaps even designing around existing patents), and ask the computer to develop a new catalyst. From this interaction, the computer will produce a new design. As most research in this field is now performed by inventive machines, a machine would be the standard for judging obviousness.
The decisionmaker would then need to characterize the inventive machine(s). It could be a hypothetical machine based on general capabilities of inventive machines, or a specific computer. Using the standard of a hypothetical machine would be similar to using the skilled person test, but this test could be difficult to implement. A decisionmaker would need to reason what the machine would have found obvious, perhaps with expert guidance. It is already challenging for a person to predict what a hypothetical person would find obvious; it would be even more difficult to do so with a machine. Computers may excel at tasks people find difficult (like multiplying a thousand different numbers together), but even supercomputers struggle with visual intuition, which is mastered by most toddlers.
In contrast, using a specific computer should result in a more objective test. This computer might be the most commonly used computer in a field. For instance, if DeepMind and Watson are the two most commonly used AI systems for research on petroleum catalysts, and DeepMind accounts for 35 percent of the market while Watson accounts for 20 percent, then DeepMind could represent the standard. However, this potentially creates a problem—if DeepMind is the standard, then it would be more likely that DeepMind’s own inventions would appear obvious as opposed to the inventions of another machine. This might give an unfair advantage to non-market leaders, simply because of their size.
To avoid unfairness, the test could be based on more than one specific computer. For instance, both DeepMind and Watson could be selected to represent the standard. This test could be implemented in two different ways. In the first case, if a patent application would be obvious to DeepMind or Watson, then the application would fail. In the second case, the application would have to be obvious to both DeepMind and Watson to fail. The first option would result in fewer patents being granted, with those patents presumably going mainly to disruptive inventive machines with limited market penetration, or to inventions made using specialized non-public data. The second option would permit patents where a machine is able to outperform its competitors in some
 
453
Everything Is Obvious 41
material respect. The second option could continue to reward advances in inventive machines, and therefore seems preferable.
It may be that relatively few AI systems, such as DeepMind and Watson, end up dominating the research market in a field. Alternately, many different machines may each occupy a small share of the market. There is no need to limit the test to two computers. To avoid discriminating on the basis of size, all inventive machines being routinely used in a field or to solve a particular problem might be considered. However, allowing any machine to be considered could allow an underperforming machine to lower the standard, and too many machines might result in an unmanageable standard. An arbitrary cutoff may be applied based on some percentage of market share. That might still give some advantage to very small entities, but it should be a minor disparity.
After characterizing the inventive machine(s), a decisionmaker would need to determine whether the inventive machine(s) would find an invention obvious. This could broadly be accomplished in one of two ways: either with abstract knowledge of what the machines would find obvious, perhaps through expert testimony, or through querying the machines. The former would be the morepracticaloption.184 Forexample,apetroleumresearcherexperiencedwith DeepMind might be an expert, or a computer science expert in DeepMind and neural networks. This inquiry could focus on reproducibility.
Finally, a decisionmaker will have to go through a similar process if the same invention and fact pattern occurs twenty-five years from now, at which point artificial general intelligence has theoretically taken over in all fields of research. AGI should have the ability to respond directly to queries about whether it finds an invention obvious. Once AGI has taken over from the average researcher in all inventive fields, it may be widely enough available that the Patent Office could arrange to use it for obviousness queries. In the litigation context, it may be available from opposing parties. If courts cannot somehow access AGI, they may still have to rely on expert evidence.
184. Alternatively, the machine could be asked to solve the problem at question and given the relevant prior art. If the machine generates the substance of the patent, the invention would be considered obvious. However, this would require a decisionmaker to have access to the inventive machine. At the application stage, the Patent Office would need to contract with, say, Google to use DeepMind in such a fashion. For that matter, the Patent Office might use DeepMind not only to decide whether inventions are obvious, but to automate the entire patent examination process. At trial, if Google is party to a lawsuit, an opposing party might subpoena use of the computer. However, if Google is not a party, it might be unreasonable to impose on Google for access to DeepMind.
  
454
42 66 UCLA L. REV. 2 (2019)
B. Reproducibility
Even if an inventive machine standard is the appropriate theoretical tool for nonobviousness, it still requires certain somewhat subjective limitations, and decisionmakers may still have difficulty with administration. Still, the new standard only needs to be slightly better than the existing standard to be an administrative success.
A test focused on reproducibility, based on the ability of the machine selected to represent the standard being able to independently reproduce the invention, offers some clear advantages over the current skilled person standard, which results in inconsistent and unpredictable outcomes.185 Courts have “provided almost no guidance concerning either what degree of ingenuity is necessary to meet the standard or how a decisionmaker is supposed to evaluate whether the differences between the invention and prior art meet this degree.”186 This leaves decisionmakers in the unenviable position of trying to subjectively establish what another person would have found obvious. Worse, this determination is to be made in hindsight with the benefit of a patent application. On top of that, judges and juries lack scientific expertise.187 In practice, decisionmakers may read a patent application, decide that they know
185. See FED. TRADE COMM’N, supra note 16 (discussing objections to the skilled person standard).
186. Mandel, The Non-Obvious Problem, supra note 19, at 64.
187. As Judge Learned Hand wrote:
I cannot stop without calling attention to the extraordinary condition of the law which makes it possible for a man without any knowledge of even the rudiments of chemistry to pass upon such questions as these. The inordinate expense of time is the least of the resulting evils, for only a trained chemist is really capable of passing upon such facts . . . . How long we shall continue to blunder along without the aid of unpartisan and authoritative scientific assistance in the administration of justice, no one knows; but all fair persons not conventionalized by provincial legal habits of mind ought, I should think, unite to effect some such advance.
Parke-Davis & Co. v. H.K. Mulford Co., 189 F. 95, 115 (S.D.N.Y. 1911). See also Safety Car Heating & Lighting Co. v. Gen. Elec. Co., 155 F.2d 937, 939 (1946) (“Courts, made up of laymen as they must be, are likely either to underrate, or to overrate, the difficulties in making new and profitable discoveries in fields with which they cannot be familiar . . . .”); see also Doug Lichtman & Mark A. Lemley, Rethinking Patent Law’s Presumption of Validity, 60 STAN. L. REV. 45, 67 (2007) (“District Court judges are poorly equipped to read patent documents and construe technical patent claims. Lay juries have no skill when it comes to evaluating competing testimony about the originality of a technical accomplishment.”).
  
455
Everything Is Obvious 43
obviousness when they see it, and then reason backward to justify their findings.188
This is problematic because patents play a critical role in the development and commercialization of products, and patent holders and potential infringers should have a reasonable degree of certainty about whether patents are valid. A more determinate standard would make it more likely the Patent Office would apply a single standard consistently and result in fewer judicially invalidated patents. To the extent machine reproducibility is a more objective standard, this would seem to address many of the problems inherent in the current standard.
On the other hand, reproducibility comes with its own baggage. Decisionmakers have difficulty imagining what another person would find obvious, and it would probably be even more difficult to imagine in the abstract what a machine could reproduce. More evidence might need to be supplied in patent prosecution and during litigation, perhaps in the format of analyses performed by inventive machines, to demonstrate whether particular output was reproducible. This might also result in a greater administrative burden.
In some instances, reproducibility may be dependent on access to data. A large health insurer might be able to use Watson to find new uses for existing drugs by giving Watson access to proprietary information on its millions of members. Or, the insurer might license its data to drug discovery companies using Watson for this purpose. Without that information, another inventive computer might not able to recreate Watson’s analysis.
This too is analogous to the way data is used now in patent applications: Obviousness is viewed in light of the prior art, which does not include non- public data relied upon in a patent application. The rationale here is that this rule incentivizes research to produce and analyze new data. Yet as machines become highly advanced, it is likely that the importance of proprietary data will decrease. More advanced machines may be able to do more with less.
Finally, reproducibility would require limits. For instance, a computer which generates semi-random output might eventually recreate the inventive concept of a patent application if it were given unlimited resources. However, it would be unreasonable to base a test on what a computer would reproduce given, say, 7.5 million years.189 The precise limits that should be placed on
188. Jacobellis v. Ohio, 378 U.S. 184, 197 (1964) (Stewart, J., dissenting). This was later recognized as a failed standard. Miller v. California, 413 U.S. 15, 47–48 (1973) (Brennan, J., dissenting) (obscenity cases similarly relying on the Elephant Test).
189. This brings to mind a super intelligent artificial intelligence system, “Deep Thought,” which famously, and fictionally, took 7.5 million years to arrive at the “Answer to the Ultimate Question of Life, the Universe, and Everything.” DOUGLAS ADAMS, THE HITCHHIKER’S GUIDE TO THE GALAXY 180 (rev. ed. 2001) (1979). The answer was 42. Id. at 188.
  
456
44 66 UCLA L. REV. 2 (2019)
reproducibility might depend on the field in question, and what best reflected the actual use of inventive machines in research. For instance, when asked to design a new catalyst in the petroleum industry, Watson might be given access to all prior art and publicly available data, and then given a day to generate output.
C. An Economic vs. Cognitive Standard
The skilled person standard received its share of criticism even before the arrival of inventive machines.190 The inquiry focuses on the degree of cognitive difficulty in conceiving an invention but fails to explain what it actually means for differences to be obvious to an average worker. The approach lacks both a normative foundation and a clear application.191
In Graham, the Supreme Court’s seminal opinion on nonobviousness, the Court attempted to supplement the test with more “objective” measures by looking to real-world evidence about how an invention was received in the marketplace.192 Rather than technological features, these “secondary” considerations focus on “economic and motivational” features, such as commercial success, unexpected results, long-felt but unsolved needs, and the failure of others.193 Since Graham, courts have also considered, among other
190. See, e.g., Chiang, supra note 19, at 49 (as one commentator noted about the test as articulated by the Supreme Court in Graham, it gives “all the appearance of expecting a solution to appear out of thin air once the formula was followed. The lack of an articulable rule meant that determinations of obviousness took the appearance—and arguably the reality—of resting on judicial whim . . . .” (footnote omitted)); Abramowicz & Duffy, supra note 16, at 1598; Gregory N. Mandel, Patently Non-Obvious: Empirical Demonstration That the Hindsight Bias Renders Patent Decisions Irrational, 67 OHIO ST. L.J. 1391 (2006) (discussing problems with hindsight in nonobviousness inquiries); Gregory N. Mandel, Another Missed Opportunity: The Supreme Court’s Failure to Define Nonobviousness or Combat Hindsight Bias in KSR v. Teleflex, 12 LEWIS & CLARK L. REV. 323 (2008).
191. See Abramowicz & Duffy, supra note 16, at 1603 (“[N]either Graham nor in subsequent cases has the Supreme Court attempted either to reconcile the inducement standard with the statutory text or to provide a general theoretical or doctrinal foundation for the inducement standard.”).
192. See Graham v. John Deere Co., 383 U.S. 1, 17; MPEP § 2144.
193. Graham, 383 U.S. at 17; MPEP § 2144. Additional secondary considerations have since been
proposed. See, e.g., Andrew Blair-Stanek, Increased Market Power as a New Secondary Consideration in Patent Law, 58 AM. U. L. REV. 707 (2009) (arguing for whether an invention provides an inventor with market power); Abramowicz & Duffy, supra note 16, at 1656 (proposing changing commercial success to “unexpected commercial success,” adding as a consideration of the “cost of the experimentation leading to the invention,” and a few additional considerations).
  
457
Everything Is Obvious 45
things, patent licensing,194 professional approval,195 initial skepticism,196 near- simultaneous invention,197 and copying.198 Today, while decisionmakers are required to consider secondary evidence when available, the importance of these factors varies significantly.199 Graham endorsed the use of secondary considerations, but their precise use and relative importance have never been made clear.200
An existing vein of critical scholarship has advocated for adopting a more economic than cognitive nonobviousness inquiry, for example through greater reliance on secondary considerations.201 This would reduce the need for decisionmakers to try and make sense of complex technologies, and it could reduce hindsight bias.202
Theoretically, in Graham, the Court articulated an inducement standard, which dictates that patents should only be granted to “those inventions which would not be disclosed or devised but for the inducement of a patent.”203 But in practice, the inducement standard has been largely ignored due to concerns over application.204 For instance, few, if any, inventions would never be disclosed or devised given an unlimited time frame. Patent incentives may not increase, so
194. See, e.g., SIBIA Neurosciences, Inc. v. Cadus Pharm. Corp., 225 F.3d 1349, 1358 (Fed. Cir. 2000).
195. See, e.g., Vulcan Eng’g Co. v. Fata Aluminum, Inc., 278 F.3d 1366, 1373 (Fed. Cir. 2002).
196. See, e.g., Metabolite Labs., Inc. v. Lab. Corp. of Am. Holdings, 370 F.3d 1354, 1368 (Fed. Cir.
2004).
197. See, e.g., Ecolochem, Inc. v. S. Cal. Edison Co., 227 F.3d 1361, 1379 (Fed. Cir. 2000).
198. See, e.g., id. at 1377. See also Mark A. Lemley, Should Patent Infringement Require Proof of
Copying?, 105 MICH. L. REV. 1525, 1534–35 (2007).
199. See MPEP § 2144; Durie & Lemley, supra note 19, at 996–97.
200. See, e.g., Dorothy Whelan, A Critique of the Use of Secondary Considerations in Applying the
Section 103 Nonobviousness Test for Patentability, 28 B.C. L. REV. 357 (1987).
201. See, e.g., Merges, supra note 19, at 19 (arguing for patentability to be based on an a priori degree of uncertainty, that “rewards one who successfully invents when the uncertainty facing her prior to the invention makes it more likely than not that the invention won’t succeed” (emphasis omitted)); Chiang, supra note 19, at 42 (arguing for a utilitarian standard, such that “[a]n invention should receive a patent if the accrued benefits before independent invention outweigh the costs after independent invention”); Mandel, The Non- Obvious Problem, supra note 19, at 62 (arguing for nonobviousness to be based on “how probable the invention would have been for a person having ordinary skill in the art working on the problem that the invention solves”); Durie & Lemley, supra note 19, at 1004–07 (arguing for a greater reliance on secondary considerations); Duffy, supra note 19, at 343 (arguing a timing approach to determining obviousness); Devlin & Sukhatme, supra note
19; Abramowicz & Duffy, supra note 16, at 1598 (arguing for an inducement standard).
202. Graham, 383 U.S. at 36 (“[Secondary considerations] may also serve to ‘guard against slipping into use of hindsight.’” (citation omitted)). See also HERBERT F. SCHWARTZ &
ROBERT J. GOLDMAN, PATENT LAW AND PRACTICE 90–91 (6th ed. 2008).
203. Graham, 383 U.S. at 11.
204. See Abramowicz & Duffy, supra note 16, at 1594–95.
  
458
46 66 UCLA L. REV. 2 (2019)
much as accelerate, invention.205 This suggests that an inducement standard would at least need to be modified to include some threshold for the quantum of acceleration needed for patentability. Too high a threshold would fail to provide adequate innovation incentives, but too low a threshold would be similarly problematic. Just as inventions will be eventually disclosed without patents given enough time, patents on all inventions could marginally speed the disclosure of just about everything, but a trivial acceleration would not justify the costs of patents. An inducement standard would thus require a somewhat arbitrary threshold in relation to how much patents should accelerate the disclosure of information, as well as a workable test to measure acceleration.206 To be sure, an economic test based on the inducement standard would have challenges, but it might be an improvement over the current cognitive standard.207
The widespread use of inventive machines may provide the impetus for an economic focus. After inventive machines become the standard way that R&D is conducted in a field, courts could increase reliance on secondary factors. For instance, patentability may depend on how costly it was to develop an invention, andtheexanteprobabilityofsuccess.208 Thereisnoreasonaninventivemachine cannot be thought of, functionally, as an economically motivated rational actor. The test would raise the bar to patentability in fields where the cost of invention decreases over time due to inventive machines.
D. Other Alternatives
Courts may maintain the current skilled person standard and decline to consider the use of machines in obviousness determinations. However, this means that as research is augmented and then automated by machines, the average worker will routinely generate patentable output. The dangers of such a
205. See, e.g., Yoram Barzel, Optimal Timing of Innovations, 50 REV. ECON. & STATS. 348, 348 (1968); John F. Duffy, Rethinking the Prospect Theory of Patents, 71 U. CHI. L. REV. 439, 444 (2004).
206. Abramowicz & Duffy, supra note 16, at 1599 (proposing a “substantial period of time”).
207. See Abramowicz & Duffy, supra note 16, at 1663.
208. Id.
  
459
Everything Is Obvious 47
standard for patentability are well-recognized.209 A low obviousness requirement can “stifle, rather than promote, the progress of the useful arts.”210
Concerns already exist that the current bar to patentability is too low, and that a patent “anticommons” with excessive private property is resulting in “potential economic value . . . disappear[ing] into the ‘black hole’ of resource underutilization.”211 It is expensive for firms interested in making new products to determine whether patents cover a particular innovation, evaluate those patents, contact patent owners, and negotiate licenses.212 In many cases, patent owners may not wish to license their patents, even if they are non-practicing entities that do not manufacture products themselves.213 Firms that want to make a product may thus be unable to find and license all the rights they need to avoid infringing. Adding to this morass, most patents turn out to be invalid or not infringed in litigation.214 Excessive patenting can thus slow innovation, destroy markets, and, in the case of patents on some essential medicines, even cost lives.215 Failing to raise the bar to patentability once the use of inventive machines is widespread would significantly exacerbate this anticommons effect.
Instead of updating the skilled person standard, courts might determine that inventive machines are incapable of inventive activity, much as the U.S. Copyright Office has determined that nonhuman authors cannot generate copyrightable output.216 In this case, otherwise patentable inventions might not
209. See, e.g., ADAM B. JAFFE & JOSH LERNER, INNOVATION AND ITS DISCONTENTS: HOW OUR BROKEN PATENT SYSTEM IS ENDANGERING INNOVATION AND PROGRESS, AND WHAT TO DO ABOUT IT 32–35, 75, 119–23, 145–49 (2004) (criticizing the Patent Office for granting patents on obvious inventions); NATIONAL RESEARCH COUNCIL, A PATENT SYSTEM FOR THE 21ST CENTURY 87–95 (2004) (criticizing lenient nonobviousness standards); Matthew Sag & Kurt Rohde, Patent Reform and Differential Impact, 8 MINN. J.L. SCI. & TECH. 1, 2 (2007) (“Academics, business leaders, and government officials have all expressed concern that too many patents are issued for [obvious] inventions.” ).
210. KSR Int’l Co. v. Teleflex Inc., 550 U.S. 398, 427 (2007).
211. James M. Buchanan & Yong J. Yoon, Symmetric Tragedies: Commons and Anticommons, 43
J.L. & ECON. 1, 2; accord DAN L. BURK & MARK A. LEMLEY, THE PATENT CRISIS AND HOW THE
COURTS CAN SOLVE IT (2009) (arguing for a heightened bar to patentability).
212. See generally Mark A. Lemley, Ignoring Patents, 2008 MICH. ST. L. REV. 19, 25–26 (2008)
(describing various costs associated with innovation in patent heavy industries).
213. See David L. Schwartz & Jay P. Kesan, Analyzing the Role of Non-Practicing Entities in the
Patent System, 99 CORNELL L. REV. 425 (2014).
214. See Mark A. Lemley & Carl Shapiro, Probabilistic Patents, 19 J. ECON. PERSP. 75, 80 (2005).
215. See Michael A. Heller, The Tragedy of the Anticommons: Property in the Transition From
Marx to Markets, 111 HARV. L. REV. 621 (1998); see also MICHAEL HELLER, THE GRIDLOCK ECONOMY: HOW TOO MUCH OWNERSHIP WRECKS MARKETS, STOPS INNOVATION AND COSTS LIVES (2008); see also Michael A. Heller & Rebecca S. Eisenberg, Can Patents Deter Innovation? The Anticommons in Biomedical Research, 280 SCIENCE 698 (1998).
216. This has been a policy of the Copyright Office since at least 1984. See U.S. COPYRIGHT OFFICE, COMPENDIUM OF U.S. COPYRIGHT OFFICE PRACTICES § 306 (3d ed. 2014). The
  
460
48 66 UCLA L. REV. 2 (2019)
be eligible for patent protection, unless provisions were made for the inventor to be the first person to recognize the machine output as patentable. However, this would not be a desirable outcome. As I have argued elsewhere, providing intellectual property protection for computer-generated inventions would incentivize the development of inventive machines, which would ultimately result in additional invention.217 This is most consistent with the constitutional rationale for patent protection “[t]o promote the Progress of Science and useful Arts, by securing for limited Times to Authors and Inventors the exclusive Right to their respective Writings and Discoveries.”218
E. Incentives Without Patents?
Today, there are strong incentives to develop inventive machines. Inventions by these machines have value independent of intellectual property protection, but they should also be eligible for patent protection. People may apply as inventors for recognizing the inventive nature of a machine’s output,219 or more ambitiously, inventive machines may be recognized as inventors, resulting in stronger and fairer incentives.
Once inventive machines set the baseline for patentability, standard inventive machines, as well as people, should have difficulty obtaining patents. It is widely thought that setting a nonobviousness standard too high would reduce the incentives for innovators to invent and disclose. Yet once inventive machinesarenormal,thereshouldbelessneedforpatentincentives.220 Oncethe
Compendium of U.S. Copyright Office Practices elaborates on the “human authorship” requirement by stating: “The term ‘authorship’ implies that, for a work to be copyrightable, it must owe its origin to a human being.” Id. It further elaborates on the phrase “[w]orks not originated by a human author” by stating: “In order to be entitled to copyright registration, a work must be the product of human authorship. Works produced by mechanical processes or random selection without any contribution by a human author are not registrable.” Id. § 503.03(a).
217. See generally I Think, supra note 1.
218. U.S. CONST. art. I, § 8, cl. 8.
219. Conception requires contemporaneous recognition and appreciation of the invention. See
Invitrogen Corp. v. Clontech Labs., Inc., 429 F.3d 1052, 1064 (Fed. Cir. 2005) (noting that the inventor must have actually made the invention and understood the invention to have the features that comprise the inventive subject matter at issue); see also, e.g., Silvestri v. Grant, 496 F.2d 593, 597 (C.C.P.A. 1974) (“[A]n accidental and unappreciated duplication of an invention does not defeat the patent right of one who, though later in time, was the first to recognize that which constitutes the inventive subject matter.”).
220. See generally, Mark A. Lemley, IP in a World Without Scarcity (Stanford Public Law, Working Paper No. 2413974, 2014), http://dx.doi.org/10.2139/ssrn.2413974 (arguing new technologies that reduce costs will weaken the case for IP).
  
461
Everything Is Obvious 49
average worker is inventive, inventions will “occur in the ordinary course.”221 Machine inventions will be self-sustaining. In addition, the heightened bar might result in a technological arms race to create ever more intelligent computers capable of outdoing the standard. That would be a desirable outcome in terms of incentivizing innovation.
Even after the widespread use of inventive machines, patents may still be desirable. For instance, patents may be needed in the biotechnology and pharmaceutical industries to commercialize new technologies. The biopharma industry claims that new drug approvals cost around 2.2 billion dollars and take an average of eight years.222 This cost is largely due to resource intensive clinical trials required to prove safety and efficacy. Once a drug is approved, it is often relatively easy for another company to recreate the approved drug. Patents thus incentivize the necessary levels of investment to commercialize a product given that patent holders can charge monopoly prices for their approved products during the term of a patent.
Yet patents are not the only means of promoting product commercialization. Newly approved drugs and biologics, for example, receive a period of market exclusivity during which time no other party can sell a generic or biosimilar version of the product. Newly approved biologics, for instance, receive a twelve-year exclusivity period in the United States. Because of the length of time it takes to get a new biologic approved, the market exclusivity period may exceed the term of any patent an originator company has on its product. A heightened bar to patentability may lead to greater reliance on alternative forms of intellectual property protection such as market exclusivity, prizes, grants, or tax incentives.223
With regards to disclosure, without the ability to receive patent protection, owners of inventive machines may choose not to disclose their discoveries and rely on trade secret protection. However, with an accelerated rate of technological progress, intellectual property holders would run a significant risk that their inventions would be independently recreated by inventive machines.
Depending on the type of innovation, industry, and competitive landscape, business ventures may be successful without patents, and patent protection is
221. KSR Int’l Co. v. Teleflex Inc., 550 U.S. 398, 402 (2007).
222. Joseph A. DiMasi, Henry G. Grabowski, & Ronald W. Hansen, Innovation in the
Pharmaceutical Industry: New Estimates of R&D Costs, 47 J. OF HEALTH ECON. 20–33 (2016).
223. See generally Daniel J. Hemel & Lisa Larrimore Ouellette, Beyond the Patents-Prizes Debate, 92 TEX. L. REV. 303 (2013) (describing various nontraditional intellectual property
incentives).
  
462
50 66 UCLA L. REV. 2 (2019)
not sought for all potentially patentable inventions.224 In fact, “few industries consider patents essential.”225 For instance, patents are often considered a critical part of biotechnology corporate strategy, but often ignored in the software industry.226 On the whole, a relatively small percentage of firms patent, evenamongfirmsconductingR&D.227 Mostcompaniesdonotconsiderpatents crucial to business success.228 Other types of intellectual property such as trademark, copyright, and trade secret protection, combined with “alternative” mechanisms such as first mover advantage and design complexity may protect innovation even in the absence of patents.229
F. A Changing Innovation Landscape
Inventive machines may result in further consolidation of wealth and intellectual property in the hands of large corporations like Google and IBM. Large enterprises may be the most likely developers of inventive machines due to their high development costs.230 A counterbalance to additional wealth disparity could be broad societal gains. The public would stand to gain access to a tremendous amount of innovation—innovation which might be significantly delayed or never come about without inventive machines. In fact, concerns about industry consolidation are another basis for revising the obviousness inquiry. The widespread use of inventive machines may be inevitable, but raising the bar to patentability would make it so that inventions which would
224. BRONWYN HALL ET AL., INTELLECTUAL PROPERTY OFFICE, THE USE OF ALTERNATIVES TO PATENTS AND LIMITS TO INCENTIVES, 2 (2012), http://webarchive.nationalarchives.gov.uk/ 20140603121456/http://www.ipo.gov.uk/ipresearch-patalternative.pdf; see also, Rochelle Cooper Dreyfuss, Does IP Need IP? Accommodating Intellectual Production Outside the Intellectual Property Paradigm, 31 CARDOZO L. REV. 1437, 1439 (2010); see also David Fagundes, Talk Derby to Me: Intellectual Property Norms Governing Roller Derby Pseudonyms, 90 TEX. L. REV. 1094, 1146 (2012) (describing norm-based protections that function effectively in the absence of traditional IP). Patent holders are only successful in about a quarter of cases that are litigated to a final disposition and appealed. Paul M. Janicke & LiLan Ren, Who Wins Patent Infringement Cases?, 34 AIPLA Q.J. 1, 8 (2006). Fewer than two percent of patents are ever litigated, and only about 0.1 percent go to trial. Lemley & Shapiro, supra note 214, at 79. In cases where the validity of a patent is challenged, about half of the time the patent is invalidated. Allison & Lemley, supra note 20, at 205 (1998).
225. Merges, supra note 19, at 19.
226. See generally, Lemley & Shapiro, supra note 214.
227. Id.
228. Id.
229. Id.
230. See Jamie Carter, The Most Powerful Supercomputers in the World—and What They Do,
TECHRADAR (Dec. 13, 2014), http://www.techradar.com/us/news/computing/the-most- powerfulsupercomputers-in-the-world-and-what-they-do-1276865 (noting that most advanced computer systems are owned by governments and large businesses).
  
463
Everything Is Obvious 51
naturally occur would be less likely to receive protection. To the extent market abuses such as price gouging and supply shortages are a concern, protections are, at least theoretically, built into patent law to protect consumers against such problems.231 For example, the government could exercise its march in rights or issue compulsory licenses.232
Inventive machines may ultimately automate knowledge work and render human researchers redundant. While past technological advances have resulted in increased rather than decreased employment, the technological advances of the near future may be different.233 There will be fewer limits to what machines will be able to do, and greater access to machines. Automation should generate innovation with net societal gains, but it may also contribute to unemployment, financial disparities, and decreased social mobility.234 It is important that policymakers act to ensure that automation benefits everyone, for instance by investing in retraining and social benefits for workers rendered technologically unemployed.235 Ultimately, patent law alone will not determine whether automation occurs. Even without the ability to receive patent protection, once inventive machines are significantly more efficient than human researchers, they will replace people.
CONCLUSION
Prediction is very difficult, especially about the future.236
In the past, patent law has reacted slowly to technological change. For instance, it was not until 2013 that the Supreme Court decided human genes should be unpatentable.237 By then, the Patent Office had been granting patents on human genes for decades,238 and more than 50,000 gene-related patents had been issued.239
231. See Balancing Access, supra note 27 (discussing patent law protections against practices including “evergreening”).
232. See id. at 345 (explaining India’s issuance of a compulsory license).
233. See Should Robots Pay Taxes?, supra note 6; see supra Part I.
234. Id.
235. Id.
236. ARTHUR K. ELLIS, TEACHING AND LEARNING ELEMENTARY SOCIAL STUDIES 56, (1970) (quoting physicist Niels Bohr).
237. Ass’n for Molecular Pathology v. Myriad Genetics, Inc., 133 S. Ct. 2107 (2013).
238. See, e.g., U.S. Patent No. 4,447,538 (filed Feb. 5, 1982) (a patent issued in 1984 which claims
the human Chorionic Somatomammotropin gene).
239. Robert Cook-Deegan & Christopher Heaney, Patents in Genomics and Human Genetics, 11
ANN. REV. OF GENOMICS & HUM. GENETICS 383, 384 (2010) (“In April 2009, the U.S. Patent
  
464
52 66 UCLA L. REV. 2 (2019)
Eminent technologists now predict that artificial intelligence is going to revolutionize the way innovation occurs in the near to medium term. Much of what we know about intellectual property law, while it might not be wrong, has not been adapted to where we are headed. The principles that guide patent law need to be, if not rethought, then at least retooled in respect of inventive machines. We should be asking what our goals are for these new technologies, what we want our world to look like, and how the law can help make it so.
  and Trademark Office (USPTO) granted the 50,000th U.S. patent that entered the DNA Patent Database at Georgetown University. That database includes patents that make claims mentioning terms specific to nucleic acids (e.g., DNA, RNA, nucleotide, plasmid, etc.).”).

465
Should Robots Pay Taxes? Tax Policy in the Age of Automation
Ryan Abbott* & Bret Bogenschneider**
Existing technologies can already automate most work functions, and the cost of these technologies is decreasing at a time when human labor costs are increasing. This, combined with ongoing advances in computing, artificial intelligence, and robotics, has led experts to predict that automation will lead to significant job losses and worsening income inequality. Policy makers are actively debating how to deal with these problems, with most proposals focusing on investing in education to train workers in new job types, or investing in social benefits to distribute the gains of automation.
The importance of tax policy has been neglected in this debate, which is unfor- tunate because such policies are critically important. The tax system incentivizes automation even in cases where it is not otherwise efficient. This is because the vast majority of tax revenues are now derived from labor income, so firms avoid taxes by eliminating employees. Also, when a machine replaces a person, the government loses a substantial amount of tax revenue—potentially hundreds of billions of dol- lars a year in the aggregate. All of this is the unintended result of a system designed to tax labor rather than capital. Such a system no longer works once the labor is capital. Robots are not good taxpayers.
We argue that existing tax policies must be changed. The system should be at least “neutral” as between robot and human workers, and automation should not be allowed to reduce tax revenue. This could be achieved through some combination of disallowing corporate tax deductions for automated workers, creating an “automa- tion tax” which mirrors existing unemployment schemes, granting offsetting tax pref- erences for human workers, levying a corporate self-employment tax, and increasing the corporate tax rate.
INTRODUCTION
An automation revolution is underway.1 Current technologies can al- ready mechanize most work activities, and the cost of these technologies is
* Professor of Law and Health Sciences, University of Surrey School of Law and Adjunct Assistant Professor of Medicine at the David Geffen School of Medicine at University of California, Los Angeles.
** Senior Lecturer (Associate Professor), Finance Law & Ethics, University of Surrey School of Law. Thanks to Daniel Hemel for his insightful comments.
1 See, e.g., BANK OF AMERICA MERRILL LYNCH, ROBOT REVOLUTION: GLOBAL ROBOT & AI PRIMER 3 (Dec. 16, 2015) (on file with the Harvard Law School Library) (“The pace of disruptive technological innovation has gone from linear to parabolic in recent years. Penetra- tion of robots and artificial intelligence (AI) has hit every industry sector, and has become an integral part of our daily lives. Technology has also expanded beyond routine work, and moved into complex problem-solving, and replicating human perception, tasks that only people were capable of.”); see also Relating to the Training and Utilization of the Manpower Resources of the Nation: Hearing Before the Subcomm. on Emp’t and Manpower of the Comm. on Labor and Pub. Welfare, 88th Cong. 1659 (1963) (statement of Isaac L. Auerbach, President, Interna- tional Federation for Information Processing) (“The word ‘automation’ was coined by Delmar S. Harder, then executive vice president of the Ford Motor Co., in attempting to describe the latest kind of assembly line technique involving engine-block transfer machines then being installed at Ford’s River Rouge and Cleveland plants.”). For a definition of the term “automa- tion,” see Meg Leta Jones, The Ironies of Automation Law: Tying Policy Knots with Fair Auto-
  
146 466 Harvard Law & Policy Review [Vol. 12
decreasing at a time when human labor costs are increasing.2 On top of that, ongoing and exponential improvements in computing, artificial intelligence (AI), and robotics are permitting automation in an ever-increasing number of fields.3 As a result, academic and industry experts are widely predicting that automation will result in substantial “technological unemployment” in the near future.4 For instance, the McKinsey Global Institute has claimed that the disruption caused by AI will “happ[en] ten times faster and at 300 times the scale, or roughly 3,000 times the impact,” of the Industrial Revolution.5 We
mation Practices Principles, 18 VAND. J. ENT. & TECH. L. 77, 84 (2015) (“Broadly, automation includes all the ways computers and machines help people perform tasks more quickly, accurately, and efficiently. The term ‘automation’ refers to: (1) the mechanization and integration of the sensing of environmental variables through artificial sensors, (2) data processing and decision making by computers, and (3) mechanical action by devices that apply forces on the environment or information action through communication to people of informa- tion processed. The term encompasses open-loop operations and closed-loop control, as well as intelligent systems.”) (citations omitted). One of the most cited studies on technological unemployment claims that forty-seven percent of American jobs are at high risk of loss due to automation. See Carl Benedikt Frey & Michael A. Osborne, The Future of Employment: How Susceptible are Jobs to Computerisation?, 114 TECH. FORECASTING & SOC. CHANGE 254, 265–66 (2017), https://ac.els-cdn.com/S0040162516302244/1-s2.0-S0040162516302244-main .pdf?_tid=14d233e0-c236-11e7-a741-00000aacb362&acdnat=1509892499_c57668bde931faf 6de11b39073cccfc5 [https://perma.cc/LFE2-2T7A] (“[O]ur findings suggest recent develop- ments in [machine learning] will put a substantial share of employment, across a wide range of occupations, at risk in the near future.”).
2 See Frey & Osborne, supra note 1, at 265–68; but see JAMES MANYIKA ET AL., MCKIN- SEY GLOBAL INST., A FUTURE THAT WORKS: AUTOMATION, EMPLOYMENT, AND PRODUCTIVITY 21 (2017), https://www.mckinsey.com/~/media/McKinsey/Global%20Themes/Digital%20Dis ruption/Harnessing%20automation%20for%20a%20future%20that%20works/MGI-A-future- that-works_Full-report.ashx [https://perma.cc/2F6U-U259] (predicting that fewer than five percent of occupations could be entirely automated with existing technologies).
3 For examples of automation in white-collar and professional settings, see Roger Parloff, Why Deep Learning is Suddenly Changing Your Life, FORTUNE (Sept. 28, 2016, 5:00 PM), http://fortune.com/ai-artificial-intelligence-deep-machine-learning/ [https://perma.cc/5A6Q- 5U4T]. Of particular concern to future attorneys is that AI is already automating work func- tions in the legal services industry. See, e.g., Jane Croft, Legal Firms Unleash Office Auto- matons, FIN. TIMES, May 16, 2016 at 4 (discussing various software programs that can outperform attorneys and paralegals in document review); but see generally Dana Remus & Frank Levy, Can Robots Be Lawyers?: Computers, Lawyers, and the Practice of Law, 30 GEO. J. LEGAL ETHICS 501 (2017) (arguing that AI will refocus rather than replace attorneys).
4 See supra note 1. In the 1930s, the economist John Maynard Keynes popularized the term “technological unemployment” to refer to “unemployment due to our discovery of means of economising the use of labour outrunning the pace at which we can find new uses for labour.” The Future of Jobs: The Onrushing Wave, ECONOMIST (Jan. 18, 2014), https://www .economist.com/news/briefing/21594264-previous-technological-innovation-has-always-deliv- ered-more-long-run-employment-not-less [https://perma.cc/QQ3N-9AWN].
5 Richard Dobbs et al., The Four Global Forces Breaking All the Trends, MCKINSEY GLOBAL INST. (Apr. 2015), https://www.mckinsey.com/business-functions/strategy-and-corpo- rate-finance/our-insights/the-four-global-forces-breaking-all-the-trends [https://perma.cc/ LC89-B23C] (excerpting RICHARD DOBBS ET AL., NO ORDINARY DISRUPTION: THE FOUR GLOBAL FORCES BREAKING ALL THE TRENDS (2015)); see also JAMES MANYIKA ET AL., MCK- INSEY GLOBAL INST., DISRUPTIVE TECHNOLOGIES: ADVANCES THAT WILL TRANSFORM LIFE, BUSINESS, AND THE GLOBAL ECONOMY (2013), https://www.mckinsey.com/~/media/McKin sey/Business%20Functions/McKinsey%20Digital/Our%20Insights/Disruptive%20technolo gies/MGI_Disruptive_technologies_Full_report_May2013.ashx [https://perma.cc/EV85- WHVG] (predicting also trillions of dollars in economic impact by 2025 from advanced robot- ics, 3D printing and autonomous vehicles).
 
467
2018] Should Robots Pay Taxes? 147
are entering an era in which the combined impact of technological improve- ments in many different areas is going to be profoundly transformative—and disruptive.6
Automation has the potential to create widespread benefits. Not only will automation increase productivity, it will also improve safety and lead to new scientific breakthroughs.7 But without oversight, automation will also exacerbate unemployment and economic inequality.8 Even if workers ren- dered technologically unemployed are able to transition to new jobs, as has been the case during previous eras of rapid change, there will still be signifi- cant short-term disruptions. Moreover, many experts are predicting that to- day’s technological advances are different in kind from those of the past, and that large-scale permanent increases in unemployment are inevitable.9 In 1990, the three largest companies in Detroit with a combined market capital- ization of $36 billion employed 1.2 million workers.10 In 2014, the three
6 See, e.g., HERRING KAGERMANN, ET AL., INDUSTRIE 4.0 WORKING GRP., RECOMMENDA- TIONS FOR IMPLEMENTING THE STRATEGIC INITIATIVE INDUSTRIE 4.0, at 5 (2013), http://www .acatech.de/fileadmin/user_upload/Baumstruktur_nach_Website/Acatech/root/de/Material_fuer _Sonderseiten/Industrie_4.0/Final_report__Industrie_4.0_accessible.pdf [https://perma.cc/ PA7X-YSRE] (“The first three industrial revolutions came about as a result of mechanisation, electricity and IT. Now, the introduction of the Internet of Things and Services into the manu- facturing environment is ushering in a fourth industrial revolution.”); see also VERNOR VINGE, THE COMING TECHNOLOGICAL SINGULARITY: HOW TO SURVIVE IN THE POST-HUMAN ERA (1993) https://edoras.sdsu.edu/~vinge/misc/singularity.html [https://perma.cc/K4C9-LRDE] (coining the term “singularity” to refer to the argument that “we are on the edge of change comparable to the rise of human life on Earth. The precise cause of this change is the imminent creation by technology of entities with greater than human intelligence.”).
7 See generally Ryan Abbott, The Reasonable Computer: Disrupting the Paradigm of Tort Liability, 86 GEO. WASH. L. REV. (forthcoming 2018) (discussing the potential of automation to result in substantial safety benefits, for instance in the transportation industry); see also Ryan Abbott, I Think, Therefore I Invent: Creative Computers and the Future of Patent Law, 1079 B.C. L. REV. 1083–91 (2016) (discussing examples in which AI has generated patentable subject matter under circumstances in which the computer rather than a person has qualified for inventorship).
8 See COMM. ON TECH., NAT’L SCI. & TECH. COUNCIL, PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE 2 (2016) [hereinafter COMM. ON TECH.], https://obamawhitehouse .archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_fut ure_of_ai.pdf [https://perma.cc/DEH5-AQBK].
9 See Klaus Schwab & Richard Samans, Preface to WORLD ECON. F., THE FUTURE OF JOBS: EMPLOYMENT, SKILLS AND WORKFORCE STRATEGY FOR THE FOURTH INDUSTRIAL REVOLUTION, at v–vi (2016), http://www3.weforum.org/docs/WEF_Future_of_Jobs.pdf [https://perma.cc/K6B4-2EDL]; see also Brian Dorini, The End of Work: The Decline of the Global Labor Force and the Dawn of the Post-Market Era, 9 HARV. J.L. & TECH. 231, 232–33 (1995) (reviewing JEREMY RIFKIN, THE END OF WORK: THE DECLINE OF THE GLOBAL LABOR FORCE AND THE DAWN OF THE POST-MARKET ERA 136–43 (1995)) (“The ranks of the unem- ployed are swelling with former service sector workers, such as secretaries, receptionists, clerks, and cashiers. These workers are being replaced by what Rifkin calls the silicon-collar workforce: answering machines, scanners, voice and handwriting recognition devices, elec- tronic mail, and inventory control and monitoring devices.”) (citation omitted).
10 See Michael Chui & James Manyika, Digital Era Brings Hyperscale Challenges, FIN. TIMES (Aug. 13, 2014), https://www.ft.com/content/f30051b2-1e36-11e4-bb68-00144feabdc0 [http://perma.cc/4QHG-ZKDL].
 
148 468 Harvard Law & Policy Review [Vol. 12
largest companies in Silicon Valley with a combined market capitalization of $1.09 trillion employed 137,000 workers.11
These are not new problems.12 In 1962, President Kennedy stated, “I regard it as the major domestic challenge, really, of the sixties, to maintain full employment at a time when automation, of course, is replacing men.”13 His solution was to pass the nation’s first and most sweeping federal pro- gram to train workers unemployed due to technological advances.14 More recently, in December 2016, the Executive Office of the President issued a report which outlined a three-pronged policy response to automation and AI, namely, to: (i) “[i]nvest in and develop AI for its many benefits,” (ii) “[e]ducate and train Americans for jobs of the future,” and, (iii) “[a]id workers in the transition and empower workers to ensure broadly shared growth.”15 These and other proposals for dealing with automation have fo- cused on improving education and improving social benefit systems. Con- cerns about technological unemployment have even breathed new life into an old social benefit proposal—guaranteed minimum income, which could involve the government making fixed payments to each of its citizens re- gardless of their circumstances.16 While education reform often enjoys bipar- tisan support, enhanced social benefits are a politically challenging goal since liberals and conservatives often disagree on their desirability.17 In any
11 See id.
12 See generally JOHN FORBES DOUGLAS, SOME EVIDENCES OF TECHNOLOGICAL UNEM- PLOYMENT IN ANCIENT ATHENS AND ROME (1932). For instance, the Roman Emperor Vespa- sian once refused to use a labor-saving transportation machine, famously stating, “You must allow my poor hauliers to earn their bread.” See Steve Welch, The Real Political Divide is Education, TECH CRUNCH (Dec. 30, 2016), https://techcrunch.com/2016/12/30/the-real-politi- cal-divide-is-education/ [https://perma.cc/EL6C-JKAQ].
13 John F. Kennedy, The President’s News Conference, AM. PRESIDENCY PROJECT (Feb. 14, 1962), http://www.presidency.ucsb.edu/ws/index.php?pid=9003 [https://perma.cc/2L35- QTT7].
14 See Gladys Roth Kremen, MDTA: The Origins of the Manpower Development and Training Act of 1962, U.S. DEP’T OF LAB. (1974), www.dol.gov/general/aboutdol/history/ mono-mdtatext [https://perma.cc/KFC7-MPCV] (describing the law’s origins). Also of note, in 1961 (a year before the MDTA), the Office of Automation and Manpower was created at the Department of Labor to anticipate technological change and create occupational guidance. See id. For reviews of automation issues in the 1960s, see JAMES L. SUNDQUIST, POLITICS AND POLICY: THE EISENHOWER, KENNEDY, AND JOHNSON YEARS 77 (1968).
15 EXEC. OFFICE OF THE PRESIDENT, ARTIFICIAL INTELLIGENCE, AUTOMATION, AND THE ECONOMY 3 (2016) [hereinafter ARTIFICIAL INTELLIGENCE, AUTOMATION, AND THE ECON- OMY], https://obamawhitehouse.archives.gov/sites/whitehouse.gov/files/documents/Artificial- Intelligence-Automation-Economy.pdf [https://perma.cc/LK89-E5RG].
16 Guaranteed minimum income was proposed during the Industrial Revolution by Charles Fourier, and then later Joseph Charlier, before being adopted by John Stuart Mill. See Philippe Van Parijs, A Basic Income for All, BOS. REV. (2000), bostonreview.net/forum/ubi-van-parijs [https://perma.cc/6E52-Q63K]. (According to Mill’s proposal, “[A] certain minimum is first assigned for the subsistence of every member of the community, whether capable or not of labour.”).
17 See Yvonne A. Stevens, The Future: Innovation and Jobs, 56 JURIMETRICS J. 367, 373 (2016) (“One of the most commonly considered government payout schemes is what is re- ferred to as a basic income guarantee (BIG). Generally speaking, BIG is a monetary govern- ment-backed and issued guarantee such that all adults have access to an amount of money necessary to meet basic needs.”). President Richard Nixon also once proposed a guaranteed
 
469
2018] Should Robots Pay Taxes? 149
event, both education and social benefit reforms to deal with automation would require significant financial support.18
While there has been a lively public discourse on technological unem- ployment and income disparity, the automation debate has historically ig- nored the issue of taxation. That has very recently started to change. In February 2017, the European Parliament rejected a proposal to impose a “robot tax” on owners to fund support for displaced workers, citing con- cerns of stifling innovation.19 The next day, Bill Gates stated that he thought governments should tax companies’ use of robots to slow the spread of auto- mation and to fund other types of employment.20 Former U.S. Secretary of the Treasury Lawrence Summers then claimed Gates’s argument was “pro- foundly misguided.”21 In August 2017, South Korea announced plans for the world’s first “tax on robots” by limiting tax incentives for automated ma- chines.22 Currently, Korean businesses may deduct three to seven percent of an investment in automation equipment from their corporate taxes, depend- ing on the size of their operation.23 The announced reform would decrease the deduction rate by up to two percent.24
basic income of about $10,000 in today’s dollars for families of four. This proposal, the Family Assistance Plan, passed through the House before it was voted down by Senate Democrats. See Whitney Mallett, The Town Where Everyone Got Free Money, VICE: MOTHERBOARD (Feb. 4, 2015), https://motherboard.vice.com/en_us/article/nze99z/the-mincome-experiment-dauphin [https://perma.cc/R7E7-3NTL].
18 For example, in 2016, Switzerland voted down proposed guaranteed minimum income legislation that would have provided each citizen with about $30,000 a year. The cost of the legislation was estimated at about $200 billion, about three times Switzerland’s current annual federal spending. See John Thornhill & Ralph Atkins, Universal Basic Income: Money for Nothing, FIN. TIMES.COM (May 26, 2016), https://www.ft.com/content/7c7ba87e-229f-11e6- 9d4d-c11776a5124d [https://perma.cc/GR78-WG5H]. In the United Kingdom, it was esti- mated that distributing the current total welfare spending of £251 billion to 64.5 million per- sons as a universal basic income would result in a monthly payment to all residents of just £324. See Jim Edwards & Will Heilpern, Here’s How Much We’d All Get if the UK Introduced a ‘Fiscally Neutral’ Universal Basic Income Scheme, BUS. INSIDER (June 6, 2016, 10:25 AM), http://www.businessinsider.com/universal-basic-income-scheme-for-the-uk-2016- 6?r=UK&IR=T [https://perma.cc/4YRW-35G9]. This analysis is overly simplified, but dem- onstrates that providing a meaningful level of social benefits on a widespread basis requires significant funding.
19 See Reuters Staff, European Parliament Calls for Robot Law, Rejects Robot Tax, REUTERS (Feb. 16, 2007, 2:03 PM), http://ca.reuters.com/article/technologyNews/idCAKBN15 V2KM [https://perma.cc/5KTN-6VTJ].
20 See Kevin J. Delaney, The Robot That Takes Your Job Should Pay Taxes, Says Bill Gates, QUARTZ (Feb. 17, 2017), https://qz.com/911968/bill-gates-the-robot-that-takes-your- job-should-pay-taxes/ [https://perma.cc/6SHD-L7WY] (“Exactly how you’d do it, measure it, you know, it’s interesting for people to start talking about now.”).
21 Sarah Kessler, Lawrence Summers Says Bill Gates’ Idea for a Robot Tax is “Profoundly Misguided”, QUARTZ (Mar. 6, 2017), https://qz.com/925412/lawrence-summers-says-bill- gates-idea-for-a-robot-tax-is-profoundly-misguided/ [https://perma.cc/ATV3-DXEG].
22 See Cara McGoogan, South Korea Introduces World’s First ‘Robot Tax’, TELEGRAPH: TECH (Aug. 9, 2017, 12:54 PM), http://www.telegraph.co.uk/technology/2017/08/09/south-ko- rea-introduces-worlds-first-robot-tax/ [https://perma.cc/H93H-RPMC].
23 See Yoon Sung-won, Korea Takes First Step to Introduce ‘Robot Tax’, KOREA TIMES (Aug. 7, 2017, 8:47 PM), http://www.koreatimes.co.kr/www/news/tech/2017/08/133_234312 .html [https://perma.cc/82WW-B4QL].
24 See id.
 
150 470 Harvard Law & Policy Review [Vol. 12
The critical importance of tax policies on automation has not been ap- preciated. The current system encourages automation by providing employ- ers with preferential tax treatment for robot workers. Automation allows firms to avoid employee and employer wage taxes levied by federal, state, and local taxing authorities. It also permits firms to claim accelerated tax depreciation on capital costs for automated workers, and it creates a variety of indirect incentives for machine workers. All of this is the unintended re- sult of a tax system designed to tax labor rather than capital. Tax policies may thus result in automation in some cases in which a firm would other- wise choose a human worker.
Even more concerning, automation significantly reduces the govern- ment’s tax revenue since most tax revenue comes from labor-related taxes.25 When firms replace employees with machines, the government loses income due to taxation. A very rough estimate of revenue loss can be arrived at by multiplying an effective tax rate by the gross salary loss due to automation. In January 2017, the McKinsey Global Institute claimed that about half of current work activities could be automated using currently demonstrated technologies, which would eliminate $2.7 trillion in annual wages in the United States alone.26 Workers pay high effective tax rates ranging from twenty-five percent to fifty-five percent when all tax types are taken into account.27 This suggests that worker automation could result in hundreds of billions or even trillions of dollars in tax revenue lost per year at various levels of government.28
In the United States and most other developed nations, the bulk of taxes are currently remitted by workers either through wage withholding, taxation of labor income, or indirect taxation of workers as consumers.29 Since robots are not subject to these types of tax regimes, automation reduces the overall tax base. Robots are simply not taxpayers, at least not to the same extent as human workers. If all workers were to be replaced by machines tomorrow,
25 See OFFICE OF MGMT. & BUDGET, EXEC. OFFICE OF THE PRESIDENT, FISCAL YEAR 2015 HISTORICAL TABLES: BUDGET OF THE U.S. GOVERNMENT 32–33 tbl.2.1 (2015), https://www .gpo.gov/fdsys/pkg/BUDGET-2015-TAB/pdf/BUDGET-2015-TAB.pdf [https://perma.cc/ TT33-T3HA] (showing that individual income taxes, Social Security taxes, Medicare taxes, and other taxes assessed on labor wages comprised more than fifty percent of overall revenue); I.R.S., PUB. NO. 55B, DATA BOOK, 2014, at 3 tbl.1 (2015), https://www.irs.gov/pub/irs-pdf/ p55b.pdf [https://perma.cc/Q4YU-GUFD]; CONG. BUDGET OFFICE, DISTRIBUTION OF HOUSE- HOLD INCOME AND FEDERAL TAXES, 2010 (2013), https://www.cbo.gov/sites/default/files/ 113th-congress-2013-2014/reports/44604-AverageTaxRates.pdf [https://perma.cc/GH9J- YNQW]; see also Lester B. Snyder & Marianne Gallegos, Redefining the Role of the Federal Income Tax: Taking the Tax Law “Private” Through the Flat Tax and Other Consumption Taxes, 13 AM. J. TAX POL’Y 1, 86 (1996).
26 MANYIKA ET AL., supra note 2, at 6 exhibit E3.
27 See Bret N. Bogenschneider, The Effective Tax Rate of U.S. Persons by Income Level, 145 TAX NOTES 117, 117 tbl.1 (2014).
28 See MANYIKA ET AL., supra note 2, at 5; see also Frey & Osborne, supra note 1, at 267 (asserting that many creative science, engineering, and general knowledge work jobs will be done by computers in the long run).
29 See REVENUE STATISTICS - OECD COUNTRIES: COMPARATIVE TABLES, ORG. FOR ECON. CO-OPERATION & DEV. (2016), http://stats.oecd.org/Index.aspx?DataSetCode=REV [https:// perma.cc/74EJ-2KS8].
 
471
2018] Should Robots Pay Taxes? 151
most of the tax base would immediately disappear. As a matter of taxation, automated workers represent a type of capital investment, and capital in- come is currently taxed at much lower rates than labor income.30 This is not accidental; it is based on the historic belief that the taxation of labor income is more efficient than the taxation of capital income. This concept is dis- cussed in tax policy analysis as the “tax incidence” of capital taxation.31
Tax is thus critically important to the automation debate. Tax policies should not encourage automation unless it is part of a deliberate strategy based on sound public policy. We believe the solution is to adjust the tax system to be at least neutral as between robot and human workers.32 More ambitiously, changes to tax policies are necessary to account for the loss of government tax revenue due to automation. This is particularly critical be- cause the education and social benefit reform necessitated by automation will only be possible with more, not less, tax revenue.
This article outlines several potential tax policy solutions to address the automation revolution. Tax “neutrality” between human and automated workers could be achieved through some combination of disallowing corpo- rate tax deductions for automated workers, creating an “automation tax” which mirrors existing unemployment schemes, granting offsetting tax pref- erences for human workers, levying a corporate self-employment tax, and increasing the corporate tax rate. Neutrality in this setting refers to a system in which various alternatives are taxed equally, and so actors make decisions based on non-tax reasons.
Tax neutrality is widely accepted as an economically efficient principle for organizing a tax system.33 Neutral taxes are more likely to have fewer negative effects, lower administration and compliance costs, promote distri-
30 The term “capital taxation” refers here to corporate income taxation. For a comparison of effective tax rates between U.S. and EU multinationals, see Reuven S. Avi-Yonah & Yaron Lahav, The Effective Tax Rate of the Largest U.S. and EU Multinationals, 65 TAX L. REV. 375 (2012).
31 In a strange twist of economic theory, the ultimate cost of wage taxation paid by work- ers is generally thought to be borne by capital. See Arnold C. Harberger, Tax Policy in a Small, Open Developing Economy, in THE ECONOMICS OF THE CARIBBEAN BASIN 1 (Michael B. Con- nolly & John McDermott eds., 1985). For the extension of the “small open economy” model beyond the small open economy context, see A. Lans Bovenberg, Capital Income Taxation in Growing Open Economies, 31 J. PUB. ECON. 347 (1986); Anne Sibert, Taxing Capital in a Large, Open Economy, 41 J. PUB. ECON. 297 (1990); Alan J. Auerbach, Who Bears the Corpo- rate Tax? A Review of What We Know, 20 TAX POL’Y & ECON. 1 (2006).
32 See WILLIAM MEISEL, THE SOFTWARE SOCIETY: CULTURAL AND ECONOMIC IMPACT 226 (2013) (“There are other alternatives using the tax code. One option suggested by Martin Ford in The Lights in the Tunnel is modification of the payroll tax, a tax that discourages hiring people and encourages automation since it makes the use of people more expensive. He sug- gests a reform of the tax system where we get away from taxing based on workers to reduce the disincentive to hiring.”) (citing MARTIN FORD, THE LIGHTS IN THE TUNNEL: AUTOMATION, ACCELERATING TECHNOLOGY, AND THE ECONOMY (2009)).
33 See Tax: Fundamentals in Advance of Reform: Hearing Before the S. Comm. on Fin., 110th Cong. 41–50 (2008) (prepared statement of Jason Furman, Senior Fellow and Director of The Hamilton Project, The Brookings Institution) [hereinafter Prepared Statement of Jason Furman], https://www.finance.senate.gov/imo/media/doc/56020.pdf [https://perma.cc/Y98J- RN8K].
 
152 472 Harvard Law & Policy Review [Vol. 12
butional fairness, and increase transparency.34 Tax neutrality can thus result in a broader tax base with lower rates.35 Non-neutralities in the tax system distort choices and behavior other than for economic reasons, and encourage socially wasteful efforts to reduce tax payments.36 They can thus “create complexity, encourage avoidance, and add costs for both taxpayers and governments.”37
However, non-neutral taxes can be used deliberately to advance social policy—for instance, incentivizing activities like medical research, educa- tion, and homeownership.38 Taxes may also be used to disincentivize certain activities, as so-called “Pigouvian” taxes. For instance, consumer goods such as alcoholic beverages and tobacco products bear an exceptional tax burden. In turn, this results in increased consumer costs, with the goal of decreasing consumption—but due to taxes rather than to other market and economic factors.
The advantage of tax neutrality as between human and automated work- ers is that it permits the marketplace to adjust without tax distortions. With a level playing field, firms should only automate if it will be more efficient, without taking taxes into account. Since the current tax system favors auto- mated workers, a move toward a neutral tax system could increase the ap- peal of human workers. Policy solutions could even be implemented to make human workers more appealing than machines in terms of tax costs and ben- efits, to the extent policy makers choose to discourage automation.
The remainder of this article is divided into three parts. Part I discusses the phenomenon of automation and provides historical background on ef- forts to deal with its harmful effects. Part II analyzes current tax policies and contends that they promote automation even where it would not otherwise be efficient. Finally, Part III argues that changes to tax policy are needed to prevent the unintended consequences of encouraging automation and to off- set the government’s loss of tax revenue. We provide several potential solu- tions for achieving these goals.
The increased tax revenue from our proposal could be used to provide improved education and training for workers rendered unemployed by robots and computers. Should the pessimistic prediction of a near future with sub- stantially increased unemployment due to automation manifest, these taxes could also support social benefit programs such as a guaranteed minimum income. Automation will likely generate more wealth than has ever been possible. It should not come at the expense of the most vulnerable.
34 See JAMES MIRRLEES ET AL., INST. FOR FISCAL STUDIES, TAX BY DESIGN 22–23 (2011), https://www.ifs.org.uk/docs/taxbydesign.pdf [https://perma.cc/JSU8-KS5Q].
35 See Prepared Statement of Jason Furman, supra note 33, at 33.
36 See MIRRLEES ET AL., supra note 34, at 40.
37 Id. at 41.
38 See, e.g., Daniel J. Hemel & Lisa Larrimore Ouellette, Beyond the Patents–Prizes De-
bate, 92 TEX. L. REV. 303 (2013).
 
473
2018] Should Robots Pay Taxes? 153
I. THE PROBLEM WITH AUTOMATION
A. Automation is Coming
Experts are widely predicting that automation is going to have a sub- stantial impact on employment even in the near term. Bank of America Mer- rill Lynch argues that by 2025, AI may eliminate $9 trillion in employment costs by automating knowledge work.39 A report by the World Economic Forum estimates that automation could result in the net loss of 5.1 million jobs by 2020.40 The consulting firm Deloitte claims that thirty-five percent of jobs in the United Kingdom are at high risk of redundancy due to automation in the next ten to twenty years.41 This is due to a combination of factors: improvements in automation technologies, decreased costs for such technol- ogies, and increased labor costs. Whereas it was previously possible to auto- mate a large number of work processes, it has now become practicable. As automation technologies continue to both improve and decrease in cost, it is difficult to think of work functions that will not eventually be susceptible to automation.42
1. The Good: Increased Productivity and New Jobs
Automation increases productivity, which generates value and creates wealth.43 Partly due to technological advances and automation, the U.S. Gross Domestic Product (GDP) has steadily risen from $1.37 trillion in 1960 to $73.5 trillion in 2015.44 Despite academic criticism, GDP has remained the dominant economic indicator of welfare and standard of living for half a century.45
39 BANK OF AMERICA MERRILL LYNCH, supra note 1, at 1 (noting also that AI will yield $14–33 trillion in annual economic impact).
40 See WORLD ECON. F., THE FUTURE OF JOBS: EMPLOYMENT, SKILLS AND WORKFORCE STRATEGY FOR THE FOURTH INDUSTRIAL REVOLUTION 13 (2016), http://www3.weforum.org/ docs/WEF_Future_of_Jobs.pdf [https://perma.cc/K6B4-2EDL].
41 DELOITTE, AGILETOWN: THE RELENTLESS MARCH OF TECHNOLOGY AND LONDON’S RE- SPONSE 5 (2014), https://www2.deloitte.com/content/dam/Deloitte/uk/Documents/uk-futures/ london-futures-agiletown.pdf [https://perma.cc/Z5HU-PY25].
42 See Ryan Abbott, Hal the Inventor: Big Data and Its Use by Artificial Intelligence, in BIG DATA IS NOT A MONOLITH 188–91 (Cassidy R. Sugimoto et al. eds., 2016) (noting the ways in which automation technologies could replace workers in the pharmaceutical sciences).
43 See generally Joel Mokyr et al., The History of Technological Anxiety and the Future of Economic Growth: Is This Time Different?, 29 J. ECON. PERSP. 31 (2015).
44 See GDP (Current US$), WORLD BANK: DATA (2016), https://data.worldbank.org/indi- cator/NY.GDP.MKTP.CD [https://perma.cc/C34J-U67E].
45 See, e.g., Jeroen C.J.M. van den Bergh, The GDP Paradox, 30 J. ECON. PSYCHOL. 117, 117–18 (2008) (“Gross domestic product (GDP) is the monetary, market value of all final goods and services produced in a country over a period of a year. The real GDP per capita (corrected for inflation) is generally used as the core indicator in judging the position of the economy of a country over time or relative to that of other countries. The GDP is thus implic- itly, and often even explicitly, identified with social welfare—witness the common substituting phrase ‘standard of living’. . . . For over half a century now, the GDP (per capita) has been
 
154 474 Harvard Law & Policy Review [Vol. 12
Automation can also create new jobs.46 Human workers may be needed to build and maintain automation technologies. Automation may free up cap- ital for investments in new enterprises, result in the creation of new prod- ucts, or decrease production costs for existing products. Decreased production costs may result in lower consumer prices and thus greater con- sumer demand. All of this may increase employment. Technological ad- vances have also historically upgraded the labor force: automation has reduced the need for unskilled workers but increased the need for skilled workers.47 For instance, some of today’s most in-demand occupations did not exist even five years ago.48
2. The Bad: Unemployment and Inequality
Automation can cause under- and un-employment. While worker pro- ductivity has risen robustly since 2000, employment has stagnated.49 This may be due in part to technological advances.50 When a company like Mc- Donald’s introduces computer cashiers, the company may save money and consumers may enjoy lower prices.51 But human cashiers now find them- selves in a more competitive labor market. The enhanced competition may result in lower wages, less favorable employment terms, fewer working
severely criticized as not adequately capturing human welfare and progress. All the same, the GDP has maintained a firm position as a dominant economic indicator. . . .”).
46 The following arguments were referred to as “compensation theory” by Karl Marx, who argued none of these effects were guaranteed and that automation could result in forcing workers into lower paying jobs. See KARL MARX, CAPITAL, VOLUME I: THE PROCESS OF PRO- DUCTION OF CAPITAL 570 (1867).
47 See Automation and Technological Change: Hearing Before the Subcomm. on Econ. Stabilization of the J. Comm. on the Econ. Rep., 84th Cong. 29, 34–35 (Statement of Walter S. Buckingham, Jr., Associate Professor, Georgia Institute of Technology), https://www.jec.sen ate.gov/reports/84th%20Congress/Automation%20and%20Technological%20Change%20-% 20Hearings%20%2875%29.pdf [https://perma.cc/B348-CT38].
48 See WORLD ECON. F., supra note 40, at 3.
49 See, e.g., STEVEN GREENHOUSE, THE BIG SQUEEZE: TOUGH TIMES FOR THE AMERICAN WORKER 3 (2008).
50 See id. at 9.
51 Cf. Ted Goodman, Fight for $15? McDonald’s To Place Automated Ordering Stations At All US Locations, DAILY CALLER (Nov. 18, 2016, 6:44 PM), http://dailycaller.com/2016/11/ 18/fight-for-15-mcdonalds-to-place-automated-ordering-stations-at-all-us-locations [https:// perma.cc/VS4R-X35Y]. Standard economic principles suggest that in a competitive market lower business costs will result in lower consumer prices. See, e.g., Arthur A. Thompson, Jr., Strategies for Staying Cost Competitive, HARV. BUS. REV. (Jan. 1984), https://hbr.org/1984/01/ strategies-for-staying-cost-competitive [https://perma.cc/Y3SR-2WQC]. In fairness, fast food automation has been around since the nineteenth century. See Angelika Epple, The “Automat”: A History of Technological Transfer and the Process of Global Standardization in Modern Fast Food around 1900, 7 FOOD & HISTORY 97, 98 (2009), http://wwwhomes.uni-bielefeld.de/aep- ple/Aufsatz12TheAutomat2009.pdf [https://perma.cc/LZ7F-MSXS] (discussing the restaurant chain “Automat” which opened its first location in 1896). (“One of [Automat’s] highly unique selling features around 1900 was that no waiters were to be seen in the guest room. The Automat of that time was—at first sight—operated by vending machines only. ‘You absolutely help yourself’ was one of its most prominent marketing slogans.”) Id. at 99. The Automat’s technology transferred around the U.S. and Europe and eventually developed into the world’s largest restaurant chain: Horn & Hardart. Id. at 97.
 
475
2018] Should Robots Pay Taxes? 155
hours, reduced hiring, or layoffs.52 As the former CEO of McDonald’s USA famously quipped, “[i]t’s cheaper to buy a $35,000 robotic arm than it is to hire an employee who’s inefficient making $15 an hour bagging French fries. . . .”53 McDonald’s is now expanding its use of automated cashiers throughout the United States and in other countries.54
Also, while automation generates wealth, it does so unevenly. Over the past twenty-five years, partly due to automation technologies, the income share of the top 0.1% has increased substantially.55 The top 0.1% of the U.S. population is now worth about as much as the bottom 90%.56 CEO-to-worker pay ratios have increased a thousand-fold since 1950,57 but overall wages have been stagnant for thirty-five years.58 Increased automation is likely to accelerate these trends. The White House Council of Economic Advisers has predicted that future automation will disproportionately affect lower-wage jobs and less educated workers, causing greater economic inequality.59
Worsening employment coupled with growing income inequality is a recipe for social unrest.60 As physicist Stephen Hawking has warned,
52 See Simon Neville, McDonald’s ties nine out of 10 workers to zero-hours contracts, GUARDIAN (Aug. 5, 2013, 4:13 PM), https://www.theguardian.com/business/2013/aug/05/ mcdonalds-workers-zero-hour-contracts [https://perma.cc/UF3D-D4S4] (noting that 90% of McDonald’s UK workers have no guaranteed hours); see also Stephanie Strom, McDonald’s Introduces Screen Ordering and Table Service, N.Y. TIMES (Nov. 17, 2016), https://www.ny- times.com/2016/11/18/business/mcdonalds-introduces-screen-ordering-and-table-service .html?_r=0 [https://perma.cc/3DZ7-R68J] (reporting that the cost of purchasing and installing eight touch order screens is $56,000).
53 Julia Limitone, Fmr. McDonald’s USA CEO: $35K Robots Cheaper Than Hiring at $15 Per Hour, FOX BUS. (May 24, 2016), http://www.foxbusiness.com/features/2016/05/24/fmr- mcdonalds-usa-ceo-35k-robots-cheaper-than-hiring-at-15-per-hour.html [https://perma.cc/ W65G-697K] (claiming that a $15 minimum wage results in $30,000 a year for a full-time employee).
54 See Ed Rensi, The Ugly Truth About a $15 Minimum Wage, FORBES (Apr. 25, 2016, 6:30 AM), https://www.forbes.com/sites/realspin/2016/04/25/mcdonalds-minimum-wage-real- ity/#1f50a0d93edd [https://perma.cc/TT3E-G5SR]. Automated cashiers are already the “norm” in European countries with high labor costs, and McDonald’s is now experimenting with self-serve McCafe kiosks. See id.
55 See CARL BENEDIKT FREY & MICHAEL OSBORNE, TECHNOLOGY AT WORK: THE FUTURE OF INNOVATION AND EMPLOYMENT 14 (2015) http://www.oxfordmartin.ox.ac.uk/downloads/ reports/Citi_GPS_Technology_Work.pdf [https://perma.cc/YE22-D6AE].
56 See Angela Monaghan, US Wealth Inequality - Top 0.1% Worth as Much as the Bottom 90%, GUARDIAN (Nov. 13, 2014, 7:00 AM), https://www.theguardian.com/business/2014/nov/ 13/us-wealth-inequality-top-01-worth-as-much-as-the-bottom-90 [https://perma.cc/62U8- 6ADA].
57 Elliot Blair Smith & Phil Kuntz, CEO Pay 1,795-to-1 Multiple of Wages Skirts U.S. Law, BLOOMBERG MARKETS (Apr. 30, 2013, 12:01 AM), https://www.bloomberg.com/news/ articles/2013-04-30/ceo-pay-1-795-to-1-multiple-of-workers-skirts-law-as-sec-delays [https:// perma.cc/NNF6-P2X6].
58 See ELISE GOULD, ECONOMIC POLICY INSTITUTE, 2014 CONTINUES A 35-YEAR TREND OF BROAD-BASED WAGE STAGNATION (2015), http://www.epi.org/files/pdf/stagnant-wages-in- 2014.pdf [https://perma.cc/YN3U-9LMJ].
59 COMM. ON TECH., supra note 8, at 2.
60 See Katie Allen, ILO Warns of Rise in Social Unrest and Migration as Inequality Widens, GUARDIAN (Jan. 12, 2017, 4:00 PM), https://www.theguardian.com/business/2017/jan/ 12/ilo-warns-of-rise-in-social-unrest-and-migration-as-inequality-widens [https://perma.cc/ 3DHG-T2WH].
 
156 476 Harvard Law & Policy Review [Vol. 12
“[e]veryone can enjoy a life of luxurious leisure if the machine-produced wealth is shared, or most people can end up miserably poor if the machine- owners successfully lobby against wealth redistribution. So far, the trend seems to be toward the second option, with technology driving ever-increas- ing inequality.”61
3. The Ugly: Reduced Tax Remittances
One of automation’s most pronounced and unappreciated effects relates to taxes. Automation substantially reduces tax revenue. Most of the U.S. government’s tax revenue comes from taxes on workers.62 By stating that most tax revenue comes from workers, we refer to the aggregate amount of wage tax, income tax, and indirect taxes levied on income or wages derived from work at all levels of government. Much of the prior tax policy debate focused solely on income taxation by the federal government.63 Of course, a substantial portion of income subject to federal income tax arises from work and falls within our definition of worker taxation. However, the tax policy debate has been misleading since wage taxes are also levied on labor income and comprise more than one-third of federal remittances. Likewise, indirect state taxes are levied on workers. Consequently, by replacing employees with machines, the government loses out on employee and employer wage taxes levied by federal, state, and local taxing authorities. In addition, tax revenue may be further reduced from businesses claiming accelerated tax depreciation on capital outlays for machines and from other tax incentives related to indirect taxation, such as sales tax or value-added tax (VAT) exemptions.64
B. History of the Automation Scare
Fears of the consequences of automation have been expressed since the industrial revolution.65 In 1801, the writer Thomas Mortimer objected to ma- chines, “which are intended almost totally to exclude the labor of the human
61 Akshat Rathi, Stephen Hawking: Robots aren’t just taking our jobs, they’re making soci- ety more unequal, QUARTZ (Oct. 9, 2015), http://qz.com/520907/stephen-hawking-robots- arent-just-taking-our-jobs-theyre-making-society-more-unequal [https://perma.cc/A2BN- VYY5].
62 See OFFICE OF MGMT. & BUDGET, supra note 25, at 32–33 tbl.2.1.
63 See, e.g., CURTIS S. Dubay, THE HERITAGE FOUNDATION, THE RICH PAY MORE TAXES: TOP 20 PERCENT PAY RECORD SHARE OF INCOME TAXES (2009), http://www.heritage.org/pov- erty-and-inequality/report/the-rich-pay-more-taxes-top-20-percent-pay-record-share-income- taxes [https://perma.cc/N97H-VETS].
64 See infra Part III.
65 For that matter, broader social issues related to automation have been discussed since Aristotle’s time. See, e.g., JOHANNES HANEL, ASSESSING INDUCED TECHNOLOGY: SOMBART’S UNDERSTANDING OF TECHNICAL CHANGE IN THE HISTORY OF ECONOMICS 91 (2008) (noting Aristotle’s hope that machines could occupy the place of slaves in a utopian society).
 
477
2018] Should Robots Pay Taxes? 157
race.”66 In 1821, the economist David Ricardo argued that automation would result in inequality, and that “substitution of machinery for human labour, is often very injurious to the interests of the class of labourers. . . . [It] may render the population redundant, and deteriorate the condition of the la- bourer.”67 In 1839, the philosopher Thomas Carlyle more poetically wrote:
[T]he huge demon of Mechanism smokes and thunders, panting at his great task, in all sections of English land; changing his shape like a very Proteus; and infallibly, at every change of shape, over- setting whole multitudes of workmen, as if with the waving of his shadow from afar, hurling them asunder, this way and that, in their crowded march and course of work or traffic; so that the wisest no longer knows his whereabout[s].68
The Industrial Revolution even gave birth to a social movement and group protesting the use of new technologies: the Luddites.69 Luddites were primarily English textile workers who objected to working conditions in the nineteenth century. They believed that automation threatened their liveli- hoods, and they were opposed to the introduction of industrial machinery.70 Some Luddites engaged in violent episodes of machine-breaking, in re- sponse to which the English government made machine-breaking a capital offense.71
The Luddite movement died out, but automation concerns persisted throughout the twentieth century, often flaring during times of rapid techno- logical progress.72 For instance, the debate was revitalized in the 1950s and 1960s with the widespread introduction of office computers and factory ro-
66 THOMAS MORTIMER, LECTURES ON THE ELEMENTS OF COMMERCE, POLITICS, AND FI- NANCES 72 (London, A. Strahan, for T. N. Longman and O. Rees 1801).
67 DAVID RICARDO, ON THE PRINCIPLES OF POLITICAL ECONOMY AND TAXATION 283–84 (Batoche Books 2001) (3d ed. 1821).
68 2 THOMAS CARLYLE, THE WORKS OF THOMAS CARLYLE: CRITICAL AND MISCELLANE- OUS ESSAYS 141–42 (Henry Duff Traill ed., Cambridge Univ. Press 2010) (1899). Thomas Carlyle called the Industrial Revolution “the Mechanical Age.” Id at 59. Carlyle wrote that technology was causing a “mighty change” in their “modes of thought and feeling. Men are grown mechanical in head and in heart, as well as in hand.” Id. at 63.
69 See Richard Conniff, What the Luddites Really Fought Against, SMITHSONIAN MAG. (Mar. 2011), https://www.smithsonianmag.com/history/what-the-luddites-really-fought- against-264412/ [https://perma.cc/98RV-LNJ2].
70 See Ian Coulson, Power, Politics & Protest: The Growth of Political Rights in Britain in the 19th Century: Luddites, NAT’L ARCHIVES (U.K.), https://www.nationalarchives.gov.uk/edu- cation/politics/g3/ [https://perma.cc/96H4-4NAR].
71 See id.; see also Conniff, supra note 69. The “Luddite fallacy” now describes the fear that innovation will have long-term harmful labor effects. See Vivek Wadhwa, Sorry, but the jobless future isn’t a luddite fallacy, WASH. POST (July 7, 2015), https://www.washingtonpost .com/news/innovations/wp/2015/07/07/sorry-but-the-jobless-future-isnt-a-luddite-fallacy/?utm _term=.f52e3687022c [https://perma.cc/5JUA-YPUE].
72 In 1924, Mohandas Karamchand Gandhi wrote, “What I object to, is the craze for ma- chinery, not machinery as such. The craze is for what they call labour-saving machinery. Men go on ‘saving labour’, till thousands are without work and thrown on the open streets to die of starvation.” MOHANDAS K. GANDHI, YOUNG INDIA (1924), reprinted in ALL MEN ARE BROTH- ERS: LIFE AND THOUGHTS OF MAHATMA GANDHI AS TOLD IN HIS OWN WORDS 126 (Krishna Krapilani ed., 1958).
 
158 478 Harvard Law & Policy Review [Vol. 12
bots.73 In his 1960 election campaign, John F. Kennedy suggested that auto- mation offered “hope of a new prosperity for labor and a new abundance for America,” but that it also “carries the dark menace of industrial dislocation, increasing unemployment, and deepening poverty.”74
Despite these concerns, technological advances have historically re- sulted in overall job creation. The computer eliminated jobs, but created jobs for working with information created by computers. The automobile elimi- nated jobs, but created jobs in the motel and fast-food industries. The tractor and other agricultural advances eliminated jobs, but drove job growth in other areas of the economy. In 1900, forty-one percent of the workforce was employed in agriculture.75 In 2000, less than two percent of the employed labor force worked in agriculture.76 Yet this has not translated to a thirty-nine percent increase in unemployment. Even as agriculture-based employment and agriculture’s relative contribution to the GDP decreased, the productivity of farmworkers skyrocketed and agriculture’s absolute contribution to the GDP increased.77 Indeed, in each era when concerns have been expressed about automation causing mass unemployment, technology has created more jobs than it has destroyed.
C. Is This Time Different?
The automation debate is resurfacing with a vengeance due to recent advances in AI and other automation technologies. Once more, prognosti- cators are divided into two camps: the optimists who claim there will be a net creation of jobs, and the pessimists who predict mass unemployment and growing inequality.78
History favors the optimists.79 They argue that technological advances will generate widespread benefits together with overall job creation. They
73 See Kremen, supra note 14 (“The dawn of the Atomic Age had witnessed the imple- mentation of a new technology that threatened to replace men with machines.”); see also Douglas A. Irwin, Comments, in JAGDISH BHAGWATI & ALAN S. BLINDER, OFFSHORING OF AMERICAN JOBS: WHAT RESPONSE FROM U.S. ECONOMIC POLICY? 79 (Benjamin M. Friedman ed., 2009).
74 Irwin, supra note 73, at 80.
75 See CAROLYN DIMITRI ET AL., U.S. DEP’T OF AGRIC., THE 20TH CENTURY TRANSFORMA- TION OF U.S. AGRICULTURE AND FARM POLICY 2 (June 2005), https://www.ers.usda.gov/ webdocs/publications/44197/13566_eib3_1_.pdf?v=41055 [https://perma.cc/FRJ7-V3QA].
76 See id.
77 Id.; see also JULIAN M. ALSTON ET AL., PERSISTENCE PAYS: U.S. AGRICULTURAL PRO- DUCTIVITY GROWTH AND THE BENEFITS FROM PUBLIC R&D SPENDING 43, 105 (2010).
78 See Schwab & Samans, supra note 9, at v–vi; see also Dorini, supra note 9, at 233 (“The ranks of the unemployed are swelling with former service sector workers, such as secre- taries, receptionists, clerks, and cashiers. These workers are being replaced by what Rifkin calls the silicon-collar workforce: answering machines, scanners, voice and handwriting recog- nition devices, electronic mail, and inventory control and monitoring devices.”) (citation omitted).
79 See John Maynard Keynes, Economic Possibilities for our Grandchildren, in ESSAYS IN PERSUASION 321–32 (Palgrave Macmillan 2010) (1930) (predicting that the combination of technological innovation and capital accumulation will eventually solve the problem of mate- rial needs).
 
479
2018] Should Robots Pay Taxes? 159
also argue that current unemployment may relate more to globalization and offshoring than to technology, and that any future technological unemploy- ment would be “only a temporary phase of maladjustment.”80
But there is reason to think that this time may be different.81 Computers are improving exponentially, and there are fewer limits to what they can do than ever before. Computers can replace low-skilled workers and manual laborers as well as white-collar workers and professionals in a variety of fields. Computers are already working as doctors, lawyers, artists, and in- ventors.82 All of this is occurring at a time when labor costs are rising and computer costs are declining. In 2012, Vinod Khosla, the co-founder of Sun Microsystems, predicted that diagnostic software would take the jobs of eighty percent of physicians in the next twenty years.83
While the optimists and pessimists disagree about automation’s effects on long-term unemployment, both agree it causes short-term job losses and industry-specific disruption. During past episodes of widespread automation and technological change, it took decades to develop new worker skill sets on a significant scale and to build new job markets.84 Although the Industrial Revolution ultimately resulted in net job creation, it also resulted in periods of mass unemployment and human suffering. In the coming “Automation Revolution,” whether there are detrimental long-term effects, there will al- most certainly be significant short-term disruptions.85
80 Id. at 325; see also 1 JOHN STUART MILL, PRINCIPLES OF POLITICAL ECONOMY 97 (Cosimo Classics 2006) (1848).
81 See, e.g., Stevens, supra note 17, at 368–69 (“This time there may be some distinctions requiring widespread and perhaps novel solutions, unlike other periods in history.”).
82 See Parloff, supra note 3; see also Yonghui Wu et al., Google’s Neural Machine Trans- lation System: Bridging the Gap between Human and Machine Translation, CORNELL U. LIBR.: ARXIV 20 (Oct. 8, 2016), arxiv.org/abs/1609.08144 [https://perma.cc/KGU8-9RRB] (claiming that the Google Neural Machine Translation system is approaching human-level accuracy); see also Croft, supra note 3 (discussing various software programs that can outperform attorneys and paralegals in document review); but see generally Remus & Levy, supra note 3 (arguing that AI will refocus rather than replace attorneys).
83 See Liat Clark, Vinod Khosla: Machines Will Replace 80 Percent of Doctors, WIRED UK (Sept. 4, 2012), http://www.wired.co.uk/article/doctors-replaced-with-machines [https:// perma.cc/QNL8-WP4M].
84 See Schwab & Samans, supra note 9, at 20.
85 For example, a substantial number of transportation workers are likely to be displaced by self-driving vehicles, and about three percent of the population is employed in the transpor- tation industry. See Richard Henderson, Industry Employment and Output Projections to 2024, BUREAU OF LAB. STAT.: MONTHLY LAB. REV. tbl. 1 (Dec. 2015), https://www.bls.gov/opub/ mlr/2015/article/industry-employment-and-output-projections-to-2024.htm [https://perma.cc/ 54FB-LDMM]. Tesla, for example, plans to make all its vehicles self-driving. See Tesla to Make All Its New Cars Self-Driving, BBC NEWS: TECH. (Oct. 20, 2016), http://www.bbc.co.uk/ news/technology-37711489 [https://perma.cc/DS4X-YYM2]. Tesla is only one of many com- panies developing such technologies. See 44 Corporations Working on Autonomous Vehicles, CB INSIGHTS (May 18, 2017), https://www.cbinsights.com/blog/autonomous-driverless-vehi- cles-corporations-list/ [https://perma.cc/4YNE-KDTZ]; see also Investment Into Auto Tech On Pace To Break Annual Records, CB INSIGHTS (July 14, 2016), https://www.cbinsights.com/ blog/auto-tech-funding-h1-2016/ [https://perma.cc/HY5A-XGFH]. Elon Musk, the CEO of Tesla, has even claimed that self-driving cars will be so much safer than human drivers that there will need to be a future ban on human driving. See Stuart Dredge, Elon Musk: Self- driving Cars Could Lead to Ban on Human Drivers, GUARDIAN (Mar. 18, 2015, 3:22 AM),
 
160 480 Harvard Law & Policy Review [Vol. 12 D. Automation Social Policy
It is important that policy makers act to ensure that automation benefits everyone. Our policy goal should be to accommodate and even encourage advances that promote economic value, while redistributing benefits to those negatively affected. In the midst of the Industrial Revolution, the philoso- pher John Stuart Mill wrote that while automation would ultimately benefit laborers:
this does not discharge governments from the obligation of allevi- ating, and if possible preventing, the evils of which this source of ultimate benefit is or may be productive to an existing genera- tion. . . . [T]here cannot be a more legitimate object of the legisla- tor’s care than the interests of those who are thus sacrificed to the gains of their fellow-citizens and of posterity.86
Or, as the U.S. National Science and Technology Council Committee on Technology argued in 2016:
Public policy can address these risks, ensuring that workers are retrained and able to succeed in occupations that are complemen- tary to, rather than competing with, automation. Public policy can also ensure that the economic benefits created by AI are shared broadly, and assure that AI responsibly ushers in a new age in the global economy.87
Efforts to alleviate the harms and share the benefits of automation have focused on education and social benefits. As mentioned earlier, in December 2016, the Executive Office of the President, then under Barack Obama, is- sued a report which outlined policy responses to AI and automation, namely: to invest in AI, educate and train Americans for future jobs, and transition workers to ensure widespread benefits.88 In terms of education, it is thought that technologically unemployed workers need retraining to transition to new job types. Historically, numerous government and industry programs have combated technological unemployment with education.89 The nation’s first and most sweeping federal training program, the Manpower Development and Training Act of 1962, was signed into law by President Kennedy to train workers unemployed due to technological advances and automation.90 More
https://www.theguardian.com/technology/2015/mar/18/elon-musk-self-driving-cars-ban- human-drivers [https://perma.cc/5CPB-PVHS].
86 MILL, supra note 80, at 98.
87 COMM. ON TECH., supra note 8, at 2.
88 See ARTIFICIAL INTELLIGENCE, AUTOMATION, AND THE ECONOMY, supra note 15, at 3. 89 A particularly interesting example is the Armour Meat Packing Company, which cre-
ated “a special ‘automation fund’ for retraining purposes. The company paid a 14-cent levy into the fund, established in 1959, for every 100 tons of meat shipped, up to $500,000, to pay for retraining operations.” Kremen, supra note 14.
90 Id. Also of note, a year earlier, the Office of Automation and Manpower was created at the Department of Labor to anticipate technological change and create occupational guidance. Id. For extensive reviews of automation issues in the 1960s, see generally OFFICE OF MAN-
 
481
2018] Should Robots Pay Taxes? 161
recently, President Obama provided billions of dollars to fund worker train- ing in part to address technological unemployment.91 More ambitiously, he proposed a plan to make two years of community college free for “responsi- ble students” in his 2015 State of the Union Address, although this proposal was never adopted.92
As the third prong of President Obama’s 2016 strategy report notes, social benefit investments are also critical.93 The report advocates strength- ening the social safety net through greater investments in programs such as unemployment insurance and Medicaid.94 It also proposes the creation of new programs for wage insurance and emergency aid.95 In addition, it argues for building a twenty-first century retirement system, expanding health care access, and increasing worker bargaining power.96 President Trump’s admin- istration does not appear to have announced a policy response to AI and automation.97
POWER, AUTOMATION, & TRAINING, U.S. DEP’T OF LABOR, UNEMPLOYMENT AND RETRAINING: AN ANNOTATED BIBLIOGRAPHY OF RESEARCH (1965), https://babel.hathitrust.org/cgi/pt?id= umn.31951p010922940;view=1up;seq=1 [https://perma.cc/BZK8-3UYR]; see also SUND- QUIST, supra note 14, at 77.
91 See Press Release, The White House Office of the Press Sec’y, Fact Sheet: President Obama Proposes New ‘First Job’ Funding to Connect Young Americans with Jobs and Skills Training to Start Their Careers (Feb. 4, 2016), www.whitehouse.gov/the-press-office/2016/02/ 04/fact-sheet-president-obama-proposes-new-first-job-funding-connect-young [https://perma .cc/CV2T-SGB3].
92 John Morgan, Barack Obama Free Community College Plan Backed by $100M Fund- ing, TIMES HIGHER EDUC. (Apr. 27, 2016), www.timeshighereducation.com/news/barack- obama-free-community-college-plan-backed-by-one-hundred-million-dollar-funding [https:// perma.cc/5NTN-P3ZP].
93 See ARTIFICIAL INTELLIGENCE, AUTOMATION, AND THE ECONOMY, supra note 15, at 3–4. 94 See id.
95 See id. at 4.
96 See id.
97 Treasury Secretary Steve Mnuchin stated in March 2017 when asked about technologi- cal unemployment that, “In terms of artificial intelligence taking over American jobs, I think we’re . . . so far away from that that [it’s] not even on my radar screen . . . . I think it’s 50 or 100 more years.” Interview on Health Care and Tax Reform with Steven Mnuchin, Treasury Secretary, at 33:30–47, C-SPAN (Mar. 24, 2017), https://www.c-span.org/video/?425894-1/ treasury-secretary-steven-mnuchin-talks-axios-founder-mike-allen.&start=1992 [https://per ma.cc/6KYR-A82G]. By contrast, Larry Summers, the Obama administration’s first director of the National Economic Council, predicted that AI could result in about “a third of men be- tween the ages of 25 and 54 not working by the end of this half century.” Christopher Mat- thews, Summers: Automation is The Middle Class’ Worst Enemy, AXIOS, https://www.axios .com/summers-automation-is-the-middle-class-worst-enemy-1513302420-754facf2-aaca-478 8-9a41-38f87fb0dd99.html (last visited Jan. 7, 2018) [https://perma.cc/2UEA-PVU4]. Of note, China appears be adopting the findings of the White House strategy. On July 20, 2017, China’s State Council released its Next Generation Artificial Development Plan which adopts many of the policies proposed in the White House strategy. CHINA STATE COUNCIL, STATE COUNCIL NOTICE ON THE ISSUANCE OF THE NEXT GENERATION ARTIFICIAL INTELLIGENCE DE- VELOPMENT PLAN (Rogier Creemers et al. trans., 2017), https://www.newamerica.org/cyber- security-initiative/blog/chinas-plan-lead-ai-purpose-prospects-and-problems/ [https://perma .cc/5F3L-YE9K]. The plan argues that AI will be foundational to future economic growth and military dominance, and calls for China to surpass other nations in AI technology by 2030. See generally id.
 
162 482 Harvard Law & Policy Review [Vol. 12
Revitalized concerns about technological unemployment have breathed new life into an old social benefit proposal—guaranteed minimum income.98 The basic idea is that the government would provide a fixed amount of money to its citizens regardless of their situation. This has been implemented numerous times on a relatively small scale, most recently in Finland.99 In 2017, Finland began a pilot program to give about $600 per month to 2,000 unemployed citizens, with no other requirements.100 Proponents argue this will reduce unemployment, poverty, and disincentives for the unemployed to work (as under conventional unemployment schemes recipients generally lose their unemployment benefits after returning to work).101 It might also encourage education by providing support for a period of training. Critics have argued that a guaranteed minimum income will encourage recipients to remain unemployed and discourage additional education.102 In any case, Fin- land plans to eventually replace earnings-based insurance benefits with a basic income.103 Y Combinator, the Silicon Valley start-up incubator, has plans to launch a similar private program in Oakland, California.104
Improving education and social benefit systems will not be easy. Liber- als and conservatives alike can agree on the desirability of improving worker training as it will enlarge the productive labor 